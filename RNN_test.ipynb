{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "RNN_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvgruel123/ScrollMagic/blob/master/RNN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX45YhEbVvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import datetime\n",
        "import math, time\n",
        "import itertools\n",
        "from sklearn import preprocessing\n",
        "import datetime\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import load_model\n",
        "import keras\n",
        "import pandas_datareader.data as web\n",
        "import h5py\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdGaKLj2bVva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stock_name = '^GSPC'\n",
        "seq_len = 22\n",
        "d = 0.2\n",
        "shape = [4, seq_len, 1] # feature, window, output\n",
        "neurons = [256, 256, 16, 1]\n",
        "epochs = 300\n",
        "decay = 0.1\n",
        "batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1_1nzxsdLxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stock_data(stock_name, normalize=True):\n",
        "    start = datetime.datetime(1971, 1, 1)\n",
        "    end = datetime.date.today()\n",
        "    df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
        "    df['Average'] = (df['High'] + df['Low']) / 2\n",
        "    df = df[['Volume', 'Open', 'Average', 'Adj Close']]\n",
        "    result = df.values\n",
        "    \n",
        "    if normalize:        \n",
        "        min_max_scaler = preprocessing.MinMaxScaler()\n",
        "#         df['Volume'] = min_max_scaler.fit_transform(df.Volume.values.reshape(-1,1))\n",
        "#         df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
        "#         df['Average'] = min_max_scaler.fit_transform(df.Average.values.reshape(-1,1))\n",
        "#         df['Adj Close'] = min_max_scaler.fit_transform(df['Adj Close'].values.reshape(-1,1))\n",
        "        result = min_max_scaler.fit_transform(df.values.reshape(-1,4))\n",
        "    return result\n",
        " \n",
        "df = get_stock_data(stock_name, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxiOSokNdRAE",
        "colab_type": "code",
        "outputId": "aa04df06-68a2-4cef-95a9-1e6f4e4f2454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "def plot_stock(stock_name):\n",
        "    df = get_stock_data(stock_name, normalize=False)\n",
        "    plt.plot(df[:,-1], color='red', label='Adj Close')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "plot_stock(stock_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZgU1bnH8e/LOgIiq4oighFMBlSW\niUoSFRcUNTdu0YAbJhpyoyaSqBGiiSZ6TcyiERcIBiJ6I6hEgSjKRTEKJkEHAsgiYSQog4RNBQQH\nmOHcP061XTPTPdMz093VM/37PE8/VXXqdPdb3fB2zalT55hzDhERyQ/Nog5ARESyR0lfRCSPKOmL\niOQRJX0RkTyipC8ikkdaRB1ATbp06eJ69uwZdRgiIo3KokWLtjrnuibal9NJv2fPnhQXF0cdhohI\no2Jm7yXbp+YdEZE8oqQvIpJHlPRFRPJITrfpJ7Jv3z5KS0spKyuLOpRGraCggO7du9OyZcuoQxGR\nLGp0Sb+0tJQDDzyQnj17YmZRh9MoOefYtm0bpaWl9OrVK+pwRCSLGl3zTllZGZ07d1bCbwAzo3Pn\nzvprSSQPNbqkDyjhp4E+Q5H81CiTvohIk/b44zBxYkZeWkm/nmbMmIGZ8c477yStc/XVVzN9+nQA\nrr32WlauXFmtzr59+xgzZgy9e/dm4MCBDB48mBdffBHwN6dt3bo1MwcgIrlr5Ej4zncy8tJK+vU0\ndepUvvKVrzB16tSU6v/hD3+gsLCwWvlPfvITNm7cyPLly1m8eDEzZsxg586d6Q5XRARQ0q+XTz75\nhAULFjBp0iSmTZv2WblzjhtuuIFjjjmGM888k82bN3+2b8iQIdWGlNi9ezePPvooDz74IK1btwbg\nkEMO4dJLL632nvfddx/9+vWjX79+/O53vwNg165dnHfeeRx//PH069ePp556CoBFixZx6qmnMmjQ\nIM4++2w2btyY9s9ARBqnRtdls5LRo2HJkvS+Zv/+ECTVZGbOnMmwYcPo06cPnTt3ZtGiRQwaNIjn\nnnuO1atXs3LlSjZt2kRhYSHf+ta3kr5OSUkJPXr0oH379jW+36JFi/jjH//IwoULcc5x4okncuqp\np7J27VoOO+wwXnjhBQC2b9/Ovn37+N73vsfMmTPp2rUrTz31FLfddhuTJ0+u+2chItm3Z49fnnde\nRl5eZ/r1MHXqVIYPHw7A8OHDP2vief311xkxYgTNmzfnsMMO4/TTT0/L+y1YsIALL7yQtm3b0q5d\nOy666CLmz5/Psccey9y5c7n11luZP38+Bx10EKtXr2b58uUMHTqU/v37c/fdd1NaWpqWOEQkC3bs\n8MtzzsnIyzfuM/1azsgz4cMPP2TevHm8/fbbmBkVFRWYGb/+9a/r/FpHH30077//Pjt27Kj1bD+R\nPn36sHjxYmbPns3tt9/OGWecwYUXXkjfvn35+9//XufXE5EcsH27X7Zpk5GXr/VM38wKzOxNM1tq\nZivM7GdBeS8zW2hmJWb2lJm1CspbB9slwf6eodcaG5SvNrOzM3JEGTZ9+nSuvPJK3nvvPdatW8f6\n9evp1asX8+fP55RTTuGpp56ioqKCjRs38uqrr9b4Wm3atOGaa67hxhtvZO/evQBs2bKFZ555plK9\nk08+mRkzZrB792527drFc889x8knn8wHH3xAmzZtuOKKK7jllltYvHgxxxxzDFu2bPks6e/bt48V\nK1Zk5sMQkfSaMwcmTPDr776bkbdI5Ux/D3C6c+4TM2sJLDCzF4EfAvc756aZ2QTgGmB8sPzIOXe0\nmQ0H7gW+YWaFwHCgL3AY8LKZ9XHOVWTguDJm6tSp3HrrrZXKLr74YqZOncojjzzCvHnzKCwspEeP\nHgwePLhSvUQ3RN19993cfvvtFBYWUlBQQNu2bfn5z39eqc7AgQO5+uqrOeGEEwDf/XPAgAHMmTOH\nW265hWbNmtGyZUvGjx9Pq1atmD59Ot///vfZvn075eXljB49mr59+6b5kxCRtNq/H4YNi2+fnaHz\nYudcyg+gDbAYOBHYCrQIygcDc4L1OcDgYL1FUM+AscDY0Gt9Vi/ZY9CgQa6qlStXVitrDPr16+fW\nrl0bdRiVNNbPUqRJKi11DuKPhQvr/VJAsUuSV1O6kGtmzc1sCbAZmAu8C3zsnCsPqpQChwfrhwPr\ngx+UcmA70DlcnuA54fcaZWbFZla8ZcuWVMLLeUOHDuXYY4/V4GYiktyUKZW3338/I2+T0oVc55tg\n+ptZB+A54PMZica/10RgIkBRUZHL1Ptk09y5c6MOQURyXb9+lbeHDMnI29Spy6Zz7mPgVXxzTgcz\ni/1odAc2BOsbgCMAgv0HAdvC5QmeUyf+rxdpCH2GIjmkvBxuvLFyWXDDZrql0nuna3CGj5kdAAwF\nVuGT/9eDaiOBmcH6rGCbYP+8oI1pFjA86N3TC+gNvFnXgAsKCti2bZuSVgO4YDz9goKCqEMRyV93\n3RVvwrnjDli3rvL+DCX9VJp3ugFTzKw5/kfiaefc82a2EphmZncD/wQmBfUnAU+YWQnwIb7HDs65\nFWb2NLASKAeud/XoudO9e3dKS0tpKu39UYnNnCUiEVi1Cn76U/9wDhJ1q87QrHaWy2fMRUVFrup4\nNSIijV6XLrBtm193DhLNb9GA3Gxmi5xzRYn2aRgGEZFsiyX8CCjpi4hk2v79foDIDN1lWxdK+iIi\nmbZkCTzwAIwYUbn8+OMT13/kkYyFoqQvIpJp5cF9rM7Fh04G37ZfkaA/y5FHZiwUJX0RkUzbt88v\nW7aENWvi5RUV8Omn1etnaFhlaOxDK4uINAbBKLq0agUlJfHyv/4Vqg6DnuEelTrTFxHJtHnz/PL1\n12Hp0sr7zjorq6Eo6YuIZNoXvuCXzsGdd0YaipK+iEgeUdIXEcm0cI+diCnpi4hkWllZavWC2fEy\nSb13REQyLVG3zKqyNA6azvRFRDJt9+7qZZ06ZT8OlPRFRDLvJz+pXtazZ3z9kEOyFoqSvohItr36\nqr9RKyaLZ/1K+iIi2XbUUdAslH5XrcraWyvpi4hkUqKeO82bwwEHZD8WlPRFRDJr167qZa1bw5Qp\n8e3TT89aOEr6IiKZlCjpd+kChx8OAwb47QsuyFo4SvoiIpm0cGHyfd26+WWbNtmJBSV9EZHMuvTS\n5Pti7f1K+iIiTcywYXDXXfDBB/GyCJK+hmEQEcmU8NAKs2b5mbPCYgOx5dKZvpkdYWavmtlKM1th\nZjcG5Xea2QYzWxI8zg09Z6yZlZjZajM7O1Q+LCgrMbMxmTkkEZEcERtz5/Ofr57wIT4/bvhGrQxL\n5Uy/HLjJObfYzA4EFpnZ3GDf/c6534Qrm1khMBzoCxwGvGxmfYLdDwNDgVLgLTOb5ZxbmY4DERHJ\nOZ984pc33JB4//79ftksey3ttb6Tc26jc25xsL4TWAUcXsNTzgemOef2OOf+DZQAJwSPEufcWufc\nXmBaUFdEpGn69a/98i9/Sbx/2TK/XLAgO/FQxwu5ZtYTGADE+iDdYGbLzGyymXUMyg4H1oeeVhqU\nJSuv+h6jzKzYzIq3bNlSl/BERHLLb4KGkNrmwd22LfOxBFJO+mbWDvgzMNo5twMYD3wO6A9sBH6b\njoCccxOdc0XOuaKuXbum4yVFRLLvssvi65dfXnPdXOu9Y2Yt8Qn/T865ZwGcc5tC+x8Fng82NwBH\nhJ7ePSijhnIRkablhRfi6+3b11w3ixdyU+m9Y8AkYJVz7r5QebdQtQuB5cH6LGC4mbU2s15Ab+BN\n4C2gt5n1MrNW+Iu9s9JzGCIiOaSsDHbsiG/XNrjaSSdlNp6QVM70vwxcCbxtZkuCsh8DI8ysP+CA\ndcB3AJxzK8zsaWAlvufP9c65CgAzuwGYAzQHJjvnVqTxWEREcsOKFFNbly6wdSscf3xm4wmpNek7\n5xYAlmDX7Bqe8z/A/yQon13T80REmoQZM+Lrf/tb8noWpNZY180s0B25IiLpNGAALAkaRS6/HAYP\nTl431j8/S5Oig8beERFJr1jCB7jmmprrxpJ+Fs/0lfRFRDIlPPl5IhE07yjpi4hkysEH17z/S1/y\nyyxOnaikLyKSLlXb5tu2rbn+lClQXAydO2cupiqU9EVE0mX37vj6a6/VXr9NGxg0KHPxJKCkLyKS\nLqtW+eUDD8App0QbSxJK+iIi6TJ0qF/OmxdtHDVQ0hcRSYeKCvj4Y79+7rk1142Qkr6ISDrEJkwB\nuPji6OKohZK+iEg6xKZGhKz2xqkrJX0RkXSI9dy54opo46iFkr6ISDqMHeuXtfXNj5gGXBMRaYiK\nCmgRSqVr1kQXSwp0pi8i0hDnn195+4knookjRUr6IiINEZ4WEaBbt8T1coSSvohIQ5x4YuVtSzTn\nVO5Q0hcRqYlzcPbZPpmPH199f7irZiOgC7kiIslMmADf/W58+7rroHVr6NvXn+E/8wwsWxZdfPVg\nLovTdNVVUVGRKy4ujjoMEclHzsVntkqktBS6d0/8vIiZ2SLnXFGifWreERFJ5K67at7/0EPZiSPN\n1LwjIpLIHXfUvP+Xv6y8/c47sH175uJJEyV9EZF0OOaYqCNISa3NO2Z2hJm9amYrzWyFmd0YlHcy\ns7lmtiZYdgzKzczGmVmJmS0zs4Gh1xoZ1F9jZiMzd1giIg1QUVF5O8eHVqiLVNr0y4GbnHOFwEnA\n9WZWCIwBXnHO9QZeCbYBzgF6B49RwHjwPxLAHcCJwAnAHbEfChGRnLJiReXtDz6Av/0tmljSrNak\n75zb6JxbHKzvBFYBhwPnA1OCalOAC4L184HHnfcPoIOZdQPOBuY65z50zn0EzAWGpfVoREQaaulS\nOP74ymXt2ye+6eqMM7ITUxrVqU3fzHoCA4CFwCHOuY3Brv8AhwTrhwPrQ08rDcqSlVd9j1H4vxDo\n0aNHXcITEWmYsjLo3z/xvr17q5e1bw8DBsDVV2c0rHRKOembWTvgz8Bo59wOC/3qOeecmaWlc6pz\nbiIwEXw//XS8pohISm6+uXrZ1Kl++e678bIOHfzUiAcdBIsXZye2NEmpn76ZtcQn/D85554NijcF\nzTYEy81B+QbgiNDTuwdlycpFRHLDww9X3j71VPjGN/x68+bx8nbt/LJ9++zElUap9N4xYBKwyjl3\nX2jXLCDWA2ckMDNUflXQi+ckYHvQDDQHOMvMOgYXcM8KykREctPvfhdvyw8n/dJSv6w6wmYjkErz\nzpeBK4G3zWxJUPZj4JfA02Z2DfAecGmwbzZwLlAC7Aa+CeCc+9DM7gLeCur93Dn3YVqOQkQkE1q3\njq+Hk35MuMmnkag16TvnFgDJxgqtduna+cF8rk/yWpOByXUJUEQkMq1axddbJEiXRQmHt8lpGntH\nRATgz3+uXhY+0w//AMRcdVXm4skQJX0RkdJS+PrX49udO/tlokQflgMjataVkr6IyOjRlbf79PHL\ncJNOx2AAgYMPjpcp6YuINDJvvFG5aWfPHj+C5ogRvj9+zMknw9NPw7p18bJEN2zlOCV9EclvX/lK\n5e1WreCUU+DJJ6tPonLJJXDAAfCjH/nt8vLsxJhGSvoiInU1MrhF6eKLo42jHjSevojkr6pt8mPH\npva8wsJG2Z4POtMXkXw2f37l7XvuiSaOLFLSF5H89eCDUUeQdUr6IpK/pk+POoKsU9IXEckjupAr\nIvnpo4/i6y+8AIceGl0sWaSkLyL5qVOn+Pq550YXR5apeUdE8s/GjbXXaaKU9EUk/zTC0THTRUlf\nRPLLX/8KL78cdRSRUdIXkfyycGHl7XDbfh5Q0heR/FJ1Bqx//zuaOCKipC8i+cVCs7/efju0bx9d\nLBFQ0heR/PL66/H1u+6KLo6IKOmLSH6ZOTPqCCKlpC8i2XHjjdG3n2/dGu375wAlfRHJrKlTfTv6\nuHFw1FHRxtK1a3x98eLo4ohQrUnfzCab2WYzWx4qu9PMNpjZkuBxbmjfWDMrMbPVZnZ2qHxYUFZi\nZmPSfygieeDTT6GiIuooUldSApddFnUUiQ0YEHUEkUjlTP8xYFiC8vudc/2Dx2wAMysEhgN9g+c8\nYmbNzaw58DBwDlAIjAjqikhdHHQQDBwI+/fDrbfCu+9GHVHN+vSpXrZ9e/bjqGrFiqgjiEytSd85\n9zrwYYqvdz4wzTm3xzn3b6AEOCF4lDjn1jrn9gLTgroiUhf79sGyZdC8OfzqV9C3b9QR1SzRlIJD\nh2Y/DoD334+vF+bvOWdD2vRvMLNlQfNPx6DscGB9qE5pUJasvBozG2VmxWZWvGXLlgaEJ5IH9uyJ\nOoK6e+utaN73tdeied8cU9+kPx74HNAf2Aj8Nl0BOecmOueKnHNFXcMXXUTy2f798NJLUUdRN7ny\ng+Qc7NgBrVpFHUlOqFfSd85tcs5VOOf2A4/im28ANgBHhKp2D8qSlYtIKu6/H845J+ooUrd/f+6M\nUX/77f5ayPDhfvs//4k2nojVK+mbWbfQ5oVArGfPLGC4mbU2s15Ab+BN4C2gt5n1MrNW+Iu9s+of\ntkieqTpIWK67/36YNy/qKLyqN2PleQtCKl02pwJ/B44xs1Izuwb4lZm9bWbLgNOAHwA451YATwMr\ngZeA64O/CMqBG4A5wCrg6aCuiNTk00/98plnkte5//7sxJKq/fvh5pvj2x06VK+zfTv8+Mf+wnSm\nfPKJXx5ySOXyZvl9e5K5RFfXc0RRUZErLi6OOgyRaPzrX3DMMfD447VP+pFL/49nzoQLLohv/+Mf\ncNJJies+8QRccUX6Y7j+enjkEfj5z+GnP628L5c+qwwxs0XOuaKE+5T0RXLUNdfA5Mm+PTpR3/Zz\nz4XZs/16Lv0/Do9iCbB3r7+IetxxvrtpVZmIvWoMmX6/HFNT0s/vv3NEcllBgV8mu5kplvAB1q9P\nXCcXtGwJZWXwz3/Cl78cbSzhZqc8paQvkouee843T6SqR4/cOINNdm9N69a+LT0T7ekTJsDbb6dW\nd8iQ9L9/I6OkL5KLLrqo5v2Juh1m8qJoqv7v/+Lr27bBzp2V96e7r3xJCXz3u77p6PTTfVlZWfL6\nbdum9/0boRa1VxGRnBBr27/ppuo9UgB27YruBqRdu3xz1MSJfnvWrMRzzy5Zkr73LC6GL34xvv3q\nq365dGn1ur/8pf9sTjklfe/fSOlMXyTXJBtFc9w46N8ffvITv/3731fe//DD8N57mY0tkX37oF07\nf6Ydm5XqS19KXLems/C6SjSsQkWFH4iuqptugh/8IO+7a4J674jknjFj4N57q5evXAlf+ELlskS9\nVLL5f7q83F+oTTWGe+6B226rXHbccYnPzmuT6Nh37oQDD0w9niZKvXdEGpNECR/iN2qF/epXmY2l\nNokSfk3GhKbS+Pzn/TJRN876ev75+Hrnzn6Zp+PmJ6OkL5JL5s9Pvq979+plsW6dYdmaknDOnMTl\n11+f/Dnh5pV33omvp+tMfMSI+PqTT/plrowBlCOU9EVyyXe+U3n744/j6wcfXL3+scdWL8vWJCXD\nEs2tRO09j155xd9pHPZhqlN2BFLpqTR0qD/zv/POur12E6ekL5JLVq2Kr5eW+h473bolrz9kCNx3\nX+WytWszEtpnRo6s+Y7XWNfJmvaHz/Kh7pPBvPGGXzZr5i9g33139TpmcN550EKdFMOU9EVyVcdg\nbqIlS2ru6li1OeXii9Mfy6efwujR/oz88cer76vP+Dnt28fXN22qvX74r57TTvPLP/4RrrsOevas\n+/vnKSV9kVx1wAF+efDBcPzxyesl6pufzq6bs2dDmzbwwAPxi6NhBQXwox/5M+qVK1N/3br8UFx1\nlf8RXLSocnmsDb9589RfK88p6YtEzbnqZ7pr1tTchFKbHTsaFlPYeecl3xdr1z/2WN/OXrVLaU1+\nW4cJ9554wi+vuqryRd9Y76GqE53rRyApJX2RqE2YAIce6i9wxhx9dMNe87jj/A/Htm0Nm7Zw166a\n9zdkCseCgvhsVqkqK4vf9Rv20UeVt8PDQUglSvoiUZs2zS9LStL7un36QJcuibt1JlNcDH/9a3w7\nWXPNuHF++eKL9Q4PqNtfBuAvUj/6aPXyqmf2eXYzVl3osrZI1GJdLMMXKuvr5ZfhzDOrlztXe3PR\nv/4VH8umb1/fXp6oDR/ge9/zj4aKvV+/fsnrXHJJ5e116/yypuGkq3YJlc8o6YtE6S9/iQ9BEL5b\ntb6OOipxeUkJ9O5d83N/9rP4+ooVfkLxmMWL/Xg6ZWXVe+80RGyy9/PPT7x//XqYPr1y2bZtfhnu\nyhoer+i3v018I5sASvoi0dmwAb72terl99xT/9ds0cKPwFn1wnCfPrU3ecTuYE3koINg40Z/x/B/\n/Vf940ukdevkN1sVFiZ/XrhJJ9xlM9wVVKpRm75IVB5+OHF5TcMY1KZFi8z0XGnb1k9wnu6EDz7m\n8vLq5Zs3xyc3r034TmaNpFkjfToiUUk2smR9zlTXrPF3pR56KHzwQeI6iRJr2IUXJt/Xpk3dY0pV\nsqSfaM6AZA480DdBFRQkHx5CACV9keicfHL6Xuvoo/2QxTVdrN29O/k+5/wUjVD9L5BNmxIPV5wu\nzZvD/v11e06iZp8BA/zdwYcdlp64miglfZGojB3rl1VvLEqn8OBrsV4viQweHF+/7jr/I9Cjh99O\nNNBbOjVrVn3imNoGjUs00JykpNakb2aTzWyzmS0PlXUys7lmtiZYdgzKzczGmVmJmS0zs4Gh54wM\n6q8xs5GZORyRRqimi5UNsXZt5aaiZM0+W7bAwoV+PfyXwrJlySc6T6dmzaqf6Ve9o/j3v6/8wxRe\nlzpJ5Uz/MaBqI9kY4BXnXG/glWAb4Bygd/AYBYwH/yMB3AGcCJwA3BH7oRCRDOnVyy9/8AO/jHWP\nrCp8Jh8b7gB8j50uXTITW1jz5tXP9MOTwyxeDKNGxW8Ia9cOvv/9zMfVRNWa9J1zrwNVB7s+H5gS\nrE8BLgiVP+68fwAdzKwbcDYw1zn3oXPuI2Au1X9IRPJHbNiAbCTVk05Kvq9t28rbl1+e2VgS2bgR\n/vCHymUPPeSXRxwRn/mqXz9/hj93bsPGJcpz9e2nf4hzbmOw/h8gdpn9cCB8m1xpUJasXCT/7N8f\nHwUzdhaeSbEz/COPrL4vfHE36l4vy5b5MYPCwnf9FhTA3/6W3ZiaoAbfnOWcc2aWtoEuzGwUvmmI\nHrELSSJNxZo1/kapmLqOPVMfsZ43VYdbrjrWz2OPZT6WmpSVVS+74Ybsx9HE1bf3zqag2YZguTko\n3wAcEarXPShLVl6Nc26ic67IOVfUtWvXeoYnkoPKyionfPBNG9k0d258PTz6Ztu2desXnwmJmmxi\ncwpI2tQ36c8CYj1wRgIzQ+VXBb14TgK2B81Ac4CzzKxjcAH3rKBMJH8kmqA7NgPUt7/tl3UZYz6Z\nFStg3rzKZbGBzc46Kz5x+ptv+uU3vpH+ET4bInaTWLLxeKRBzNUyHoeZTQWGAF2ATfheODOAp4Ee\nwHvApc65D83MgIfwF2l3A990zhUHr/Mt4MfBy/6Pc+6PtQVXVFTkiouL63FYIjko0ZlstoYAbt8e\ndu5MvG/yZPjmN7MTRyLhz2Xduvg4Or/4RXoGoctDZrbIOVeUaF+tbfrOuRFJdp2RoK4DEg4c4pyb\nDEyu7f1EJAOSJXzIrfllL7ssvp7pCd7zlO7IFcmGRGf0uTLRx5AhUUcQF+6dk2zkTWkQJX2RbMjG\nna31lat93usy45ekTElfJBtiE3/EdOoUTRyNyQUX1F5H6kyTqIhkw1tv+eVLL8EJJ0DLltHGE9Mi\nR1NARYXGxc8Qfaoi2TAy6OG8dy907OjHj8kFzz4bdQR+DoCqlPAzRp+sSKaFb4hKNuhZVHIhnhde\niDqCvKKkL5JJy5b5G6LADx4WVXNKsouiudq8IxmjpC+SSW+8EV9fvz55vUyL3fkbc8UV0cQhkVPS\nF8mk666Lr//3f0cXxzPPwM03x7cfe8xPLSh5R0lfJFOqjmo5YUI0cYAfUO3ee2H0aD+DVvPmudMP\nvupNav37RxNHnlCDnkimVB3eIOrhDpo1g/vvjzaGRKqO7nnXXdHEkSd0pi+SLbmYcHNB9+7+r6LY\ndYdcuYehiVLSF8mE8LgxDz4ImzbpDtOa9OgRb24qL482liZOzTsimRAeO//663N3fJtcEjvD37s3\n2jiaOJ3pi6TTjBlw5pnw8st+e+ZMJfxUtWrll0r6GaWkL5IOH38MTz7pZ3165ZV4+de+Fl1Mjc0l\nl/hl1cnRJa3UvCOSDh07Rh1B43fppX6KxNato46kSdOZvkim/PnPUUfQ+CjhZ5ySvkhD3XNP4vKL\nLspuHCIpUPOOSEPddlt83TlYvjy6WERqoaQv0hDhnjlXXumX/fpFE4tICtS8I1JfJSXx9d69YcqU\n6GIRSZGSvkh9lJb6RB+zapX640ujoKQvUh/hhL99ux+1UqQRaFDSN7N1Zva2mS0xs+KgrJOZzTWz\nNcGyY1BuZjbOzErMbJmZDUzHAYhk3c6dUFYWX2/fPtp4ROogHWf6pznn+jvnioLtMcArzrnewCvB\nNsA5QO/gMQoYn4b3Fsm+2PSHkDsTnIukKBPNO+cDsStaU4ALQuWPO+8fQAcz65aB9xfJnI8+gn/8\nw6/v3h1tLCL10NCk74D/M7NFZjYqKDvEObcxWP8PEJsh4XAgPEloaVBWiZmNMrNiMyvesmVLA8MT\nqYfYRdlp0/z2++/DtdfCypXQqZMvu/12OOCA6GIUqaeGJv2vOOcG4pturjezU8I7nXMO/8OQMufc\nROdckXOuqGvXrg0MT6QWu3bBJ5/49auv9sm+sNBvjxgBn/scHHkkTJoEffvGnzd2bNZDFUmHBt2c\n5ZzbECw3m9lzwAnAJjPr5pzbGDTfbA6qbwCOCD29e1AmEo2XXoJzzqm5ztq11cuefRbatMlMTCIZ\nVu8zfTNra2YHxtaBs4DlwCxgZFBtJDAzWJ8FXBX04jkJ2B5qBhLJjvJyPzXf888nTvidOvn9VZP9\nAw/4ZevWfvhkkUaqIWf6hwDPmb8hpQXwpHPuJTN7C3jazK4B3gMuDerPBs4FSoDdwDcb8N4iqSkr\nS63t/dJL/bSGBx8cL/vf/073fuoAAArXSURBVIVu3aCoyHfL/P73MxenSJbUO+k759YCxyco3wac\nkaDcAdfX9/1E6mT/fnjjDXjrrdrrJbuT9vLL0x+XSMQ04Jo0LdddB+NruQXkpptg40aYMEFDJ0je\nUdKXxmvsWHjmGd/FsmVLGDcuecJfuxYqKuDoo7Mbo0iOUdKXxuG22+KTlbRp45ttfvlLv33++TB7\nNtx4Y+Xn3HKLv5nqwAOhV6/sxiuSo5T0JfvWrYPTT4d3302teWXmzMqzU+3eXbnP/Isvwp49vmdN\nly6wfr2abUSSUNKX7IuddTdr5meaqsnSpXDBBTXXASgo8MtLLlHCF6mBhlaW7Fm6FKZOTb1+WRn0\n7x/fXr8eFi3y6wUFMG9e9eccdFDDYhRp4pT0JTt27vQJ/LLLKpeXl1evW14OTzxRuX/9jh3QvTsM\nHOj/Ovj0UzjtNPjpT+N1vvxlGD06M/GLNBFq3pHsqDrm/Lhx/manjz6CrVv9YGZf/7of92blysp1\nV6/2F2MT+dnPfF/7jz6Chx7KTOwiTYiSvmSGc7B3rz9DrzoE8csv+4u44O92ff/9+L6qCX/XrtrH\nubnrrobHK5In1Lwj6ff44/4ibUGBH9agZ09fPmGC/zE44wx4801fFk74Yffe6+tqYDORtNKZvqTX\nvffCmDGJ94UHKps0qfK+ESPgi1+E73xHiV4kg5T0JX1Gj46PRlnVhx9Cx47x7Suv9Bdroebxb0Qk\nrdS8Iw2zdKm/I7a0NJ7wv/pV3zQTfoQTPsBjj/mbtEpLlfBFskhn+lJ3n35avQlm1qz4+lNP1f4a\nzZr5GalEJKt0pi9eRYU/4676+O1vfY+abdviZTW1ueviq0hOU9LPd87Bq69CiyR/9N18sx/npkuX\n6vvmzvVdMp3z7fK1DakgIpFT0m8q9u/3Y9RUPVMfNQo2b078nJNP9s0sp58eLxs/Hq691re3Jxoy\n4bXXYMEC38Rz5pnxm6bULi/SKJjL4bOzoqIiV1xcnNk32b/fN2384hd+erxHH4VTT83se6bDrl0w\ncSLccINPvHv2pPa8Bx+ExYv9RCL9+sXLb701PlRxInv2+EfVO2tFJOeY2SLnXFHCfU026Tvnp8v7\n05/gsMOgXTs4/njYsMGf/ZaVpf5a8+f73idf+II/M67Nzp3Qowd8/DF07eqHFnjtNTj0UBgyxD/a\ntfPJeujQymPMLFjgJ+a+4go/xMBxx8Gzz/phBl580f9A1WT4cJg2zSfxpUvhpZdqrt+zp787NpXj\nEpFGoaakj3MuZx+DBg1y9VJa6tywYVU7DSZ+nHWWXxYVOXfeeak9Z+vW+HvdeWe8vHXr1J6ficfa\ntYk/i4oK55591rk9e5w77bTKzznnnPp9viKS04BilySvNs0umx06wJo1vv/4rbf6LoSTJvkz/nXr\n4IMPoHPn5M+vqPC9VQoKEg/Vm+iiJlRuYmnZ0jcVVVT4gcSWLvWjRx59tJ/iD/yYNO++6/ush119\ntf9r5Etf8tvf/rb/K+Vzn/Pt6Js3Q7duPsbHHoMf/jD5mXqzZvE7YcNDEcd664hIXmm6zTv796e/\nyWLPnvhkHWF33OEfkyb597zqquS9YZJxzifiuj5PRKSKmpp3mm6GyUQbdevWPjlfdJGfjHvoUPjN\nb6BVK7//2mvr/9pmSvgiknFZzzJmNgx4AGgO/ME5V0OXkRz17LNRRyAiUi9Z7bJhZs2Bh4FzgEJg\nhJkVZjMGEZF8lu1+eicAJc65tc65vcA04PwsxyAikreynfQPB9aHtkuDss+Y2SgzKzaz4i1btmQ1\nOBGRpi7n7shxzk10zhU554q6du0adTgiIk1KtpP+BuCI0Hb3oExERLIg20n/LaC3mfUys1bAcGBW\nLc8REZE0yWqXTedcuZndAMzBd9mc7Jxbkc0YRETyWdb76TvnZgOzs/2+IiKS48MwmNkW4L0GvEQX\nYGuawomKjiF3NIXj0DHkjkwex5HOuYQ9YXI66TeUmRUnG3+isdAx5I6mcBw6htwR1XHkXJdNERHJ\nHCV9EZE80tST/sSoA0gDHUPuaArHoWPIHZEcR5Nu0xcRkcqa+pm+iIiEKOmLiOSRJpn0zWyYma02\nsxIzGxN1PGFmdoSZvWpmK81shZndGJR3MrO5ZrYmWHYMys3MxgXHsszMBoZea2RQf42ZjYzgWJqb\n2T/N7Plgu5eZLQxifSoYagMzax1slwT7e4ZeY2xQvtrMzo7gGDqY2XQze8fMVpnZ4Mb2XZjZD4J/\nS8vNbKqZFTSG78LMJpvZZjNbHipL22dvZoPM7O3gOePM0j8pdJJj+HXw72mZmT1nZh1C+xJ+xsly\nVrLvsUGSzZjeWB/44R3eBY4CWgFLgcKo4wrF1w0YGKwfCPwLP6HMr4AxQfkY4N5g/VzgRcCAk4CF\nQXknYG2w7Bisd8zysfwQeBJ4Pth+GhgerE8AvhusXwdMCNaHA08F64XB99Ma6BV8b82zfAxTgGuD\n9VZAh8b0XeCHJv83cEDoO7i6MXwXwCnAQGB5qCxtnz3wZlDXgueek6VjOAtoEazfGzqGhJ8xNeSs\nZN9jg2LOxj/MbD6AwcCc0PZYYGzUcdUQ70xgKLAa6BaUdQNWB+u/B0aE6q8O9o8Afh8qr1QvC3F3\nB14BTgeeD/5jbQ39Y//se8CPtTQ4WG8R1LOq3024XpaO4SB8wrQq5Y3muyA+R0Wn4LN9Hji7sXwX\nQM8qCTMtn32w751QeaV6mTyGKvsuBP4UrCf8jEmSs2r6P9WQR1Ns3ql1opZcEfxpPQBYCBzinNsY\n7PoPcEiwnux4oj7O3wE/AvYH252Bj51z5Qni+SzWYP/2oH7Ux9AL2AL8MWim+oOZtaURfRfOuQ3A\nb4D3gY34z3YRje+7iEnXZ394sF61PNu+hf8rA+p+DDX9n6q3ppj0GwUzawf8GRjtnNsR3uf8z3rO\n9qU1s68Cm51zi6KOpYFa4P80H++cGwDswjcpfKYRfBcd8VOO9gIOA9oCwyINKk1y/bOvjZndBpQD\nf4o6lrCmmPRzfqIWM2uJT/h/cs49GxRvMrNuwf5uwOagPNnxRHmcXwa+Zmbr8PMcnw48AHQws9jI\nreF4Pos12H8QsI3ov6tSoNQ5tzDYno7/EWhM38WZwL+dc1ucc/uAZ/HfT2P7LmLS9dlvCNarlmeF\nmV0NfBW4PPjxgrofwzaSf4/11hSTfk5P1BL0IJgErHLO3RfaNQuI9TwYiW/rj5VfFfReOAnYHvz5\nOwc4y8w6Bmd7ZwVlGeecG+uc6+6c64n/fOc55y4HXgW+nuQYYsf29aC+C8qHBz1KegG98RffssI5\n9x9gvZkdExSdAaykEX0X+Gadk8ysTfBvK3YMjeq7CEnLZx/s22FmJwWfy1Wh18ooMxuGb/r8mnNu\nd2hXss84Yc4Kvpdk32P9ZfpCTRQP/JX+f+GviN8WdTxVYvsK/k/WZcCS4HEuvv3uFWAN8DLQKahv\nwMPBsbwNFIVe61tASfD4ZkTHM4R4752jgn/EJcAzQOugvCDYLgn2HxV6/m3Bsa0mA70rUoi/P1Ac\nfB8z8D1AGtV3AfwMeAdYDjyB7x2S898FMBV/HWIf/q+ua9L52QNFwWfyLvAQVS7YZ/AYSvBt9LH/\n3xNq+4xJkrOSfY8NeWgYBhGRPNIUm3dERCQJJX0RkTyipC8ikkeU9EVE8oiSvohIHlHSFxHJI0r6\nIiJ55P8B9jymEZdtCbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrNtRGatdXDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data, seq_len):\n",
        "    amount_of_features = data.shape[1]\n",
        "    sequence_length = seq_len # index starting from 0\n",
        "    X = []\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
        "    for index in range(data.shape[0] - sequence_length - 2): # maxmimum date = lastest date - sequence length\n",
        "        X.append(data[index: index + sequence_length]) # index : index + 22days\n",
        "        \n",
        "    y = data[seq_len + 2:,3]\n",
        "    X,y = np.array(X), np.array(y)\n",
        "    \n",
        "    X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle=False)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS8-FEnNdZ57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_data(df, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edtZ3nf0AwUf",
        "colab_type": "code",
        "outputId": "ff9e591f-6e1a-400c-b105-97da72b6d40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "df[:26]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00023321, 0.00974497, 0.00957063, 0.00939975],\n",
              "       [0.00045943, 0.00941873, 0.00959348, 0.00961138],\n",
              "       [0.00084026, 0.00963079, 0.00984319, 0.00979045],\n",
              "       [0.00079658, 0.00981022, 0.00992643, 0.00980022],\n",
              "       [0.00059045, 0.00982001, 0.00986277, 0.00973836],\n",
              "       [0.0006446 , 0.00975802, 0.00970609, 0.00966999],\n",
              "       [0.00091537, 0.00968951, 0.0099101 , 0.00991092],\n",
              "       [0.00102455, 0.00993093, 0.01001293, 0.00985882],\n",
              "       [0.00089616, 0.00987873, 0.00992969, 0.00993697],\n",
              "       [0.00093197, 0.00995703, 0.01011901, 0.01001185],\n",
              "       [0.000704  , 0.01003207, 0.01020878, 0.01013558],\n",
              "       [0.00073894, 0.01015605, 0.01027243, 0.01024953],\n",
              "       [0.00095992, 0.01027023, 0.01034914, 0.01025604],\n",
              "       [0.00102368, 0.01027675, 0.01038831, 0.01038954],\n",
              "       [0.00125252, 0.01041052, 0.01065761, 0.01061419],\n",
              "       [0.00102281, 0.01063563, 0.01075553, 0.01074443],\n",
              "       [0.00122632, 0.01076612, 0.01091221, 0.01084536],\n",
              "       [0.00116168, 0.01086726, 0.01069841, 0.01061745],\n",
              "       [0.00100446, 0.01063889, 0.01072452, 0.01072164],\n",
              "       [0.00118963, 0.01074329, 0.01094975, 0.01093978],\n",
              "       [0.00116256, 0.01096187, 0.01113744, 0.0111156 ],\n",
              "       [0.00128309, 0.01113804, 0.0111962 , 0.01111885],\n",
              "       [0.00125252, 0.01114131, 0.01119293, 0.01118397],\n",
              "       [0.0011809 , 0.01120656, 0.01122231, 0.01118072],\n",
              "       [0.00114771, 0.0112033 , 0.01129902, 0.01128165],\n",
              "       [0.00159404, 0.01130443, 0.01142143, 0.01145095]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWmYwk5d_9W7",
        "colab_type": "code",
        "outputId": "f9ba4221-cb45-473b-89a9-b18424f0e678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "X_train[0], y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.00023321, 0.00974497, 0.00957063, 0.00939975],\n",
              "        [0.00045943, 0.00941873, 0.00959348, 0.00961138],\n",
              "        [0.00084026, 0.00963079, 0.00984319, 0.00979045],\n",
              "        [0.00079658, 0.00981022, 0.00992643, 0.00980022],\n",
              "        [0.00059045, 0.00982001, 0.00986277, 0.00973836],\n",
              "        [0.0006446 , 0.00975802, 0.00970609, 0.00966999],\n",
              "        [0.00091537, 0.00968951, 0.0099101 , 0.00991092],\n",
              "        [0.00102455, 0.00993093, 0.01001293, 0.00985882],\n",
              "        [0.00089616, 0.00987873, 0.00992969, 0.00993697],\n",
              "        [0.00093197, 0.00995703, 0.01011901, 0.01001185],\n",
              "        [0.000704  , 0.01003207, 0.01020878, 0.01013558],\n",
              "        [0.00073894, 0.01015605, 0.01027243, 0.01024953],\n",
              "        [0.00095992, 0.01027023, 0.01034914, 0.01025604],\n",
              "        [0.00102368, 0.01027675, 0.01038831, 0.01038954],\n",
              "        [0.00125252, 0.01041052, 0.01065761, 0.01061419],\n",
              "        [0.00102281, 0.01063563, 0.01075553, 0.01074443],\n",
              "        [0.00122632, 0.01076612, 0.01091221, 0.01084536],\n",
              "        [0.00116168, 0.01086726, 0.01069841, 0.01061745],\n",
              "        [0.00100446, 0.01063889, 0.01072452, 0.01072164],\n",
              "        [0.00118963, 0.01074329, 0.01094975, 0.01093978],\n",
              "        [0.00116256, 0.01096187, 0.01113744, 0.0111156 ],\n",
              "        [0.00128309, 0.01113804, 0.0111962 , 0.01111885]]),\n",
              " 0.011281648105074999)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JOwRuTKdbEG",
        "colab_type": "code",
        "outputId": "9097f893-fcbd-478d-a4af-4d76e88d2f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "def build_model2(layers, neurons, d, decay):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[2]), return_sequences=False))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='relu'))        \n",
        "    model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
        "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
        "    adam = keras.optimizers.Adam(decay=decay)\n",
        "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        " \n",
        "model = build_model2(shape, neurons, d, decay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN-fdLoMddRl",
        "colab_type": "code",
        "outputId": "4adff7b7-7426-4a0a-dea7-54df5b5aeceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "history=model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=256,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "5888/8864 [==================>...........] - ETA: 1s - loss: 0.0126 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-280f7d89b243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuH6--JTdhDU",
        "colab_type": "code",
        "outputId": "4d9bbb97-7df5-4ee4-881f-d0c144711ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWQAwxhif+v/o1wuWta6eBAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5BQE0jXmoBO",
        "colab_type": "code",
        "outputId": "549238b2-7e8a-45a2-f939-303bcadc8bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "import matplotlib.pyplot as plt2\n",
        "predicted_result = model.predict(X_test)\n",
        "\n",
        "plt2.plot(predicted_result[-90:], color='red', label='Prediction')\n",
        "plt2.plot(y_test[-90:],color='blue', label='Actual')\n",
        "plt2.legend(loc='best')\n",
        "plt2.title('The test result for {}'.format(stock_name))\n",
        "plt2.xlabel('Days')\n",
        "plt2.ylabel('Adjusted Close')\n",
        "plt2.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e923a17fea6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUVfyZmlnBw2",
        "colab_type": "code",
        "outputId": "cc2a8918-376b-4e6d-ba10-1cdbd6d2d73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "def model_score(model, X_train, y_train, X_test, y_test):\n",
        "#X_testy_testX_trainy_train    \n",
        "    y_hat = model.predict(X_test)\n",
        "    y_t=y_test.reshape(-1,1)\n",
        "    \n",
        "    temp = pd.DataFrame(y_hat)  \n",
        "    temp['yhat']=y_hat\n",
        "    temp['y']=y_t\n",
        "    temp_rmse = sqrt(mean_squared_error(temp.y,temp.yhat))\n",
        "    temp_mse=mean_squared_error(temp.y,temp.yhat)\n",
        "    print('TEMP RMSE: %.3f' % temp_rmse)\n",
        "    print('TEMP MSE: %.3f' % temp_mse)\n",
        "    return temp_rmse,temp_mse\n",
        " \n",
        "model_score(model, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "TEMP RMSE: 0.645\n",
            "TEMP MSE: 0.416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6449108362520832, 0.41590998671536134)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kshW4IxUDF2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay):\n",
        "    df = get_stock_data(stock_name)\n",
        "    X_train, X_test, y_train, y_test = load_data(df, seq_len)\n",
        "    model = build_model2(shape, neurons, d, decay)\n",
        "    model.fit(X_train, y_train, batch_size=512, epochs=epochs, validation_split=0.1, verbose=1)\n",
        "    # model.save('LSTM_Stock_prediction-20170429.h5')\n",
        "    trainScore, testScore = model_score(model, X_train, y_train, X_test, y_test)\n",
        "    return trainScore, testScore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XGndmmIDXnV",
        "colab_type": "code",
        "outputId": "f7ca5f13-3ca8-4e66-a47e-4f79d6ad1f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dlist = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "neurons_LSTM = [32, 64, 128, 256, 512, 1024, 2048]\n",
        "dropout_result = {}\n",
        " \n",
        "for d in dlist:    \n",
        "    trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
        "    dropout_result[d] = testScore\n",
        " \n",
        "min_val = min(dropout_result.values())\n",
        "min_val_key = [k for k, v in dropout_result.items() if v == min_val]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 3s 342us/step - loss: 0.0142 - acc: 1.1282e-04 - val_loss: 0.0079 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.2613e-04 - acc: 1.1282e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.4742e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.8439e-04 - acc: 1.1282e-04 - val_loss: 8.0721e-04 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.3993e-04 - acc: 1.1282e-04 - val_loss: 5.3158e-04 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.2760e-04 - acc: 1.1282e-04 - val_loss: 4.2631e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1993e-04 - acc: 1.1282e-04 - val_loss: 3.0502e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0719e-04 - acc: 1.1282e-04 - val_loss: 3.9062e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0376e-04 - acc: 1.1282e-04 - val_loss: 3.9768e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0627e-04 - acc: 1.1282e-04 - val_loss: 5.6053e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 1.0050e-04 - acc: 1.1282e-04 - val_loss: 3.8251e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.6301e-05 - acc: 1.1282e-04 - val_loss: 3.4492e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.3203e-05 - acc: 1.1282e-04 - val_loss: 4.1531e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.6971e-05 - acc: 1.1282e-04 - val_loss: 2.3214e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1543e-04 - acc: 1.1282e-04 - val_loss: 5.0749e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0941e-04 - acc: 1.1282e-04 - val_loss: 2.5250e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.1405e-05 - acc: 1.1282e-04 - val_loss: 3.2556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.2282e-05 - acc: 1.1282e-04 - val_loss: 2.2656e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0046e-04 - acc: 1.1282e-04 - val_loss: 3.5749e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.9506e-05 - acc: 1.1282e-04 - val_loss: 2.2120e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.7778e-05 - acc: 1.1282e-04 - val_loss: 2.5446e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.4696e-05 - acc: 1.1282e-04 - val_loss: 4.3777e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.3843e-05 - acc: 1.1282e-04 - val_loss: 3.7635e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.3884e-05 - acc: 1.1282e-04 - val_loss: 2.2568e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.4239e-05 - acc: 1.1282e-04 - val_loss: 2.3679e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 8.4728e-05 - acc: 1.1282e-04 - val_loss: 2.1607e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 8.2676e-05 - acc: 1.1282e-04 - val_loss: 2.4126e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.9879e-05 - acc: 1.1282e-04 - val_loss: 2.0385e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.9394e-05 - acc: 1.1282e-04 - val_loss: 2.0831e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 8.0373e-05 - acc: 1.1282e-04 - val_loss: 1.9556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.5888e-05 - acc: 1.1282e-04 - val_loss: 2.0410e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 9.0340e-05 - acc: 1.1282e-04 - val_loss: 4.6114e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 8.4351e-05 - acc: 1.1282e-04 - val_loss: 3.0914e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.4508e-05 - acc: 1.1282e-04 - val_loss: 2.4810e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.0571e-05 - acc: 1.1282e-04 - val_loss: 1.9552e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.5931e-05 - acc: 1.1282e-04 - val_loss: 1.8558e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.9270e-05 - acc: 1.1282e-04 - val_loss: 6.5052e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0237e-04 - acc: 1.1282e-04 - val_loss: 1.9102e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.9807e-05 - acc: 1.1282e-04 - val_loss: 1.8243e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.7309e-05 - acc: 1.1282e-04 - val_loss: 2.3525e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 8.0851e-05 - acc: 1.1282e-04 - val_loss: 1.8968e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.9587e-05 - acc: 1.1282e-04 - val_loss: 1.7972e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.1662e-05 - acc: 1.1282e-04 - val_loss: 1.8691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.3049e-05 - acc: 1.1282e-04 - val_loss: 2.5820e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.7770e-05 - acc: 1.1282e-04 - val_loss: 1.8751e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.9073e-05 - acc: 1.1282e-04 - val_loss: 7.9604e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.9931e-05 - acc: 1.1282e-04 - val_loss: 2.6242e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.4539e-05 - acc: 1.1282e-04 - val_loss: 2.8129e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.5153e-05 - acc: 1.1282e-04 - val_loss: 4.3145e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.8566e-05 - acc: 1.1282e-04 - val_loss: 2.0232e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0230e-04 - acc: 1.1282e-04 - val_loss: 1.7365e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.2367e-05 - acc: 1.1282e-04 - val_loss: 2.6043e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.3398e-05 - acc: 1.1282e-04 - val_loss: 1.6423e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.3452e-05 - acc: 1.1282e-04 - val_loss: 3.9598e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 7.0985e-05 - acc: 1.1282e-04 - val_loss: 1.6658e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.2916e-05 - acc: 1.1282e-04 - val_loss: 1.8078e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.5552e-05 - acc: 1.1282e-04 - val_loss: 4.9860e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.4377e-05 - acc: 1.1282e-04 - val_loss: 1.5960e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.3887e-05 - acc: 1.1282e-04 - val_loss: 5.4039e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.9602e-05 - acc: 1.1282e-04 - val_loss: 1.5874e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.6353e-05 - acc: 1.1282e-04 - val_loss: 1.6283e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.7022e-05 - acc: 1.1282e-04 - val_loss: 3.2471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.9415e-05 - acc: 1.1282e-04 - val_loss: 1.5865e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.4690e-05 - acc: 1.1282e-04 - val_loss: 1.9597e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.7182e-05 - acc: 1.1282e-04 - val_loss: 1.6051e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.9034e-05 - acc: 1.1282e-04 - val_loss: 1.5011e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.4200e-05 - acc: 1.1282e-04 - val_loss: 1.6269e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.6847e-05 - acc: 1.1282e-04 - val_loss: 1.5754e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.5873e-05 - acc: 1.1282e-04 - val_loss: 2.3784e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.4649e-05 - acc: 1.1282e-04 - val_loss: 1.6229e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.5737e-05 - acc: 1.1282e-04 - val_loss: 1.5759e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.1884e-05 - acc: 1.1282e-04 - val_loss: 2.3497e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.1963e-05 - acc: 1.1282e-04 - val_loss: 1.9321e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.4789e-05 - acc: 1.1282e-04 - val_loss: 2.9532e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.9398e-05 - acc: 1.1282e-04 - val_loss: 2.7653e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.9327e-05 - acc: 1.1282e-04 - val_loss: 1.7987e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.6807e-05 - acc: 1.1282e-04 - val_loss: 1.4302e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 6.5096e-05 - acc: 1.1282e-04 - val_loss: 5.5144e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 9.5924e-05 - acc: 1.1282e-04 - val_loss: 1.6674e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.4926e-05 - acc: 1.1282e-04 - val_loss: 2.1989e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.7315e-05 - acc: 1.1282e-04 - val_loss: 1.5965e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.2125e-05 - acc: 1.1282e-04 - val_loss: 1.3644e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.5848e-05 - acc: 1.1282e-04 - val_loss: 1.6325e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.1150e-05 - acc: 1.1282e-04 - val_loss: 1.3519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.7138e-05 - acc: 1.1282e-04 - val_loss: 1.4213e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.4100e-05 - acc: 1.1282e-04 - val_loss: 1.3423e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9604e-05 - acc: 1.1282e-04 - val_loss: 2.8174e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.2750e-05 - acc: 1.1282e-04 - val_loss: 1.3255e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.8848e-05 - acc: 1.1282e-04 - val_loss: 2.3132e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9858e-05 - acc: 1.1282e-04 - val_loss: 1.3162e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.2600e-05 - acc: 1.1282e-04 - val_loss: 2.2800e-04 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.2055e-05 - acc: 1.1282e-04 - val_loss: 1.4516e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.2411e-05 - acc: 1.1282e-04 - val_loss: 1.4066e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.8167e-05 - acc: 1.1282e-04 - val_loss: 1.4276e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.3031e-05 - acc: 1.1282e-04 - val_loss: 1.5342e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.1219e-05 - acc: 1.1282e-04 - val_loss: 1.8839e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.0072e-05 - acc: 1.1282e-04 - val_loss: 2.3166e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.7681e-05 - acc: 1.1282e-04 - val_loss: 1.5357e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.4221e-05 - acc: 1.1282e-04 - val_loss: 1.9718e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.4062e-05 - acc: 1.1282e-04 - val_loss: 3.0611e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.3756e-05 - acc: 1.1282e-04 - val_loss: 2.0370e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.0382e-05 - acc: 1.1282e-04 - val_loss: 1.2732e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.5703e-05 - acc: 1.1282e-04 - val_loss: 2.4540e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.7043e-05 - acc: 1.1282e-04 - val_loss: 1.3242e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.2195e-05 - acc: 1.1282e-04 - val_loss: 1.2816e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.0689e-05 - acc: 1.1282e-04 - val_loss: 1.2464e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.7890e-05 - acc: 1.1282e-04 - val_loss: 1.2831e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.6840e-05 - acc: 1.1282e-04 - val_loss: 1.5652e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6972e-05 - acc: 1.1282e-04 - val_loss: 1.8992e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.3035e-05 - acc: 1.1282e-04 - val_loss: 1.3757e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.9231e-05 - acc: 1.1282e-04 - val_loss: 1.2294e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.4248e-05 - acc: 1.1282e-04 - val_loss: 1.7315e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.7611e-05 - acc: 1.1282e-04 - val_loss: 1.3307e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.6793e-05 - acc: 1.1282e-04 - val_loss: 1.4556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.6193e-05 - acc: 1.1282e-04 - val_loss: 2.0187e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6663e-05 - acc: 1.1282e-04 - val_loss: 1.9008e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.2034e-05 - acc: 1.1282e-04 - val_loss: 1.6502e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.7177e-05 - acc: 1.1282e-04 - val_loss: 1.2114e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.6467e-05 - acc: 1.1282e-04 - val_loss: 1.3600e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.6111e-05 - acc: 1.1282e-04 - val_loss: 1.2816e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.5122e-05 - acc: 1.1282e-04 - val_loss: 1.6405e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 5.7337e-05 - acc: 1.1282e-04 - val_loss: 1.2377e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.3329e-05 - acc: 1.1282e-04 - val_loss: 1.5903e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.2283e-05 - acc: 1.1282e-04 - val_loss: 1.3189e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.4086e-05 - acc: 1.1282e-04 - val_loss: 1.4287e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.3579e-05 - acc: 1.1282e-04 - val_loss: 1.4061e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7352e-05 - acc: 1.1282e-04 - val_loss: 1.3366e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.1031e-05 - acc: 1.1282e-04 - val_loss: 1.2196e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7365e-05 - acc: 1.1282e-04 - val_loss: 1.3297e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.0774e-05 - acc: 1.1282e-04 - val_loss: 1.1971e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.6779e-05 - acc: 1.1282e-04 - val_loss: 1.6133e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.6660e-05 - acc: 1.1282e-04 - val_loss: 1.2354e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.6005e-05 - acc: 1.1282e-04 - val_loss: 2.1500e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.1900e-05 - acc: 1.1282e-04 - val_loss: 1.3705e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.3759e-05 - acc: 1.1282e-04 - val_loss: 1.2313e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.1786e-05 - acc: 1.1282e-04 - val_loss: 1.2840e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.6970e-05 - acc: 1.1282e-04 - val_loss: 1.2458e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.5927e-05 - acc: 1.1282e-04 - val_loss: 2.6683e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.5497e-05 - acc: 1.1282e-04 - val_loss: 2.4642e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.2746e-05 - acc: 1.1282e-04 - val_loss: 1.9696e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.5983e-05 - acc: 1.1282e-04 - val_loss: 1.1797e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.1906e-05 - acc: 1.1282e-04 - val_loss: 1.4785e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.3716e-05 - acc: 1.1282e-04 - val_loss: 1.6826e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.4687e-05 - acc: 1.1282e-04 - val_loss: 1.3201e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.8170e-05 - acc: 1.1282e-04 - val_loss: 1.4229e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.0895e-05 - acc: 1.1282e-04 - val_loss: 1.1910e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 5.0530e-05 - acc: 1.1282e-04 - val_loss: 1.2776e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.4684e-05 - acc: 1.1282e-04 - val_loss: 1.1989e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.3105e-05 - acc: 1.1282e-04 - val_loss: 1.8766e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.4389e-05 - acc: 1.1282e-04 - val_loss: 1.4161e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.8974e-05 - acc: 1.1282e-04 - val_loss: 2.3521e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.9392e-05 - acc: 1.1282e-04 - val_loss: 1.8339e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6286e-05 - acc: 1.1282e-04 - val_loss: 1.3552e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.9621e-05 - acc: 1.1282e-04 - val_loss: 1.3610e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.6540e-05 - acc: 1.1282e-04 - val_loss: 1.1485e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.9741e-05 - acc: 1.1282e-04 - val_loss: 1.1620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.9043e-05 - acc: 1.1282e-04 - val_loss: 1.7644e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.1464e-05 - acc: 1.1282e-04 - val_loss: 1.1969e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.0268e-05 - acc: 1.1282e-04 - val_loss: 1.3175e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.2523e-05 - acc: 1.1282e-04 - val_loss: 1.1572e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.6527e-05 - acc: 1.1282e-04 - val_loss: 1.5237e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.8268e-05 - acc: 1.1282e-04 - val_loss: 1.2093e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0405e-05 - acc: 1.1282e-04 - val_loss: 1.1546e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.2131e-05 - acc: 1.1282e-04 - val_loss: 1.2183e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.9507e-05 - acc: 1.1282e-04 - val_loss: 2.0393e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.3083e-05 - acc: 1.1282e-04 - val_loss: 1.1491e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.7676e-05 - acc: 1.1282e-04 - val_loss: 1.4566e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.0511e-05 - acc: 1.1282e-04 - val_loss: 1.3180e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.8157e-05 - acc: 1.1282e-04 - val_loss: 1.1067e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.1032e-05 - acc: 1.1282e-04 - val_loss: 1.4092e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 5.1889e-05 - acc: 1.1282e-04 - val_loss: 1.1774e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.6411e-05 - acc: 1.1282e-04 - val_loss: 1.3299e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.6055e-05 - acc: 1.1282e-04 - val_loss: 1.1469e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.4573e-05 - acc: 1.1282e-04 - val_loss: 1.1738e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.0342e-05 - acc: 1.1282e-04 - val_loss: 1.3766e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.8460e-05 - acc: 1.1282e-04 - val_loss: 1.5271e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.6013e-05 - acc: 1.1282e-04 - val_loss: 1.1054e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.6767e-05 - acc: 1.1282e-04 - val_loss: 1.1991e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.8680e-05 - acc: 1.1282e-04 - val_loss: 1.4058e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.6880e-05 - acc: 1.1282e-04 - val_loss: 1.0937e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.9549e-05 - acc: 1.1282e-04 - val_loss: 1.1155e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.9108e-05 - acc: 1.1282e-04 - val_loss: 1.1030e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.7942e-05 - acc: 1.1282e-04 - val_loss: 1.7642e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.3083e-05 - acc: 1.1282e-04 - val_loss: 1.2080e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.7728e-05 - acc: 1.1282e-04 - val_loss: 1.0901e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.6643e-05 - acc: 1.1282e-04 - val_loss: 1.2131e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.6795e-05 - acc: 1.1282e-04 - val_loss: 1.1581e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.1829e-05 - acc: 1.1282e-04 - val_loss: 1.2008e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.8392e-05 - acc: 1.1282e-04 - val_loss: 1.4332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.7567e-05 - acc: 1.1282e-04 - val_loss: 2.3361e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.1299e-05 - acc: 1.1282e-04 - val_loss: 1.7033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.7905e-05 - acc: 1.1282e-04 - val_loss: 1.2665e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.3336e-05 - acc: 1.1282e-04 - val_loss: 1.0636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.3649e-05 - acc: 1.1282e-04 - val_loss: 1.2071e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.5506e-05 - acc: 1.1282e-04 - val_loss: 1.2209e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.7026e-05 - acc: 1.1282e-04 - val_loss: 1.1379e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.6682e-05 - acc: 1.1282e-04 - val_loss: 1.4832e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0245e-05 - acc: 1.1282e-04 - val_loss: 1.5110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.9121e-05 - acc: 1.1282e-04 - val_loss: 1.7377e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.5608e-05 - acc: 1.1282e-04 - val_loss: 1.0630e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.6780e-05 - acc: 1.1282e-04 - val_loss: 1.4629e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.6418e-05 - acc: 1.1282e-04 - val_loss: 1.3841e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9079e-05 - acc: 1.1282e-04 - val_loss: 1.1570e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.2767e-05 - acc: 1.1282e-04 - val_loss: 3.0157e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.1402e-05 - acc: 1.1282e-04 - val_loss: 1.4289e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.2035e-05 - acc: 1.1282e-04 - val_loss: 1.1215e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.6961e-05 - acc: 1.1282e-04 - val_loss: 1.4626e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.5564e-05 - acc: 1.1282e-04 - val_loss: 1.2857e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.5772e-05 - acc: 1.1282e-04 - val_loss: 1.2375e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.8161e-05 - acc: 1.1282e-04 - val_loss: 1.4316e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.7986e-05 - acc: 1.1282e-04 - val_loss: 2.3255e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.1550e-05 - acc: 1.1282e-04 - val_loss: 2.1739e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.3601e-05 - acc: 1.1282e-04 - val_loss: 1.1624e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.6479e-05 - acc: 1.1282e-04 - val_loss: 1.1589e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.5962e-05 - acc: 1.1282e-04 - val_loss: 1.3399e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.5692e-05 - acc: 1.1282e-04 - val_loss: 1.5225e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.6960e-05 - acc: 1.1282e-04 - val_loss: 1.0232e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.4657e-05 - acc: 1.1282e-04 - val_loss: 1.0288e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.2615e-05 - acc: 1.1282e-04 - val_loss: 1.3298e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.5494e-05 - acc: 1.1282e-04 - val_loss: 1.9531e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.8727e-05 - acc: 1.1282e-04 - val_loss: 1.1171e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.2323e-05 - acc: 1.1282e-04 - val_loss: 1.1835e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.5104e-05 - acc: 1.1282e-04 - val_loss: 1.0559e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.3631e-05 - acc: 1.1282e-04 - val_loss: 1.3965e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.9364e-05 - acc: 1.1282e-04 - val_loss: 1.2974e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.9117e-05 - acc: 1.1282e-04 - val_loss: 1.2176e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.0701e-05 - acc: 1.1282e-04 - val_loss: 2.2154e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.3986e-05 - acc: 1.1282e-04 - val_loss: 1.7082e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.7667e-05 - acc: 1.1282e-04 - val_loss: 1.1425e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.1439e-05 - acc: 1.1282e-04 - val_loss: 1.1856e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.6933e-05 - acc: 1.1282e-04 - val_loss: 1.0973e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.2440e-05 - acc: 1.1282e-04 - val_loss: 1.0411e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.3118e-05 - acc: 1.1282e-04 - val_loss: 1.0395e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.4408e-05 - acc: 1.1282e-04 - val_loss: 2.0377e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.4552e-05 - acc: 1.1282e-04 - val_loss: 1.0007e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.0514e-05 - acc: 1.1282e-04 - val_loss: 1.7888e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.4919e-05 - acc: 1.1282e-04 - val_loss: 1.0600e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.2199e-05 - acc: 1.1282e-04 - val_loss: 1.4198e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.9727e-05 - acc: 1.1282e-04 - val_loss: 1.7455e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.7677e-05 - acc: 1.1282e-04 - val_loss: 1.0664e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.2756e-05 - acc: 1.1282e-04 - val_loss: 1.0326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.0659e-05 - acc: 1.1282e-04 - val_loss: 1.2021e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.1469e-05 - acc: 1.1282e-04 - val_loss: 1.1773e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.3033e-05 - acc: 1.1282e-04 - val_loss: 9.8223e-05 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.8862e-05 - acc: 1.1282e-04 - val_loss: 1.1039e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.3365e-05 - acc: 1.1282e-04 - val_loss: 1.2073e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.9746e-05 - acc: 1.1282e-04 - val_loss: 1.5353e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.4139e-05 - acc: 1.1282e-04 - val_loss: 1.1623e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.2017e-05 - acc: 1.1282e-04 - val_loss: 1.1466e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.1486e-05 - acc: 1.1282e-04 - val_loss: 1.5835e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.3649e-05 - acc: 1.1282e-04 - val_loss: 1.0052e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.0647e-05 - acc: 1.1282e-04 - val_loss: 1.2651e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.1115e-05 - acc: 1.1282e-04 - val_loss: 1.0735e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.1020e-05 - acc: 1.1282e-04 - val_loss: 1.8113e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.8870e-05 - acc: 1.1282e-04 - val_loss: 1.1871e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9620e-05 - acc: 1.1282e-04 - val_loss: 9.8892e-05 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.2614e-05 - acc: 1.1282e-04 - val_loss: 1.6492e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.4192e-05 - acc: 1.1282e-04 - val_loss: 1.0652e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.5577e-05 - acc: 1.1282e-04 - val_loss: 1.0005e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.2474e-05 - acc: 1.1282e-04 - val_loss: 1.1243e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.9205e-05 - acc: 1.1282e-04 - val_loss: 1.0827e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.9440e-05 - acc: 1.1282e-04 - val_loss: 1.5697e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.1761e-05 - acc: 1.1282e-04 - val_loss: 1.2558e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.2733e-05 - acc: 1.1282e-04 - val_loss: 9.6771e-05 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.2002e-05 - acc: 1.1282e-04 - val_loss: 1.0490e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.4810e-05 - acc: 1.1282e-04 - val_loss: 1.1341e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.1052e-05 - acc: 1.1282e-04 - val_loss: 1.2161e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.3876e-05 - acc: 1.1282e-04 - val_loss: 1.1434e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.0500e-05 - acc: 1.1282e-04 - val_loss: 9.9099e-05 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.0886e-05 - acc: 1.1282e-04 - val_loss: 9.7466e-05 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.8151e-05 - acc: 1.1282e-04 - val_loss: 1.4130e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.8717e-05 - acc: 1.1282e-04 - val_loss: 9.6393e-05 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.5205e-05 - acc: 1.1282e-04 - val_loss: 1.8428e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.1936e-05 - acc: 1.1282e-04 - val_loss: 1.4161e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.0535e-05 - acc: 1.1282e-04 - val_loss: 9.6816e-05 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.0423e-05 - acc: 1.1282e-04 - val_loss: 9.8173e-05 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.9811e-05 - acc: 1.1282e-04 - val_loss: 1.1045e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.1169e-05 - acc: 1.1282e-04 - val_loss: 1.1182e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.0900e-05 - acc: 1.1282e-04 - val_loss: 9.1982e-05 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.9384e-05 - acc: 1.1282e-04 - val_loss: 1.1748e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.9706e-05 - acc: 1.1282e-04 - val_loss: 1.0576e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.8890e-05 - acc: 1.1282e-04 - val_loss: 1.0026e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.7335e-05 - acc: 1.1282e-04 - val_loss: 1.2128e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.8553e-05 - acc: 1.1282e-04 - val_loss: 1.0940e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 3.6934e-05 - acc: 1.1282e-04 - val_loss: 1.0408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.9190e-05 - acc: 1.1282e-04 - val_loss: 9.3348e-05 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.0766e-05 - acc: 1.1282e-04 - val_loss: 1.0128e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.8931e-05 - acc: 1.1282e-04 - val_loss: 1.3543e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.9123e-05 - acc: 1.1282e-04 - val_loss: 1.0723e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.6374e-05 - acc: 1.1282e-04 - val_loss: 9.4290e-05 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.0493e-05 - acc: 1.1282e-04 - val_loss: 1.2823e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.1092e-05 - acc: 1.1282e-04 - val_loss: 9.7961e-05 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.7455e-05 - acc: 1.1282e-04 - val_loss: 1.0713e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.1757e-05 - acc: 1.1282e-04 - val_loss: 1.1522e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.0453e-05 - acc: 1.1282e-04 - val_loss: 1.0064e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.7621e-05 - acc: 1.1282e-04 - val_loss: 1.3676e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.9477e-05 - acc: 1.1282e-04 - val_loss: 1.0712e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.1756e-05 - acc: 1.1282e-04 - val_loss: 1.1723e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.2780e-05 - acc: 1.1282e-04 - val_loss: 1.0390e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.1234e-05 - acc: 1.1282e-04 - val_loss: 1.0319e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.036\n",
            "TEMP MSE: 0.001\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_11 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 3s 376us/step - loss: 0.0174 - acc: 1.1282e-04 - val_loss: 0.0086 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.2103e-04 - acc: 1.1282e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.4599e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.9800e-04 - acc: 1.1282e-04 - val_loss: 6.4277e-04 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.6389e-04 - acc: 1.1282e-04 - val_loss: 6.4047e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.5068e-04 - acc: 1.1282e-04 - val_loss: 3.3178e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4953e-04 - acc: 1.1282e-04 - val_loss: 2.6942e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.4362e-04 - acc: 1.1282e-04 - val_loss: 3.9425e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4234e-04 - acc: 1.1282e-04 - val_loss: 2.7932e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4065e-04 - acc: 1.1282e-04 - val_loss: 2.5559e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2688e-04 - acc: 1.1282e-04 - val_loss: 3.2671e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2366e-04 - acc: 1.1282e-04 - val_loss: 3.0164e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2882e-04 - acc: 1.1282e-04 - val_loss: 3.1605e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 157us/step - loss: 1.2977e-04 - acc: 1.1282e-04 - val_loss: 2.4383e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1774e-04 - acc: 1.1282e-04 - val_loss: 2.4237e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3600e-04 - acc: 1.1282e-04 - val_loss: 2.4796e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1603e-04 - acc: 1.1282e-04 - val_loss: 3.2208e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.2506e-04 - acc: 1.1282e-04 - val_loss: 4.3200e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1820e-04 - acc: 1.1282e-04 - val_loss: 4.7307e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3756e-04 - acc: 1.1282e-04 - val_loss: 6.2640e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.2650e-04 - acc: 1.1282e-04 - val_loss: 4.4080e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1493e-04 - acc: 1.1282e-04 - val_loss: 3.9974e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2909e-04 - acc: 1.1282e-04 - val_loss: 3.0365e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.1521e-04 - acc: 1.1282e-04 - val_loss: 2.3478e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0662e-04 - acc: 1.1282e-04 - val_loss: 2.3795e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2401e-04 - acc: 1.1282e-04 - val_loss: 2.2925e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1740e-04 - acc: 1.1282e-04 - val_loss: 2.6738e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1745e-04 - acc: 1.1282e-04 - val_loss: 2.1902e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.1114e-04 - acc: 1.1282e-04 - val_loss: 2.2080e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.0316e-04 - acc: 1.1282e-04 - val_loss: 3.9963e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2926e-04 - acc: 1.1282e-04 - val_loss: 2.5627e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0467e-04 - acc: 1.1282e-04 - val_loss: 2.3692e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0645e-04 - acc: 1.1282e-04 - val_loss: 2.3295e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0043e-04 - acc: 1.1282e-04 - val_loss: 3.2193e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0442e-04 - acc: 1.1282e-04 - val_loss: 3.0927e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0355e-04 - acc: 1.1282e-04 - val_loss: 3.0774e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1013e-04 - acc: 1.1282e-04 - val_loss: 2.5188e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1601e-04 - acc: 1.1282e-04 - val_loss: 2.6783e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1654e-04 - acc: 1.1282e-04 - val_loss: 4.1228e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2713e-04 - acc: 1.1282e-04 - val_loss: 2.8483e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0622e-04 - acc: 1.1282e-04 - val_loss: 2.3301e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1962e-04 - acc: 1.1282e-04 - val_loss: 2.1816e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2264e-04 - acc: 1.1282e-04 - val_loss: 2.7110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0132e-04 - acc: 1.1282e-04 - val_loss: 2.3538e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 9.7472e-05 - acc: 1.1282e-04 - val_loss: 2.3072e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.7668e-05 - acc: 1.1282e-04 - val_loss: 1.9192e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0038e-04 - acc: 1.1282e-04 - val_loss: 3.0402e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.5896e-05 - acc: 1.1282e-04 - val_loss: 2.3773e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0999e-04 - acc: 1.1282e-04 - val_loss: 2.0460e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1689e-04 - acc: 1.1282e-04 - val_loss: 3.3462e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0482e-04 - acc: 1.1282e-04 - val_loss: 2.7663e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1249e-04 - acc: 1.1282e-04 - val_loss: 1.9627e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0569e-04 - acc: 1.1282e-04 - val_loss: 3.7800e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0050e-04 - acc: 1.1282e-04 - val_loss: 2.7078e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0507e-04 - acc: 1.1282e-04 - val_loss: 2.5402e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.0139e-04 - acc: 1.1282e-04 - val_loss: 1.8363e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.3231e-05 - acc: 1.1282e-04 - val_loss: 2.7201e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2070e-04 - acc: 1.1282e-04 - val_loss: 3.6191e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.7600e-05 - acc: 1.1282e-04 - val_loss: 1.7863e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.8720e-05 - acc: 1.1282e-04 - val_loss: 1.8619e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.1839e-05 - acc: 1.1282e-04 - val_loss: 4.2076e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.7805e-05 - acc: 1.1282e-04 - val_loss: 1.9893e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.2807e-05 - acc: 1.1282e-04 - val_loss: 2.8254e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.5670e-05 - acc: 1.1282e-04 - val_loss: 4.4915e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.8312e-05 - acc: 1.1282e-04 - val_loss: 1.8306e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.1744e-05 - acc: 1.1282e-04 - val_loss: 4.2299e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0128e-04 - acc: 1.1282e-04 - val_loss: 2.6148e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0367e-04 - acc: 1.1282e-04 - val_loss: 2.0838e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.1243e-05 - acc: 1.1282e-04 - val_loss: 2.4196e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.0672e-05 - acc: 1.1282e-04 - val_loss: 2.6940e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.6374e-05 - acc: 1.1282e-04 - val_loss: 1.8359e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.4251e-05 - acc: 1.1282e-04 - val_loss: 2.0328e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.7806e-05 - acc: 1.1282e-04 - val_loss: 1.7309e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.8617e-05 - acc: 1.1282e-04 - val_loss: 1.7154e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1018e-04 - acc: 1.1282e-04 - val_loss: 4.2854e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0037e-04 - acc: 1.1282e-04 - val_loss: 1.6500e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.8076e-05 - acc: 1.1282e-04 - val_loss: 1.7861e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0633e-04 - acc: 1.1282e-04 - val_loss: 3.3534e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0195e-04 - acc: 1.1282e-04 - val_loss: 1.6724e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.5808e-05 - acc: 1.1282e-04 - val_loss: 2.0310e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.6757e-05 - acc: 1.1282e-04 - val_loss: 1.9511e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.8344e-05 - acc: 1.1282e-04 - val_loss: 2.2005e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1060e-04 - acc: 1.1282e-04 - val_loss: 3.4426e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.1297e-04 - acc: 1.1282e-04 - val_loss: 1.6197e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.2431e-05 - acc: 1.1282e-04 - val_loss: 2.4671e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 8.6284e-05 - acc: 1.1282e-04 - val_loss: 1.5786e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.1640e-05 - acc: 1.1282e-04 - val_loss: 2.9586e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.1626e-05 - acc: 1.1282e-04 - val_loss: 2.2459e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.4257e-05 - acc: 1.1282e-04 - val_loss: 1.8285e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.1117e-05 - acc: 1.1282e-04 - val_loss: 2.1884e-04 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.1378e-05 - acc: 1.1282e-04 - val_loss: 2.1824e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.1098e-05 - acc: 1.1282e-04 - val_loss: 1.7555e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.8429e-05 - acc: 1.1282e-04 - val_loss: 1.4921e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.3470e-05 - acc: 1.1282e-04 - val_loss: 3.6058e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.0887e-05 - acc: 1.1282e-04 - val_loss: 1.9824e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 8.0243e-05 - acc: 1.1282e-04 - val_loss: 1.5404e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.9426e-05 - acc: 1.1282e-04 - val_loss: 2.2525e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.4003e-05 - acc: 1.1282e-04 - val_loss: 2.0843e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.8599e-05 - acc: 1.1282e-04 - val_loss: 2.1792e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.9713e-05 - acc: 1.1282e-04 - val_loss: 4.8152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.2696e-05 - acc: 1.1282e-04 - val_loss: 1.5931e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.5695e-05 - acc: 1.1282e-04 - val_loss: 1.4483e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.2892e-05 - acc: 1.1282e-04 - val_loss: 2.1351e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 8.2558e-05 - acc: 1.1282e-04 - val_loss: 2.4615e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.4874e-05 - acc: 1.1282e-04 - val_loss: 1.4352e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.3418e-05 - acc: 1.1282e-04 - val_loss: 1.4566e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.6909e-05 - acc: 1.1282e-04 - val_loss: 1.8822e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.4527e-05 - acc: 1.1282e-04 - val_loss: 1.4988e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6807e-05 - acc: 1.1282e-04 - val_loss: 1.5965e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.7250e-05 - acc: 1.1282e-04 - val_loss: 1.7633e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.7272e-05 - acc: 1.1282e-04 - val_loss: 1.9025e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.3561e-05 - acc: 1.1282e-04 - val_loss: 1.4303e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.1605e-05 - acc: 1.1282e-04 - val_loss: 5.7751e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1402e-04 - acc: 1.1282e-04 - val_loss: 5.9582e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 9.2461e-05 - acc: 1.1282e-04 - val_loss: 5.9654e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.2784e-05 - acc: 1.1282e-04 - val_loss: 1.3998e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.3880e-05 - acc: 1.1282e-04 - val_loss: 1.4640e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.7391e-05 - acc: 1.1282e-04 - val_loss: 1.4955e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.8233e-05 - acc: 1.1282e-04 - val_loss: 1.3705e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.2128e-05 - acc: 1.1282e-04 - val_loss: 1.8952e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.2434e-05 - acc: 1.1282e-04 - val_loss: 1.3715e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.4399e-05 - acc: 1.1282e-04 - val_loss: 1.3678e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.6716e-05 - acc: 1.1282e-04 - val_loss: 1.8245e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 7.2026e-05 - acc: 1.1282e-04 - val_loss: 1.4362e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.1667e-05 - acc: 1.1282e-04 - val_loss: 1.4988e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.7006e-05 - acc: 1.1282e-04 - val_loss: 1.8742e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.0676e-05 - acc: 1.1282e-04 - val_loss: 1.7430e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.1514e-05 - acc: 1.1282e-04 - val_loss: 1.6581e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.0102e-05 - acc: 1.1282e-04 - val_loss: 2.1101e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.8908e-05 - acc: 1.1282e-04 - val_loss: 3.1204e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.4668e-05 - acc: 1.1282e-04 - val_loss: 1.7731e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9355e-05 - acc: 1.1282e-04 - val_loss: 2.2747e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1236e-05 - acc: 1.1282e-04 - val_loss: 1.3442e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.1328e-05 - acc: 1.1282e-04 - val_loss: 1.3290e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.7764e-05 - acc: 1.1282e-04 - val_loss: 1.5087e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.6715e-05 - acc: 1.1282e-04 - val_loss: 1.3958e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.8472e-05 - acc: 1.1282e-04 - val_loss: 1.3469e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.1426e-05 - acc: 1.1282e-04 - val_loss: 1.3273e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.3028e-05 - acc: 1.1282e-04 - val_loss: 1.3076e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.3856e-05 - acc: 1.1282e-04 - val_loss: 1.5984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.3631e-05 - acc: 1.1282e-04 - val_loss: 2.3587e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.9985e-05 - acc: 1.1282e-04 - val_loss: 1.4722e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.3036e-05 - acc: 1.1282e-04 - val_loss: 1.4503e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.0018e-05 - acc: 1.1282e-04 - val_loss: 1.3776e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.8853e-05 - acc: 1.1282e-04 - val_loss: 1.3560e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.8702e-05 - acc: 1.1282e-04 - val_loss: 1.2866e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9516e-05 - acc: 1.1282e-04 - val_loss: 1.3023e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.6909e-05 - acc: 1.1282e-04 - val_loss: 1.3145e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.6392e-05 - acc: 1.1282e-04 - val_loss: 1.3408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.6835e-05 - acc: 1.1282e-04 - val_loss: 1.2994e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.0022e-05 - acc: 1.1282e-04 - val_loss: 2.0282e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.5959e-05 - acc: 1.1282e-04 - val_loss: 1.3691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.7801e-05 - acc: 1.1282e-04 - val_loss: 1.2776e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.5809e-05 - acc: 1.1282e-04 - val_loss: 3.3368e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.5467e-05 - acc: 1.1282e-04 - val_loss: 1.5781e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.4150e-05 - acc: 1.1282e-04 - val_loss: 1.3098e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.7382e-05 - acc: 1.1282e-04 - val_loss: 1.2945e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.7142e-05 - acc: 1.1282e-04 - val_loss: 2.1370e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.8870e-05 - acc: 1.1282e-04 - val_loss: 1.6588e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.7246e-05 - acc: 1.1282e-04 - val_loss: 1.5141e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.6775e-05 - acc: 1.1282e-04 - val_loss: 1.6498e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.7434e-05 - acc: 1.1282e-04 - val_loss: 1.3125e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.3571e-05 - acc: 1.1282e-04 - val_loss: 1.3440e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.4269e-05 - acc: 1.1282e-04 - val_loss: 2.9502e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.8606e-05 - acc: 1.1282e-04 - val_loss: 1.9130e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.2811e-05 - acc: 1.1282e-04 - val_loss: 1.3177e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.1617e-05 - acc: 1.1282e-04 - val_loss: 1.2225e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.2068e-05 - acc: 1.1282e-04 - val_loss: 1.2823e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.3651e-05 - acc: 1.1282e-04 - val_loss: 1.7224e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.9682e-05 - acc: 1.1282e-04 - val_loss: 1.2955e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.0504e-05 - acc: 1.1282e-04 - val_loss: 1.3555e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.4599e-05 - acc: 1.1282e-04 - val_loss: 1.4147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.8218e-05 - acc: 1.1282e-04 - val_loss: 1.2182e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.1622e-05 - acc: 1.1282e-04 - val_loss: 1.2786e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.4996e-05 - acc: 1.1282e-04 - val_loss: 2.1371e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1614e-05 - acc: 1.1282e-04 - val_loss: 1.6185e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.1988e-05 - acc: 1.1282e-04 - val_loss: 1.3470e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.2592e-05 - acc: 1.1282e-04 - val_loss: 1.1659e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.3349e-05 - acc: 1.1282e-04 - val_loss: 1.3949e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.1836e-05 - acc: 1.1282e-04 - val_loss: 1.3879e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.4173e-05 - acc: 1.1282e-04 - val_loss: 1.4389e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.6474e-05 - acc: 1.1282e-04 - val_loss: 2.0099e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 6.2905e-05 - acc: 1.1282e-04 - val_loss: 3.0390e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.4761e-05 - acc: 1.1282e-04 - val_loss: 1.8369e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.5588e-05 - acc: 1.1282e-04 - val_loss: 1.2361e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.4666e-05 - acc: 1.1282e-04 - val_loss: 2.4782e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.3340e-05 - acc: 1.1282e-04 - val_loss: 1.1596e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.1564e-05 - acc: 1.1282e-04 - val_loss: 1.2149e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.1677e-05 - acc: 1.1282e-04 - val_loss: 1.1345e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.0408e-05 - acc: 1.1282e-04 - val_loss: 1.3555e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.7031e-05 - acc: 1.1282e-04 - val_loss: 1.5086e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.4129e-05 - acc: 1.1282e-04 - val_loss: 1.3472e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 6.6297e-05 - acc: 1.1282e-04 - val_loss: 1.1629e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.7872e-05 - acc: 1.1282e-04 - val_loss: 1.1842e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.6946e-05 - acc: 1.1282e-04 - val_loss: 1.1571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.1267e-05 - acc: 1.1282e-04 - val_loss: 1.1270e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0363e-05 - acc: 1.1282e-04 - val_loss: 1.2443e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.8411e-05 - acc: 1.1282e-04 - val_loss: 1.7438e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0813e-05 - acc: 1.1282e-04 - val_loss: 1.2780e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9181e-05 - acc: 1.1282e-04 - val_loss: 1.1444e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.9642e-05 - acc: 1.1282e-04 - val_loss: 1.2150e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.2875e-05 - acc: 1.1282e-04 - val_loss: 1.2708e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.7464e-05 - acc: 1.1282e-04 - val_loss: 1.1332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7173e-05 - acc: 1.1282e-04 - val_loss: 1.1413e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 5.9729e-05 - acc: 1.1282e-04 - val_loss: 1.3070e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.7325e-05 - acc: 1.1282e-04 - val_loss: 1.4069e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.8955e-05 - acc: 1.1282e-04 - val_loss: 1.1907e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6373e-05 - acc: 1.1282e-04 - val_loss: 1.2775e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9571e-05 - acc: 1.1282e-04 - val_loss: 1.2343e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.9276e-05 - acc: 1.1282e-04 - val_loss: 1.1700e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9206e-05 - acc: 1.1282e-04 - val_loss: 1.1305e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.1840e-05 - acc: 1.1282e-04 - val_loss: 1.1370e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9397e-05 - acc: 1.1282e-04 - val_loss: 1.0891e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.9859e-05 - acc: 1.1282e-04 - val_loss: 1.1645e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7965e-05 - acc: 1.1282e-04 - val_loss: 1.0985e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.9657e-05 - acc: 1.1282e-04 - val_loss: 1.5865e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.0997e-05 - acc: 1.1282e-04 - val_loss: 2.5774e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.0238e-05 - acc: 1.1282e-04 - val_loss: 1.5380e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.1184e-05 - acc: 1.1282e-04 - val_loss: 1.1290e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.5004e-05 - acc: 1.1282e-04 - val_loss: 1.3574e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.2439e-05 - acc: 1.1282e-04 - val_loss: 1.1026e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.0772e-05 - acc: 1.1282e-04 - val_loss: 1.8149e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.1656e-05 - acc: 1.1282e-04 - val_loss: 1.1384e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.7141e-05 - acc: 1.1282e-04 - val_loss: 1.3223e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9273e-05 - acc: 1.1282e-04 - val_loss: 1.1415e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.4827e-05 - acc: 1.1282e-04 - val_loss: 1.0584e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.9025e-05 - acc: 1.1282e-04 - val_loss: 1.3160e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.7020e-05 - acc: 1.1282e-04 - val_loss: 1.1473e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.5308e-05 - acc: 1.1282e-04 - val_loss: 1.1194e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.5474e-05 - acc: 1.1282e-04 - val_loss: 1.6268e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.7505e-05 - acc: 1.1282e-04 - val_loss: 1.1418e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.4228e-05 - acc: 1.1282e-04 - val_loss: 1.1592e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.5286e-05 - acc: 1.1282e-04 - val_loss: 1.8986e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.8810e-05 - acc: 1.1282e-04 - val_loss: 1.0471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.4686e-05 - acc: 1.1282e-04 - val_loss: 1.1011e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.4033e-05 - acc: 1.1282e-04 - val_loss: 1.3672e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.3189e-05 - acc: 1.1282e-04 - val_loss: 1.5867e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.5556e-05 - acc: 1.1282e-04 - val_loss: 1.0464e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6899e-05 - acc: 1.1282e-04 - val_loss: 1.1902e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 5.6858e-05 - acc: 1.1282e-04 - val_loss: 1.1232e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.5539e-05 - acc: 1.1282e-04 - val_loss: 1.3950e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.4570e-05 - acc: 1.1282e-04 - val_loss: 1.3569e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 5.7000e-05 - acc: 1.1282e-04 - val_loss: 1.0647e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.5661e-05 - acc: 1.1282e-04 - val_loss: 1.4251e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.9257e-05 - acc: 1.1282e-04 - val_loss: 1.0494e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.9556e-05 - acc: 1.1282e-04 - val_loss: 2.7584e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 6.4066e-05 - acc: 1.1282e-04 - val_loss: 1.0992e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.7009e-05 - acc: 1.1282e-04 - val_loss: 1.0391e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.4107e-05 - acc: 1.1282e-04 - val_loss: 1.9683e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.1928e-05 - acc: 1.1282e-04 - val_loss: 1.3173e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.7424e-05 - acc: 1.1282e-04 - val_loss: 1.6937e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.0528e-05 - acc: 1.1282e-04 - val_loss: 1.4412e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.0189e-05 - acc: 1.1282e-04 - val_loss: 1.0784e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.1565e-05 - acc: 1.1282e-04 - val_loss: 1.0644e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.1421e-05 - acc: 1.1282e-04 - val_loss: 2.1537e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.7628e-05 - acc: 1.1282e-04 - val_loss: 1.2538e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.3615e-05 - acc: 1.1282e-04 - val_loss: 1.0621e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.1933e-05 - acc: 1.1282e-04 - val_loss: 1.0565e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.9664e-05 - acc: 1.1282e-04 - val_loss: 1.3751e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.2495e-05 - acc: 1.1282e-04 - val_loss: 1.0907e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.1113e-05 - acc: 1.1282e-04 - val_loss: 1.0921e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.3392e-05 - acc: 1.1282e-04 - val_loss: 2.3192e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.1264e-05 - acc: 1.1282e-04 - val_loss: 1.0484e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.7797e-05 - acc: 1.1282e-04 - val_loss: 9.9984e-05 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 5.7936e-05 - acc: 1.1282e-04 - val_loss: 9.8586e-05 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.1506e-05 - acc: 1.1282e-04 - val_loss: 1.3177e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0267e-05 - acc: 1.1282e-04 - val_loss: 1.0448e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.8586e-05 - acc: 1.1282e-04 - val_loss: 1.1136e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.4364e-05 - acc: 1.1282e-04 - val_loss: 1.0196e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.0990e-05 - acc: 1.1282e-04 - val_loss: 2.1507e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.4910e-05 - acc: 1.1282e-04 - val_loss: 1.3450e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.2289e-05 - acc: 1.1282e-04 - val_loss: 1.6163e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.3875e-05 - acc: 1.1282e-04 - val_loss: 1.1681e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.1233e-05 - acc: 1.1282e-04 - val_loss: 2.4258e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.7972e-05 - acc: 1.1282e-04 - val_loss: 1.2169e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.8501e-05 - acc: 1.1282e-04 - val_loss: 9.9829e-05 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.7503e-05 - acc: 1.1282e-04 - val_loss: 1.1265e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9978e-05 - acc: 1.1282e-04 - val_loss: 9.7309e-05 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.9567e-05 - acc: 1.1282e-04 - val_loss: 1.3253e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8588e-05 - acc: 1.1282e-04 - val_loss: 2.3777e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8212e-05 - acc: 1.1282e-04 - val_loss: 1.1131e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.5265e-05 - acc: 1.1282e-04 - val_loss: 9.9579e-05 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.3700e-05 - acc: 1.1282e-04 - val_loss: 1.4676e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.9139e-05 - acc: 1.1282e-04 - val_loss: 1.2350e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.7595e-05 - acc: 1.1282e-04 - val_loss: 1.7726e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 4.9694e-05 - acc: 1.1282e-04 - val_loss: 9.9510e-05 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.9735e-05 - acc: 1.1282e-04 - val_loss: 1.3650e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.9140e-05 - acc: 1.1282e-04 - val_loss: 1.4261e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 4.6726e-05 - acc: 1.1282e-04 - val_loss: 1.1297e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.9215e-05 - acc: 1.1282e-04 - val_loss: 1.7590e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.6533e-05 - acc: 1.1282e-04 - val_loss: 9.7984e-05 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.9302e-05 - acc: 1.1282e-04 - val_loss: 1.1117e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.8363e-05 - acc: 1.1282e-04 - val_loss: 2.6092e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.9002e-05 - acc: 1.1282e-04 - val_loss: 1.0999e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.7916e-05 - acc: 1.1282e-04 - val_loss: 1.0996e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.6252e-05 - acc: 1.1282e-04 - val_loss: 1.2346e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.5640e-05 - acc: 1.1282e-04 - val_loss: 1.5108e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.3011e-05 - acc: 1.1282e-04 - val_loss: 1.6356e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9599e-05 - acc: 1.1282e-04 - val_loss: 1.0333e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.045\n",
            "TEMP MSE: 0.002\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_13 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 4s 418us/step - loss: 0.0132 - acc: 1.1282e-04 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.8683e-04 - acc: 1.1282e-04 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.1258e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.7473e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.1970e-04 - acc: 1.1282e-04 - val_loss: 6.1045e-04 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.0873e-04 - acc: 1.1282e-04 - val_loss: 4.6831e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.9277e-04 - acc: 1.1282e-04 - val_loss: 3.9710e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.8943e-04 - acc: 1.1282e-04 - val_loss: 7.0115e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.8612e-04 - acc: 1.1282e-04 - val_loss: 4.1689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.6707e-04 - acc: 1.1282e-04 - val_loss: 2.4524e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6241e-04 - acc: 1.1282e-04 - val_loss: 7.3860e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.6476e-04 - acc: 1.1282e-04 - val_loss: 3.5858e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5423e-04 - acc: 1.1282e-04 - val_loss: 2.4253e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.5921e-04 - acc: 1.1282e-04 - val_loss: 2.2798e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.5994e-04 - acc: 1.1282e-04 - val_loss: 6.6582e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0770e-04 - acc: 1.1282e-04 - val_loss: 6.4608e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.6362e-04 - acc: 1.1282e-04 - val_loss: 2.2636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.5924e-04 - acc: 1.1282e-04 - val_loss: 5.4956e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.5330e-04 - acc: 1.1282e-04 - val_loss: 4.6902e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.4788e-04 - acc: 1.1282e-04 - val_loss: 2.2828e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3898e-04 - acc: 1.1282e-04 - val_loss: 3.4392e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5012e-04 - acc: 1.1282e-04 - val_loss: 2.8645e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4122e-04 - acc: 1.1282e-04 - val_loss: 2.0989e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3762e-04 - acc: 1.1282e-04 - val_loss: 2.1180e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.3275e-04 - acc: 1.1282e-04 - val_loss: 2.8224e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.3884e-04 - acc: 1.1282e-04 - val_loss: 2.1291e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3487e-04 - acc: 1.1282e-04 - val_loss: 3.7015e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3018e-04 - acc: 1.1282e-04 - val_loss: 2.0443e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3096e-04 - acc: 1.1282e-04 - val_loss: 2.4061e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.4792e-04 - acc: 1.1282e-04 - val_loss: 4.9132e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 1.4173e-04 - acc: 1.1282e-04 - val_loss: 2.0306e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.4242e-04 - acc: 1.1282e-04 - val_loss: 2.3964e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3515e-04 - acc: 1.1282e-04 - val_loss: 3.3878e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.5388e-04 - acc: 1.1282e-04 - val_loss: 2.3085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.3209e-04 - acc: 1.1282e-04 - val_loss: 2.6885e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2407e-04 - acc: 1.1282e-04 - val_loss: 3.1514e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.5418e-04 - acc: 1.1282e-04 - val_loss: 5.9250e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.7693e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.3952e-04 - acc: 1.1282e-04 - val_loss: 3.8675e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3010e-04 - acc: 1.1282e-04 - val_loss: 3.6738e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1974e-04 - acc: 1.1282e-04 - val_loss: 1.8431e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1925e-04 - acc: 1.1282e-04 - val_loss: 2.1863e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.4469e-04 - acc: 1.1282e-04 - val_loss: 2.0634e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2383e-04 - acc: 1.1282e-04 - val_loss: 3.0998e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2833e-04 - acc: 1.1282e-04 - val_loss: 5.1085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2290e-04 - acc: 1.1282e-04 - val_loss: 1.9548e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.4632e-04 - acc: 1.1282e-04 - val_loss: 8.0838e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3772e-04 - acc: 1.1282e-04 - val_loss: 2.9100e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2524e-04 - acc: 1.1282e-04 - val_loss: 1.7752e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.2682e-04 - acc: 1.1282e-04 - val_loss: 2.3750e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2436e-04 - acc: 1.1282e-04 - val_loss: 1.7269e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3178e-04 - acc: 1.1282e-04 - val_loss: 1.8229e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2132e-04 - acc: 1.1282e-04 - val_loss: 1.6961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1322e-04 - acc: 1.1282e-04 - val_loss: 1.8809e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.1607e-04 - acc: 1.1282e-04 - val_loss: 1.7670e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0519e-04 - acc: 1.1282e-04 - val_loss: 1.6713e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0764e-04 - acc: 1.1282e-04 - val_loss: 4.8399e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1464e-04 - acc: 1.1282e-04 - val_loss: 1.8250e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1266e-04 - acc: 1.1282e-04 - val_loss: 3.5572e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3100e-04 - acc: 1.1282e-04 - val_loss: 2.0281e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1164e-04 - acc: 1.1282e-04 - val_loss: 1.8843e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.0880e-04 - acc: 1.1282e-04 - val_loss: 1.6382e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0790e-04 - acc: 1.1282e-04 - val_loss: 1.7389e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0840e-04 - acc: 1.1282e-04 - val_loss: 2.0937e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0335e-04 - acc: 1.1282e-04 - val_loss: 1.7018e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.1065e-04 - acc: 1.1282e-04 - val_loss: 5.6592e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1549e-04 - acc: 1.1282e-04 - val_loss: 2.6287e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.3236e-04 - acc: 1.1282e-04 - val_loss: 1.7762e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0615e-04 - acc: 1.1282e-04 - val_loss: 2.6168e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0542e-04 - acc: 1.1282e-04 - val_loss: 2.8019e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1559e-04 - acc: 1.1282e-04 - val_loss: 1.9003e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2206e-04 - acc: 1.1282e-04 - val_loss: 1.5314e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.9937e-05 - acc: 1.1282e-04 - val_loss: 2.5928e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0824e-04 - acc: 1.1282e-04 - val_loss: 5.1067e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.2067e-04 - acc: 1.1282e-04 - val_loss: 1.5992e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.0272e-04 - acc: 1.1282e-04 - val_loss: 1.6186e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 9.4076e-05 - acc: 1.1282e-04 - val_loss: 1.9629e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0388e-04 - acc: 1.1282e-04 - val_loss: 3.2437e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 9.5636e-05 - acc: 1.1282e-04 - val_loss: 2.8795e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.3898e-05 - acc: 1.1282e-04 - val_loss: 5.4571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2620e-04 - acc: 1.1282e-04 - val_loss: 3.0558e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.5421e-05 - acc: 1.1282e-04 - val_loss: 3.4458e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0876e-04 - acc: 1.1282e-04 - val_loss: 2.8503e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0136e-04 - acc: 1.1282e-04 - val_loss: 1.8525e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0098e-04 - acc: 1.1282e-04 - val_loss: 2.1580e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.1137e-04 - acc: 1.1282e-04 - val_loss: 1.4478e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.7720e-05 - acc: 1.1282e-04 - val_loss: 3.1130e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.7236e-05 - acc: 1.1282e-04 - val_loss: 1.6227e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 9.4707e-05 - acc: 1.1282e-04 - val_loss: 1.3986e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1571e-04 - acc: 1.1282e-04 - val_loss: 1.6280e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.8995e-05 - acc: 1.1282e-04 - val_loss: 1.3861e-04 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.0825e-05 - acc: 1.1282e-04 - val_loss: 1.5445e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.0562e-05 - acc: 1.1282e-04 - val_loss: 1.5992e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.9837e-05 - acc: 1.1282e-04 - val_loss: 2.3601e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2078e-04 - acc: 1.1282e-04 - val_loss: 2.3223e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0453e-04 - acc: 1.1282e-04 - val_loss: 2.1137e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.9782e-05 - acc: 1.1282e-04 - val_loss: 3.6395e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0348e-04 - acc: 1.1282e-04 - val_loss: 1.3986e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 9.0919e-05 - acc: 1.1282e-04 - val_loss: 2.4369e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.5763e-05 - acc: 1.1282e-04 - val_loss: 1.5026e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.3268e-05 - acc: 1.1282e-04 - val_loss: 1.6340e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.3570e-05 - acc: 1.1282e-04 - val_loss: 1.5347e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.5757e-05 - acc: 1.1282e-04 - val_loss: 1.3258e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.0738e-05 - acc: 1.1282e-04 - val_loss: 2.6181e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.7298e-05 - acc: 1.1282e-04 - val_loss: 1.3607e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.1616e-05 - acc: 1.1282e-04 - val_loss: 1.4274e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.4075e-05 - acc: 1.1282e-04 - val_loss: 1.6040e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.0384e-05 - acc: 1.1282e-04 - val_loss: 2.8859e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 9.5385e-05 - acc: 1.1282e-04 - val_loss: 1.4102e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.3422e-05 - acc: 1.1282e-04 - val_loss: 2.6113e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.9693e-05 - acc: 1.1282e-04 - val_loss: 1.3014e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.4143e-05 - acc: 1.1282e-04 - val_loss: 1.3335e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.1713e-05 - acc: 1.1282e-04 - val_loss: 1.3180e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.7858e-05 - acc: 1.1282e-04 - val_loss: 1.7592e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.6176e-05 - acc: 1.1282e-04 - val_loss: 3.0033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.8481e-05 - acc: 1.1282e-04 - val_loss: 2.7199e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.4094e-05 - acc: 1.1282e-04 - val_loss: 1.8228e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.6141e-05 - acc: 1.1282e-04 - val_loss: 1.4856e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.7682e-05 - acc: 1.1282e-04 - val_loss: 2.0461e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.4078e-05 - acc: 1.1282e-04 - val_loss: 1.2665e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.9461e-05 - acc: 1.1282e-04 - val_loss: 1.3530e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.6688e-05 - acc: 1.1282e-04 - val_loss: 1.3129e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.6880e-05 - acc: 1.1282e-04 - val_loss: 1.7955e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.5779e-05 - acc: 1.1282e-04 - val_loss: 1.8467e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 7.9665e-05 - acc: 1.1282e-04 - val_loss: 2.0717e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.4361e-05 - acc: 1.1282e-04 - val_loss: 1.3993e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.5230e-05 - acc: 1.1282e-04 - val_loss: 1.3984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.0655e-05 - acc: 1.1282e-04 - val_loss: 1.5408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.8759e-05 - acc: 1.1282e-04 - val_loss: 1.5898e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.8771e-05 - acc: 1.1282e-04 - val_loss: 2.4033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.7231e-05 - acc: 1.1282e-04 - val_loss: 1.2763e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.9198e-05 - acc: 1.1282e-04 - val_loss: 1.3823e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.3483e-05 - acc: 1.1282e-04 - val_loss: 1.4455e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6743e-05 - acc: 1.1282e-04 - val_loss: 1.4803e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.7959e-05 - acc: 1.1282e-04 - val_loss: 1.7560e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.4513e-05 - acc: 1.1282e-04 - val_loss: 1.6936e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.4907e-05 - acc: 1.1282e-04 - val_loss: 1.5673e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.6918e-05 - acc: 1.1282e-04 - val_loss: 1.3766e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.7930e-05 - acc: 1.1282e-04 - val_loss: 1.3096e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.8393e-05 - acc: 1.1282e-04 - val_loss: 1.7093e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.4947e-05 - acc: 1.1282e-04 - val_loss: 1.1996e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.8861e-05 - acc: 1.1282e-04 - val_loss: 1.1926e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.6703e-05 - acc: 1.1282e-04 - val_loss: 2.1688e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.9915e-05 - acc: 1.1282e-04 - val_loss: 1.2513e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.4204e-05 - acc: 1.1282e-04 - val_loss: 1.2583e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.1235e-05 - acc: 1.1282e-04 - val_loss: 1.2219e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.7530e-05 - acc: 1.1282e-04 - val_loss: 1.1930e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.2526e-05 - acc: 1.1282e-04 - val_loss: 1.8641e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.3463e-05 - acc: 1.1282e-04 - val_loss: 1.9302e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6160e-05 - acc: 1.1282e-04 - val_loss: 1.2988e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.6105e-05 - acc: 1.1282e-04 - val_loss: 1.6814e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.3065e-05 - acc: 1.1282e-04 - val_loss: 1.5140e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.3528e-05 - acc: 1.1282e-04 - val_loss: 1.3440e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.2525e-05 - acc: 1.1282e-04 - val_loss: 1.3801e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.8053e-05 - acc: 1.1282e-04 - val_loss: 1.2739e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.3779e-05 - acc: 1.1282e-04 - val_loss: 1.7435e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.3669e-05 - acc: 1.1282e-04 - val_loss: 1.4065e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.1918e-05 - acc: 1.1282e-04 - val_loss: 1.6304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.1646e-05 - acc: 1.1282e-04 - val_loss: 1.2757e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.5251e-05 - acc: 1.1282e-04 - val_loss: 1.3067e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.2334e-05 - acc: 1.1282e-04 - val_loss: 1.1984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8391e-05 - acc: 1.1282e-04 - val_loss: 1.8324e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.3054e-05 - acc: 1.1282e-04 - val_loss: 1.4846e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.5516e-05 - acc: 1.1282e-04 - val_loss: 1.3306e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1643e-05 - acc: 1.1282e-04 - val_loss: 1.4419e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.2637e-05 - acc: 1.1282e-04 - val_loss: 1.1474e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.8908e-05 - acc: 1.1282e-04 - val_loss: 2.7412e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.1585e-05 - acc: 1.1282e-04 - val_loss: 1.1598e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.7824e-05 - acc: 1.1282e-04 - val_loss: 1.1935e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.0418e-05 - acc: 1.1282e-04 - val_loss: 1.1757e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.5726e-05 - acc: 1.1282e-04 - val_loss: 2.0620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 7.9003e-05 - acc: 1.1282e-04 - val_loss: 3.0396e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6869e-05 - acc: 1.1282e-04 - val_loss: 1.4597e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.7143e-05 - acc: 1.1282e-04 - val_loss: 2.8150e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.4471e-05 - acc: 1.1282e-04 - val_loss: 1.7520e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.6905e-05 - acc: 1.1282e-04 - val_loss: 1.5711e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1973e-05 - acc: 1.1282e-04 - val_loss: 1.3914e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.8609e-05 - acc: 1.1282e-04 - val_loss: 1.5081e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.5347e-05 - acc: 1.1282e-04 - val_loss: 1.2741e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.4582e-05 - acc: 1.1282e-04 - val_loss: 1.1287e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.4562e-05 - acc: 1.1282e-04 - val_loss: 2.6146e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.2231e-05 - acc: 1.1282e-04 - val_loss: 1.2307e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.6351e-05 - acc: 1.1282e-04 - val_loss: 1.1507e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.1716e-05 - acc: 1.1282e-04 - val_loss: 2.5003e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.8844e-05 - acc: 1.1282e-04 - val_loss: 1.1042e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.3761e-05 - acc: 1.1282e-04 - val_loss: 1.6163e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.9076e-05 - acc: 1.1282e-04 - val_loss: 1.5620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 6.8779e-05 - acc: 1.1282e-04 - val_loss: 1.8033e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.4163e-05 - acc: 1.1282e-04 - val_loss: 2.3710e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.9866e-05 - acc: 1.1282e-04 - val_loss: 1.1814e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8227e-05 - acc: 1.1282e-04 - val_loss: 1.3573e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.4056e-05 - acc: 1.1282e-04 - val_loss: 1.4605e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.3838e-05 - acc: 1.1282e-04 - val_loss: 1.1157e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 159us/step - loss: 6.6940e-05 - acc: 1.1282e-04 - val_loss: 1.3786e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.6815e-05 - acc: 1.1282e-04 - val_loss: 1.1495e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.4921e-05 - acc: 1.1282e-04 - val_loss: 1.1532e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.2393e-05 - acc: 1.1282e-04 - val_loss: 1.2970e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.3993e-05 - acc: 1.1282e-04 - val_loss: 1.3820e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.6529e-05 - acc: 1.1282e-04 - val_loss: 1.1342e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.4370e-05 - acc: 1.1282e-04 - val_loss: 1.1173e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 6.2988e-05 - acc: 1.1282e-04 - val_loss: 1.4501e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.6022e-05 - acc: 1.1282e-04 - val_loss: 1.2592e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.5424e-05 - acc: 1.1282e-04 - val_loss: 1.0911e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.3844e-05 - acc: 1.1282e-04 - val_loss: 1.7081e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.5090e-05 - acc: 1.1282e-04 - val_loss: 1.0790e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.8199e-05 - acc: 1.1282e-04 - val_loss: 1.1079e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.9330e-05 - acc: 1.1282e-04 - val_loss: 1.1222e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.0778e-05 - acc: 1.1282e-04 - val_loss: 2.0734e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.7030e-05 - acc: 1.1282e-04 - val_loss: 2.0331e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9661e-05 - acc: 1.1282e-04 - val_loss: 1.5125e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.5241e-05 - acc: 1.1282e-04 - val_loss: 1.4476e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.4079e-05 - acc: 1.1282e-04 - val_loss: 1.1852e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.3319e-05 - acc: 1.1282e-04 - val_loss: 1.2144e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.2579e-05 - acc: 1.1282e-04 - val_loss: 3.1512e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.1524e-05 - acc: 1.1282e-04 - val_loss: 1.1614e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.9229e-05 - acc: 1.1282e-04 - val_loss: 1.3034e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.8809e-05 - acc: 1.1282e-04 - val_loss: 1.0492e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.0999e-05 - acc: 1.1282e-04 - val_loss: 2.0755e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.0871e-05 - acc: 1.1282e-04 - val_loss: 1.0844e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.7862e-05 - acc: 1.1282e-04 - val_loss: 1.1264e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0194e-05 - acc: 1.1282e-04 - val_loss: 1.6245e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.2514e-05 - acc: 1.1282e-04 - val_loss: 1.6326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.6666e-05 - acc: 1.1282e-04 - val_loss: 2.3295e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9332e-05 - acc: 1.1282e-04 - val_loss: 3.5917e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.4358e-05 - acc: 1.1282e-04 - val_loss: 1.4235e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.0939e-05 - acc: 1.1282e-04 - val_loss: 1.1525e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8519e-05 - acc: 1.1282e-04 - val_loss: 3.1959e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8925e-05 - acc: 1.1282e-04 - val_loss: 1.9605e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.2015e-05 - acc: 1.1282e-04 - val_loss: 1.0405e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.1425e-05 - acc: 1.1282e-04 - val_loss: 2.1251e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.3238e-05 - acc: 1.1282e-04 - val_loss: 1.0355e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.0138e-05 - acc: 1.1282e-04 - val_loss: 1.2437e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8100e-05 - acc: 1.1282e-04 - val_loss: 2.3631e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.3862e-05 - acc: 1.1282e-04 - val_loss: 1.1496e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0799e-05 - acc: 1.1282e-04 - val_loss: 1.1069e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.5836e-05 - acc: 1.1282e-04 - val_loss: 1.9021e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.4060e-05 - acc: 1.1282e-04 - val_loss: 1.4918e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.8562e-05 - acc: 1.1282e-04 - val_loss: 1.0322e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.6130e-05 - acc: 1.1282e-04 - val_loss: 1.0325e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.4181e-05 - acc: 1.1282e-04 - val_loss: 1.3008e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.6086e-05 - acc: 1.1282e-04 - val_loss: 1.1309e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.6801e-05 - acc: 1.1282e-04 - val_loss: 1.0305e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.4227e-05 - acc: 1.1282e-04 - val_loss: 1.1587e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.0894e-05 - acc: 1.1282e-04 - val_loss: 1.2434e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.7180e-05 - acc: 1.1282e-04 - val_loss: 2.1883e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.2654e-05 - acc: 1.1282e-04 - val_loss: 2.2690e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7170e-05 - acc: 1.1282e-04 - val_loss: 1.0192e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0664e-05 - acc: 1.1282e-04 - val_loss: 2.1779e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.8971e-05 - acc: 1.1282e-04 - val_loss: 1.1333e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.5402e-05 - acc: 1.1282e-04 - val_loss: 1.5062e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.9879e-05 - acc: 1.1282e-04 - val_loss: 1.6418e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.4492e-05 - acc: 1.1282e-04 - val_loss: 1.0447e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.6546e-05 - acc: 1.1282e-04 - val_loss: 1.5808e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6724e-05 - acc: 1.1282e-04 - val_loss: 1.6147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.8067e-05 - acc: 1.1282e-04 - val_loss: 1.0242e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8938e-05 - acc: 1.1282e-04 - val_loss: 1.0080e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7472e-05 - acc: 1.1282e-04 - val_loss: 1.3771e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.7193e-05 - acc: 1.1282e-04 - val_loss: 1.2961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.6930e-05 - acc: 1.1282e-04 - val_loss: 1.1719e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.7602e-05 - acc: 1.1282e-04 - val_loss: 2.3255e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.6698e-05 - acc: 1.1282e-04 - val_loss: 1.0334e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.6496e-05 - acc: 1.1282e-04 - val_loss: 1.0869e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.1823e-05 - acc: 1.1282e-04 - val_loss: 1.1307e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.4704e-05 - acc: 1.1282e-04 - val_loss: 9.9024e-05 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.3878e-05 - acc: 1.1282e-04 - val_loss: 9.8032e-05 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.4378e-05 - acc: 1.1282e-04 - val_loss: 1.0322e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.8268e-05 - acc: 1.1282e-04 - val_loss: 1.2514e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.9000e-05 - acc: 1.1282e-04 - val_loss: 9.9276e-05 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8735e-05 - acc: 1.1282e-04 - val_loss: 1.7642e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.8053e-05 - acc: 1.1282e-04 - val_loss: 1.1029e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.6114e-05 - acc: 1.1282e-04 - val_loss: 1.4720e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6143e-05 - acc: 1.1282e-04 - val_loss: 1.2386e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.6585e-05 - acc: 1.1282e-04 - val_loss: 1.4012e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.3204e-05 - acc: 1.1282e-04 - val_loss: 1.0993e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.2267e-05 - acc: 1.1282e-04 - val_loss: 9.9087e-05 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.0304e-05 - acc: 1.1282e-04 - val_loss: 1.0002e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.3984e-05 - acc: 1.1282e-04 - val_loss: 1.2225e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.1428e-05 - acc: 1.1282e-04 - val_loss: 9.9085e-05 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.3819e-05 - acc: 1.1282e-04 - val_loss: 1.3497e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0109e-05 - acc: 1.1282e-04 - val_loss: 1.0420e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.7947e-05 - acc: 1.1282e-04 - val_loss: 9.8932e-05 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.9960e-05 - acc: 1.1282e-04 - val_loss: 1.7102e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.2483e-05 - acc: 1.1282e-04 - val_loss: 9.9752e-05 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.2293e-05 - acc: 1.1282e-04 - val_loss: 9.8001e-05 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.2830e-05 - acc: 1.1282e-04 - val_loss: 2.7154e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.6730e-05 - acc: 1.1282e-04 - val_loss: 1.2556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.9143e-05 - acc: 1.1282e-04 - val_loss: 1.1450e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.8526e-05 - acc: 1.1282e-04 - val_loss: 1.0055e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.0302e-05 - acc: 1.1282e-04 - val_loss: 1.0673e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.8610e-05 - acc: 1.1282e-04 - val_loss: 1.0005e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0281e-05 - acc: 1.1282e-04 - val_loss: 1.1896e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.7863e-05 - acc: 1.1282e-04 - val_loss: 2.0280e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.2809e-05 - acc: 1.1282e-04 - val_loss: 1.4087e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.3783e-05 - acc: 1.1282e-04 - val_loss: 1.2924e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.3538e-05 - acc: 1.1282e-04 - val_loss: 1.1403e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.6369e-05 - acc: 1.1282e-04 - val_loss: 9.9325e-05 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.0208e-05 - acc: 1.1282e-04 - val_loss: 1.1085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.0756e-05 - acc: 1.1282e-04 - val_loss: 9.8139e-05 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.8377e-05 - acc: 1.1282e-04 - val_loss: 1.0640e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.9176e-05 - acc: 1.1282e-04 - val_loss: 1.5935e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.026\n",
            "TEMP MSE: 0.001\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_15 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 4s 460us/step - loss: 0.0161 - acc: 1.1282e-04 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.5839e-04 - acc: 1.1282e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.0657e-04 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 3.3062e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.9153e-04 - acc: 1.1282e-04 - val_loss: 8.8209e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.5388e-04 - acc: 1.1282e-04 - val_loss: 4.9382e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.4203e-04 - acc: 1.1282e-04 - val_loss: 3.6233e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.1882e-04 - acc: 1.1282e-04 - val_loss: 3.1771e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2461e-04 - acc: 1.1282e-04 - val_loss: 3.6617e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1709e-04 - acc: 1.1282e-04 - val_loss: 2.5289e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.9791e-04 - acc: 1.1282e-04 - val_loss: 3.2853e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.2667e-04 - acc: 1.1282e-04 - val_loss: 7.7068e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9040e-04 - acc: 1.1282e-04 - val_loss: 2.8152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0375e-04 - acc: 1.1282e-04 - val_loss: 4.4926e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.0775e-04 - acc: 1.1282e-04 - val_loss: 3.8470e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.9288e-04 - acc: 1.1282e-04 - val_loss: 3.4636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.9390e-04 - acc: 1.1282e-04 - val_loss: 4.5699e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.9612e-04 - acc: 1.1282e-04 - val_loss: 3.4945e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.9588e-04 - acc: 1.1282e-04 - val_loss: 2.3437e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.2009e-04 - acc: 1.1282e-04 - val_loss: 2.5411e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9559e-04 - acc: 1.1282e-04 - val_loss: 2.3736e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.9135e-04 - acc: 1.1282e-04 - val_loss: 5.9394e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.0017e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.6750e-04 - acc: 1.1282e-04 - val_loss: 2.6550e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.9843e-04 - acc: 1.1282e-04 - val_loss: 4.2609e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.9478e-04 - acc: 1.1282e-04 - val_loss: 2.8836e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.8484e-04 - acc: 1.1282e-04 - val_loss: 3.4692e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.0395e-04 - acc: 1.1282e-04 - val_loss: 7.6323e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.1093e-04 - acc: 1.1282e-04 - val_loss: 3.2121e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9426e-04 - acc: 1.1282e-04 - val_loss: 3.0241e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7960e-04 - acc: 1.1282e-04 - val_loss: 2.2263e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7459e-04 - acc: 1.1282e-04 - val_loss: 2.4680e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7195e-04 - acc: 1.1282e-04 - val_loss: 3.8331e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.8832e-04 - acc: 1.1282e-04 - val_loss: 2.1868e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.6554e-04 - acc: 1.1282e-04 - val_loss: 2.2205e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.6770e-04 - acc: 1.1282e-04 - val_loss: 2.2704e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.7256e-04 - acc: 1.1282e-04 - val_loss: 4.2472e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.8533e-04 - acc: 1.1282e-04 - val_loss: 2.1991e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.6821e-04 - acc: 1.1282e-04 - val_loss: 2.3011e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.8612e-04 - acc: 1.1282e-04 - val_loss: 5.1605e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.2324e-04 - acc: 1.1282e-04 - val_loss: 2.3735e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.3081e-04 - acc: 1.1282e-04 - val_loss: 8.8537e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.7808e-04 - acc: 1.1282e-04 - val_loss: 3.6171e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.7436e-04 - acc: 1.1282e-04 - val_loss: 2.6226e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6123e-04 - acc: 1.1282e-04 - val_loss: 2.0587e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.7381e-04 - acc: 1.1282e-04 - val_loss: 3.9293e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7345e-04 - acc: 1.1282e-04 - val_loss: 4.3650e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.7171e-04 - acc: 1.1282e-04 - val_loss: 2.0636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.6301e-04 - acc: 1.1282e-04 - val_loss: 3.7038e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.5080e-04 - acc: 1.1282e-04 - val_loss: 2.4715e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.5192e-04 - acc: 1.1282e-04 - val_loss: 2.2734e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.4570e-04 - acc: 1.1282e-04 - val_loss: 2.0829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5043e-04 - acc: 1.1282e-04 - val_loss: 2.3831e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6904e-04 - acc: 1.1282e-04 - val_loss: 3.8282e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4710e-04 - acc: 1.1282e-04 - val_loss: 1.9264e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5041e-04 - acc: 1.1282e-04 - val_loss: 2.4776e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.5293e-04 - acc: 1.1282e-04 - val_loss: 6.9584e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5048e-04 - acc: 1.1282e-04 - val_loss: 1.9364e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.7874e-04 - acc: 1.1282e-04 - val_loss: 4.6670e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.6374e-04 - acc: 1.1282e-04 - val_loss: 5.0560e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.5465e-04 - acc: 1.1282e-04 - val_loss: 2.3255e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.4480e-04 - acc: 1.1282e-04 - val_loss: 1.8620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.5466e-04 - acc: 1.1282e-04 - val_loss: 2.1297e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.5052e-04 - acc: 1.1282e-04 - val_loss: 3.6278e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5197e-04 - acc: 1.1282e-04 - val_loss: 3.0054e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.5008e-04 - acc: 1.1282e-04 - val_loss: 2.7323e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.6951e-04 - acc: 1.1282e-04 - val_loss: 4.4408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.6181e-04 - acc: 1.1282e-04 - val_loss: 2.0774e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.3448e-04 - acc: 1.1282e-04 - val_loss: 1.7878e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3991e-04 - acc: 1.1282e-04 - val_loss: 3.0834e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.3231e-04 - acc: 1.1282e-04 - val_loss: 2.4756e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.3515e-04 - acc: 1.1282e-04 - val_loss: 2.8846e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3941e-04 - acc: 1.1282e-04 - val_loss: 3.2211e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6414e-04 - acc: 1.1282e-04 - val_loss: 3.9093e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.4480e-04 - acc: 1.1282e-04 - val_loss: 1.8931e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3387e-04 - acc: 1.1282e-04 - val_loss: 2.0286e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.3914e-04 - acc: 1.1282e-04 - val_loss: 1.7285e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4456e-04 - acc: 1.1282e-04 - val_loss: 4.2125e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.7725e-04 - acc: 1.1282e-04 - val_loss: 2.7300e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.6171e-04 - acc: 1.1282e-04 - val_loss: 1.8211e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.5013e-04 - acc: 1.1282e-04 - val_loss: 1.7659e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3198e-04 - acc: 1.1282e-04 - val_loss: 6.6770e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.4380e-04 - acc: 1.1282e-04 - val_loss: 2.1341e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2945e-04 - acc: 1.1282e-04 - val_loss: 1.7176e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2722e-04 - acc: 1.1282e-04 - val_loss: 1.6411e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2378e-04 - acc: 1.1282e-04 - val_loss: 1.6383e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2762e-04 - acc: 1.1282e-04 - val_loss: 1.6556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2454e-04 - acc: 1.1282e-04 - val_loss: 1.7304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2877e-04 - acc: 1.1282e-04 - val_loss: 1.6853e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3170e-04 - acc: 1.1282e-04 - val_loss: 1.9733e-04 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.2346e-04 - acc: 1.1282e-04 - val_loss: 1.9420e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2781e-04 - acc: 1.1282e-04 - val_loss: 3.6219e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4276e-04 - acc: 1.1282e-04 - val_loss: 3.3584e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2654e-04 - acc: 1.1282e-04 - val_loss: 1.7634e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2981e-04 - acc: 1.1282e-04 - val_loss: 2.4164e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2222e-04 - acc: 1.1282e-04 - val_loss: 2.3586e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2089e-04 - acc: 1.1282e-04 - val_loss: 1.7888e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.1688e-04 - acc: 1.1282e-04 - val_loss: 1.5624e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.2442e-04 - acc: 1.1282e-04 - val_loss: 1.5387e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2219e-04 - acc: 1.1282e-04 - val_loss: 1.6724e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2300e-04 - acc: 1.1282e-04 - val_loss: 2.6480e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.3219e-04 - acc: 1.1282e-04 - val_loss: 1.8565e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.1567e-04 - acc: 1.1282e-04 - val_loss: 1.6003e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1848e-04 - acc: 1.1282e-04 - val_loss: 2.5609e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1282e-04 - acc: 1.1282e-04 - val_loss: 1.5292e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.2100e-04 - acc: 1.1282e-04 - val_loss: 1.6843e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1209e-04 - acc: 1.1282e-04 - val_loss: 2.2419e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0938e-04 - acc: 1.1282e-04 - val_loss: 1.5341e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0753e-04 - acc: 1.1282e-04 - val_loss: 3.8240e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.2035e-04 - acc: 1.1282e-04 - val_loss: 1.5527e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0463e-04 - acc: 1.1282e-04 - val_loss: 1.4519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1049e-04 - acc: 1.1282e-04 - val_loss: 1.5948e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0399e-04 - acc: 1.1282e-04 - val_loss: 1.5606e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1033e-04 - acc: 1.1282e-04 - val_loss: 3.2037e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2486e-04 - acc: 1.1282e-04 - val_loss: 2.3726e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.0463e-04 - acc: 1.1282e-04 - val_loss: 1.6001e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0704e-04 - acc: 1.1282e-04 - val_loss: 1.6135e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2192e-04 - acc: 1.1282e-04 - val_loss: 1.4452e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0387e-04 - acc: 1.1282e-04 - val_loss: 1.4584e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0307e-04 - acc: 1.1282e-04 - val_loss: 1.8853e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.8003e-05 - acc: 1.1282e-04 - val_loss: 1.8666e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 9.7358e-05 - acc: 1.1282e-04 - val_loss: 1.4167e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0098e-04 - acc: 1.1282e-04 - val_loss: 1.4125e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1951e-04 - acc: 1.1282e-04 - val_loss: 1.6876e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1023e-04 - acc: 1.1282e-04 - val_loss: 1.9882e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.6462e-05 - acc: 1.1282e-04 - val_loss: 1.8990e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.9986e-05 - acc: 1.1282e-04 - val_loss: 1.4172e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0501e-04 - acc: 1.1282e-04 - val_loss: 2.6673e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.0304e-04 - acc: 1.1282e-04 - val_loss: 1.4644e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 9.7042e-05 - acc: 1.1282e-04 - val_loss: 1.5324e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.7296e-05 - acc: 1.1282e-04 - val_loss: 1.3624e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.9136e-05 - acc: 1.1282e-04 - val_loss: 3.1402e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0518e-04 - acc: 1.1282e-04 - val_loss: 1.3694e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.0199e-04 - acc: 1.1282e-04 - val_loss: 1.3761e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.7470e-05 - acc: 1.1282e-04 - val_loss: 2.4297e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.8525e-05 - acc: 1.1282e-04 - val_loss: 1.3358e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.3549e-05 - acc: 1.1282e-04 - val_loss: 1.7288e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.6475e-05 - acc: 1.1282e-04 - val_loss: 3.1758e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.6664e-05 - acc: 1.1282e-04 - val_loss: 1.3346e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.2004e-04 - acc: 1.1282e-04 - val_loss: 1.4542e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0848e-04 - acc: 1.1282e-04 - val_loss: 1.3984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.2126e-05 - acc: 1.1282e-04 - val_loss: 3.1331e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.0339e-04 - acc: 1.1282e-04 - val_loss: 1.6251e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.7171e-05 - acc: 1.1282e-04 - val_loss: 1.8900e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.8571e-05 - acc: 1.1282e-04 - val_loss: 1.5951e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.8581e-05 - acc: 1.1282e-04 - val_loss: 1.2996e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.7459e-05 - acc: 1.1282e-04 - val_loss: 1.3660e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.0424e-05 - acc: 1.1282e-04 - val_loss: 2.3408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.9790e-05 - acc: 1.1282e-04 - val_loss: 2.2496e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.9799e-05 - acc: 1.1282e-04 - val_loss: 1.4090e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.7803e-05 - acc: 1.1282e-04 - val_loss: 2.1618e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 9.3267e-05 - acc: 1.1282e-04 - val_loss: 1.8283e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.5868e-05 - acc: 1.1282e-04 - val_loss: 1.9371e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.4957e-05 - acc: 1.1282e-04 - val_loss: 1.3062e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.7456e-05 - acc: 1.1282e-04 - val_loss: 2.8441e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.9597e-05 - acc: 1.1282e-04 - val_loss: 1.2876e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0569e-04 - acc: 1.1282e-04 - val_loss: 2.0703e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.8705e-05 - acc: 1.1282e-04 - val_loss: 1.3612e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.9070e-05 - acc: 1.1282e-04 - val_loss: 2.2601e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.6253e-05 - acc: 1.1282e-04 - val_loss: 1.3995e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.1845e-05 - acc: 1.1282e-04 - val_loss: 1.8425e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.2392e-05 - acc: 1.1282e-04 - val_loss: 1.2900e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.2757e-05 - acc: 1.1282e-04 - val_loss: 1.5045e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.9782e-05 - acc: 1.1282e-04 - val_loss: 1.3551e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.8756e-05 - acc: 1.1282e-04 - val_loss: 2.1332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 7.9243e-05 - acc: 1.1282e-04 - val_loss: 1.4419e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.0113e-05 - acc: 1.1282e-04 - val_loss: 1.7056e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.1275e-05 - acc: 1.1282e-04 - val_loss: 1.2982e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.1440e-05 - acc: 1.1282e-04 - val_loss: 1.3891e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.7366e-05 - acc: 1.1282e-04 - val_loss: 1.6051e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.7310e-05 - acc: 1.1282e-04 - val_loss: 1.5903e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.2017e-05 - acc: 1.1282e-04 - val_loss: 1.6362e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.3822e-05 - acc: 1.1282e-04 - val_loss: 2.0842e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.7274e-05 - acc: 1.1282e-04 - val_loss: 1.7780e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.7331e-05 - acc: 1.1282e-04 - val_loss: 1.4293e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.5184e-05 - acc: 1.1282e-04 - val_loss: 1.8915e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.9109e-05 - acc: 1.1282e-04 - val_loss: 1.2729e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.7943e-05 - acc: 1.1282e-04 - val_loss: 1.2892e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.8687e-05 - acc: 1.1282e-04 - val_loss: 1.3260e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6261e-05 - acc: 1.1282e-04 - val_loss: 2.1148e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.0812e-05 - acc: 1.1282e-04 - val_loss: 1.3690e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.6621e-05 - acc: 1.1282e-04 - val_loss: 1.7096e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.9776e-05 - acc: 1.1282e-04 - val_loss: 1.7478e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.1856e-05 - acc: 1.1282e-04 - val_loss: 2.3604e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.2604e-05 - acc: 1.1282e-04 - val_loss: 3.0071e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.9910e-05 - acc: 1.1282e-04 - val_loss: 1.7364e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.1745e-05 - acc: 1.1282e-04 - val_loss: 1.8459e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.6697e-05 - acc: 1.1282e-04 - val_loss: 1.2408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.8719e-05 - acc: 1.1282e-04 - val_loss: 2.1390e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 158us/step - loss: 7.6502e-05 - acc: 1.1282e-04 - val_loss: 1.1640e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.1821e-05 - acc: 1.1282e-04 - val_loss: 1.2150e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 7.2779e-05 - acc: 1.1282e-04 - val_loss: 1.9485e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.9787e-05 - acc: 1.1282e-04 - val_loss: 1.3653e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.9201e-05 - acc: 1.1282e-04 - val_loss: 1.2180e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.5593e-05 - acc: 1.1282e-04 - val_loss: 1.2878e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.6143e-05 - acc: 1.1282e-04 - val_loss: 1.5152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.1158e-05 - acc: 1.1282e-04 - val_loss: 2.2123e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.1765e-05 - acc: 1.1282e-04 - val_loss: 1.3291e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.2168e-05 - acc: 1.1282e-04 - val_loss: 1.8237e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.9062e-05 - acc: 1.1282e-04 - val_loss: 2.0577e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9924e-05 - acc: 1.1282e-04 - val_loss: 1.2700e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.8946e-05 - acc: 1.1282e-04 - val_loss: 1.9518e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.0944e-05 - acc: 1.1282e-04 - val_loss: 1.2217e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.2682e-05 - acc: 1.1282e-04 - val_loss: 2.0933e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.5675e-05 - acc: 1.1282e-04 - val_loss: 2.6792e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.9008e-05 - acc: 1.1282e-04 - val_loss: 1.3169e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.9915e-05 - acc: 1.1282e-04 - val_loss: 2.0528e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.8535e-05 - acc: 1.1282e-04 - val_loss: 1.3690e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.3525e-05 - acc: 1.1282e-04 - val_loss: 1.3267e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.5520e-05 - acc: 1.1282e-04 - val_loss: 1.2442e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.1294e-05 - acc: 1.1282e-04 - val_loss: 1.5602e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.0530e-05 - acc: 1.1282e-04 - val_loss: 2.4960e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.7044e-05 - acc: 1.1282e-04 - val_loss: 1.2978e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.0368e-05 - acc: 1.1282e-04 - val_loss: 2.2521e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.6842e-05 - acc: 1.1282e-04 - val_loss: 1.4691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.4790e-05 - acc: 1.1282e-04 - val_loss: 1.5091e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.3729e-05 - acc: 1.1282e-04 - val_loss: 2.6289e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.2877e-05 - acc: 1.1282e-04 - val_loss: 1.1571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.8248e-05 - acc: 1.1282e-04 - val_loss: 1.1742e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.6949e-05 - acc: 1.1282e-04 - val_loss: 1.6836e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.0580e-05 - acc: 1.1282e-04 - val_loss: 1.3849e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.4295e-05 - acc: 1.1282e-04 - val_loss: 1.1090e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.1407e-05 - acc: 1.1282e-04 - val_loss: 1.7521e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.2983e-05 - acc: 1.1282e-04 - val_loss: 1.2095e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.3378e-05 - acc: 1.1282e-04 - val_loss: 1.3232e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.3697e-05 - acc: 1.1282e-04 - val_loss: 1.3583e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.1776e-05 - acc: 1.1282e-04 - val_loss: 1.7320e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.6719e-05 - acc: 1.1282e-04 - val_loss: 1.1257e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0879e-05 - acc: 1.1282e-04 - val_loss: 1.1190e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.2751e-05 - acc: 1.1282e-04 - val_loss: 1.1226e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.2301e-05 - acc: 1.1282e-04 - val_loss: 1.1486e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.2705e-05 - acc: 1.1282e-04 - val_loss: 1.6420e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.2665e-05 - acc: 1.1282e-04 - val_loss: 1.1108e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9362e-05 - acc: 1.1282e-04 - val_loss: 1.3541e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.0370e-05 - acc: 1.1282e-04 - val_loss: 1.9218e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.5319e-05 - acc: 1.1282e-04 - val_loss: 1.4658e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 6.2095e-05 - acc: 1.1282e-04 - val_loss: 1.4348e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.7762e-05 - acc: 1.1282e-04 - val_loss: 1.7274e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 156us/step - loss: 6.1499e-05 - acc: 1.1282e-04 - val_loss: 1.1311e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.7057e-05 - acc: 1.1282e-04 - val_loss: 1.1057e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.3409e-05 - acc: 1.1282e-04 - val_loss: 1.1116e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.1674e-05 - acc: 1.1282e-04 - val_loss: 1.1858e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.0083e-05 - acc: 1.1282e-04 - val_loss: 1.6182e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.5871e-05 - acc: 1.1282e-04 - val_loss: 1.1379e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.4333e-05 - acc: 1.1282e-04 - val_loss: 1.2580e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.0740e-05 - acc: 1.1282e-04 - val_loss: 1.9556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.6355e-05 - acc: 1.1282e-04 - val_loss: 1.2519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8249e-05 - acc: 1.1282e-04 - val_loss: 2.7327e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8126e-05 - acc: 1.1282e-04 - val_loss: 1.2675e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.1643e-05 - acc: 1.1282e-04 - val_loss: 1.3452e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.7064e-05 - acc: 1.1282e-04 - val_loss: 1.9132e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.3462e-05 - acc: 1.1282e-04 - val_loss: 1.1216e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.4774e-05 - acc: 1.1282e-04 - val_loss: 1.3440e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.2227e-05 - acc: 1.1282e-04 - val_loss: 1.6058e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.0265e-05 - acc: 1.1282e-04 - val_loss: 1.2441e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7815e-05 - acc: 1.1282e-04 - val_loss: 1.0945e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.6485e-05 - acc: 1.1282e-04 - val_loss: 1.7578e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7367e-05 - acc: 1.1282e-04 - val_loss: 1.1381e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.8481e-05 - acc: 1.1282e-04 - val_loss: 1.4355e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.6877e-05 - acc: 1.1282e-04 - val_loss: 1.4940e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.1406e-05 - acc: 1.1282e-04 - val_loss: 2.9993e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.1533e-05 - acc: 1.1282e-04 - val_loss: 1.3000e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.0864e-05 - acc: 1.1282e-04 - val_loss: 1.3962e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.3013e-05 - acc: 1.1282e-04 - val_loss: 1.1123e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.2391e-05 - acc: 1.1282e-04 - val_loss: 1.1519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.7056e-05 - acc: 1.1282e-04 - val_loss: 1.2700e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.4246e-05 - acc: 1.1282e-04 - val_loss: 1.6877e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.8630e-05 - acc: 1.1282e-04 - val_loss: 1.0912e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.7664e-05 - acc: 1.1282e-04 - val_loss: 1.4152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.4551e-05 - acc: 1.1282e-04 - val_loss: 1.0763e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.4248e-05 - acc: 1.1282e-04 - val_loss: 1.7736e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.0248e-05 - acc: 1.1282e-04 - val_loss: 1.4229e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.7885e-05 - acc: 1.1282e-04 - val_loss: 1.5270e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 5.8641e-05 - acc: 1.1282e-04 - val_loss: 1.1336e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.2111e-05 - acc: 1.1282e-04 - val_loss: 1.1190e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.2476e-05 - acc: 1.1282e-04 - val_loss: 1.1292e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.1012e-05 - acc: 1.1282e-04 - val_loss: 1.0765e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.3646e-05 - acc: 1.1282e-04 - val_loss: 1.5005e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.2435e-05 - acc: 1.1282e-04 - val_loss: 1.0840e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.1179e-05 - acc: 1.1282e-04 - val_loss: 2.2508e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.4124e-05 - acc: 1.1282e-04 - val_loss: 1.8411e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0794e-05 - acc: 1.1282e-04 - val_loss: 1.4571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.8648e-05 - acc: 1.1282e-04 - val_loss: 1.0480e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.2729e-05 - acc: 1.1282e-04 - val_loss: 1.6803e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.7327e-05 - acc: 1.1282e-04 - val_loss: 1.0910e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 157us/step - loss: 5.3618e-05 - acc: 1.1282e-04 - val_loss: 2.2314e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.8734e-05 - acc: 1.1282e-04 - val_loss: 1.0746e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.1319e-05 - acc: 1.1282e-04 - val_loss: 1.2246e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.7959e-05 - acc: 1.1282e-04 - val_loss: 1.1184e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.2564e-05 - acc: 1.1282e-04 - val_loss: 1.7152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.7648e-05 - acc: 1.1282e-04 - val_loss: 1.4025e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.4209e-05 - acc: 1.1282e-04 - val_loss: 1.3914e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.8751e-05 - acc: 1.1282e-04 - val_loss: 1.5161e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.3528e-05 - acc: 1.1282e-04 - val_loss: 1.2892e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.3121e-05 - acc: 1.1282e-04 - val_loss: 1.1806e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.9870e-05 - acc: 1.1282e-04 - val_loss: 1.3489e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.8438e-05 - acc: 1.1282e-04 - val_loss: 1.0243e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.6870e-05 - acc: 1.1282e-04 - val_loss: 1.2090e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.6130e-05 - acc: 1.1282e-04 - val_loss: 1.0634e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.050\n",
            "TEMP MSE: 0.002\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_17 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 5s 521us/step - loss: 0.0170 - acc: 1.1282e-04 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.3579e-04 - acc: 1.1282e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.6944e-04 - acc: 1.1282e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.3719e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.6607e-04 - acc: 1.1282e-04 - val_loss: 7.2402e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.4668e-04 - acc: 1.1282e-04 - val_loss: 5.3531e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.4477e-04 - acc: 1.1282e-04 - val_loss: 3.6728e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.1171e-04 - acc: 1.1282e-04 - val_loss: 3.0721e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.9095e-04 - acc: 1.1282e-04 - val_loss: 2.6527e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.0042e-04 - acc: 1.1282e-04 - val_loss: 2.6110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.2507e-04 - acc: 1.1282e-04 - val_loss: 8.4739e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.1370e-04 - acc: 1.1282e-04 - val_loss: 9.6312e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.3077e-04 - acc: 1.1282e-04 - val_loss: 6.8497e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.7408e-04 - acc: 1.1282e-04 - val_loss: 2.6231e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.5726e-04 - acc: 1.1282e-04 - val_loss: 2.4439e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.4381e-04 - acc: 1.1282e-04 - val_loss: 2.5344e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.6860e-04 - acc: 1.1282e-04 - val_loss: 4.9597e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.7058e-04 - acc: 1.1282e-04 - val_loss: 3.4791e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.4483e-04 - acc: 1.1282e-04 - val_loss: 4.4342e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.4728e-04 - acc: 1.1282e-04 - val_loss: 2.8101e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.7145e-04 - acc: 1.1282e-04 - val_loss: 5.2167e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.5162e-04 - acc: 1.1282e-04 - val_loss: 2.9280e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 2.9404e-04 - acc: 1.1282e-04 - val_loss: 3.9001e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.4682e-04 - acc: 1.1282e-04 - val_loss: 2.3543e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.3968e-04 - acc: 1.1282e-04 - val_loss: 3.4622e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 2.3404e-04 - acc: 1.1282e-04 - val_loss: 2.4828e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.3560e-04 - acc: 1.1282e-04 - val_loss: 2.3637e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.3735e-04 - acc: 1.1282e-04 - val_loss: 4.1961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3930e-04 - acc: 1.1282e-04 - val_loss: 2.6301e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.2827e-04 - acc: 1.1282e-04 - val_loss: 2.1984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.4284e-04 - acc: 1.1282e-04 - val_loss: 3.6855e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.5215e-04 - acc: 1.1282e-04 - val_loss: 2.1373e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.2797e-04 - acc: 1.1282e-04 - val_loss: 3.1901e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.1814e-04 - acc: 1.1282e-04 - val_loss: 2.6848e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1889e-04 - acc: 1.1282e-04 - val_loss: 6.7706e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.3105e-04 - acc: 1.1282e-04 - val_loss: 2.7508e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.0986e-04 - acc: 1.1282e-04 - val_loss: 2.4709e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.1708e-04 - acc: 1.1282e-04 - val_loss: 2.2915e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.1850e-04 - acc: 1.1282e-04 - val_loss: 2.1347e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3493e-04 - acc: 1.1282e-04 - val_loss: 2.2478e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2091e-04 - acc: 1.1282e-04 - val_loss: 3.4103e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.1693e-04 - acc: 1.1282e-04 - val_loss: 2.1882e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.2126e-04 - acc: 1.1282e-04 - val_loss: 2.0447e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.0101e-04 - acc: 1.1282e-04 - val_loss: 3.6192e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.0837e-04 - acc: 1.1282e-04 - val_loss: 2.6637e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9735e-04 - acc: 1.1282e-04 - val_loss: 4.2440e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.1957e-04 - acc: 1.1282e-04 - val_loss: 3.4904e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.3252e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.3469e-04 - acc: 1.1282e-04 - val_loss: 2.1424e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9836e-04 - acc: 1.1282e-04 - val_loss: 2.0883e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9551e-04 - acc: 1.1282e-04 - val_loss: 6.1580e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.1541e-04 - acc: 1.1282e-04 - val_loss: 5.0313e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0172e-04 - acc: 1.1282e-04 - val_loss: 2.8246e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.8972e-04 - acc: 1.1282e-04 - val_loss: 2.7912e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.2139e-04 - acc: 1.1282e-04 - val_loss: 6.9649e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.1776e-04 - acc: 1.1282e-04 - val_loss: 2.1617e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.3783e-04 - acc: 1.1282e-04 - val_loss: 3.1701e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.0985e-04 - acc: 1.1282e-04 - val_loss: 2.8319e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.8150e-04 - acc: 1.1282e-04 - val_loss: 1.9764e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.8128e-04 - acc: 1.1282e-04 - val_loss: 1.9154e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.9611e-04 - acc: 1.1282e-04 - val_loss: 3.9372e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.2367e-04 - acc: 1.1282e-04 - val_loss: 3.6689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.8012e-04 - acc: 1.1282e-04 - val_loss: 2.7808e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.8384e-04 - acc: 1.1282e-04 - val_loss: 2.5978e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.8794e-04 - acc: 1.1282e-04 - val_loss: 2.4264e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.7587e-04 - acc: 1.1282e-04 - val_loss: 2.2580e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.8698e-04 - acc: 1.1282e-04 - val_loss: 1.8783e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.8078e-04 - acc: 1.1282e-04 - val_loss: 3.6689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.8402e-04 - acc: 1.1282e-04 - val_loss: 2.3358e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.7871e-04 - acc: 1.1282e-04 - val_loss: 2.7542e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.7922e-04 - acc: 1.1282e-04 - val_loss: 1.8719e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.7209e-04 - acc: 1.1282e-04 - val_loss: 3.3183e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.7606e-04 - acc: 1.1282e-04 - val_loss: 1.8854e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.5965e-04 - acc: 1.1282e-04 - val_loss: 2.6345e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5526e-04 - acc: 1.1282e-04 - val_loss: 1.8911e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.7931e-04 - acc: 1.1282e-04 - val_loss: 2.7476e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.6471e-04 - acc: 1.1282e-04 - val_loss: 1.6427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6001e-04 - acc: 1.1282e-04 - val_loss: 1.6978e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.6874e-04 - acc: 1.1282e-04 - val_loss: 1.7019e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.6453e-04 - acc: 1.1282e-04 - val_loss: 1.7356e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6272e-04 - acc: 1.1282e-04 - val_loss: 3.7362e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.5601e-04 - acc: 1.1282e-04 - val_loss: 1.6135e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.5620e-04 - acc: 1.1282e-04 - val_loss: 1.5573e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.5782e-04 - acc: 1.1282e-04 - val_loss: 3.6294e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5779e-04 - acc: 1.1282e-04 - val_loss: 2.5770e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5114e-04 - acc: 1.1282e-04 - val_loss: 3.3113e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6056e-04 - acc: 1.1282e-04 - val_loss: 2.0433e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.4698e-04 - acc: 1.1282e-04 - val_loss: 2.6982e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5819e-04 - acc: 1.1282e-04 - val_loss: 1.6455e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.5539e-04 - acc: 1.1282e-04 - val_loss: 2.2365e-04 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.8470e-04 - acc: 1.1282e-04 - val_loss: 2.8064e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9772e-04 - acc: 1.1282e-04 - val_loss: 3.5253e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.8900e-04 - acc: 1.1282e-04 - val_loss: 4.6493e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.5713e-04 - acc: 1.1282e-04 - val_loss: 1.7765e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.5765e-04 - acc: 1.1282e-04 - val_loss: 2.3046e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.4743e-04 - acc: 1.1282e-04 - val_loss: 1.6295e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3869e-04 - acc: 1.1282e-04 - val_loss: 1.6533e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.4314e-04 - acc: 1.1282e-04 - val_loss: 2.3711e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.4322e-04 - acc: 1.1282e-04 - val_loss: 1.3932e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4117e-04 - acc: 1.1282e-04 - val_loss: 1.3853e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5109e-04 - acc: 1.1282e-04 - val_loss: 1.4749e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.4527e-04 - acc: 1.1282e-04 - val_loss: 1.4804e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.4027e-04 - acc: 1.1282e-04 - val_loss: 1.6824e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.4834e-04 - acc: 1.1282e-04 - val_loss: 3.2756e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4332e-04 - acc: 1.1282e-04 - val_loss: 1.8949e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.3470e-04 - acc: 1.1282e-04 - val_loss: 1.4569e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.3612e-04 - acc: 1.1282e-04 - val_loss: 1.3635e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4795e-04 - acc: 1.1282e-04 - val_loss: 2.4089e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4236e-04 - acc: 1.1282e-04 - val_loss: 1.9557e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2956e-04 - acc: 1.1282e-04 - val_loss: 3.0488e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2965e-04 - acc: 1.1282e-04 - val_loss: 2.9569e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2820e-04 - acc: 1.1282e-04 - val_loss: 2.0463e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3720e-04 - acc: 1.1282e-04 - val_loss: 1.3926e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2509e-04 - acc: 1.1282e-04 - val_loss: 1.3611e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2704e-04 - acc: 1.1282e-04 - val_loss: 1.6981e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2348e-04 - acc: 1.1282e-04 - val_loss: 1.4070e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.4009e-04 - acc: 1.1282e-04 - val_loss: 4.1304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2999e-04 - acc: 1.1282e-04 - val_loss: 2.5198e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.2902e-04 - acc: 1.1282e-04 - val_loss: 1.4658e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.2844e-04 - acc: 1.1282e-04 - val_loss: 1.3735e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3834e-04 - acc: 1.1282e-04 - val_loss: 1.5603e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3413e-04 - acc: 1.1282e-04 - val_loss: 1.9738e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2576e-04 - acc: 1.1282e-04 - val_loss: 2.4866e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2720e-04 - acc: 1.1282e-04 - val_loss: 1.7682e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.1454e-04 - acc: 1.1282e-04 - val_loss: 1.5979e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1937e-04 - acc: 1.1282e-04 - val_loss: 1.5480e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3506e-04 - acc: 1.1282e-04 - val_loss: 1.6014e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.2922e-04 - acc: 1.1282e-04 - val_loss: 1.3220e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2378e-04 - acc: 1.1282e-04 - val_loss: 1.4299e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.2152e-04 - acc: 1.1282e-04 - val_loss: 2.1575e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2639e-04 - acc: 1.1282e-04 - val_loss: 1.5430e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2249e-04 - acc: 1.1282e-04 - val_loss: 1.6833e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2633e-04 - acc: 1.1282e-04 - val_loss: 3.1382e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1244e-04 - acc: 1.1282e-04 - val_loss: 1.5213e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2325e-04 - acc: 1.1282e-04 - val_loss: 1.3427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1549e-04 - acc: 1.1282e-04 - val_loss: 1.3293e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2532e-04 - acc: 1.1282e-04 - val_loss: 4.1471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2008e-04 - acc: 1.1282e-04 - val_loss: 3.6318e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0973e-04 - acc: 1.1282e-04 - val_loss: 1.6035e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0969e-04 - acc: 1.1282e-04 - val_loss: 2.5630e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2103e-04 - acc: 1.1282e-04 - val_loss: 1.3969e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 1.0704e-04 - acc: 1.1282e-04 - val_loss: 2.4614e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1216e-04 - acc: 1.1282e-04 - val_loss: 1.3631e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1493e-04 - acc: 1.1282e-04 - val_loss: 2.5841e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.1039e-04 - acc: 1.1282e-04 - val_loss: 1.4327e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1862e-04 - acc: 1.1282e-04 - val_loss: 4.5511e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1418e-04 - acc: 1.1282e-04 - val_loss: 1.3760e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0848e-04 - acc: 1.1282e-04 - val_loss: 1.5899e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.1356e-04 - acc: 1.1282e-04 - val_loss: 2.3557e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0949e-04 - acc: 1.1282e-04 - val_loss: 2.7688e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0930e-04 - acc: 1.1282e-04 - val_loss: 2.7393e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1935e-04 - acc: 1.1282e-04 - val_loss: 1.7290e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0892e-04 - acc: 1.1282e-04 - val_loss: 2.4842e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0118e-04 - acc: 1.1282e-04 - val_loss: 1.4550e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.9156e-05 - acc: 1.1282e-04 - val_loss: 3.0693e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0831e-04 - acc: 1.1282e-04 - val_loss: 1.4704e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1550e-04 - acc: 1.1282e-04 - val_loss: 1.9953e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.6244e-05 - acc: 1.1282e-04 - val_loss: 1.7182e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.8490e-05 - acc: 1.1282e-04 - val_loss: 3.4060e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0400e-04 - acc: 1.1282e-04 - val_loss: 1.7397e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0514e-04 - acc: 1.1282e-04 - val_loss: 5.0571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0754e-04 - acc: 1.1282e-04 - val_loss: 1.3131e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0805e-04 - acc: 1.1282e-04 - val_loss: 1.3302e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.1161e-04 - acc: 1.1282e-04 - val_loss: 4.0991e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1069e-04 - acc: 1.1282e-04 - val_loss: 2.1646e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.4340e-05 - acc: 1.1282e-04 - val_loss: 2.0618e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.8046e-05 - acc: 1.1282e-04 - val_loss: 2.9926e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 9.6127e-05 - acc: 1.1282e-04 - val_loss: 1.3072e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0938e-04 - acc: 1.1282e-04 - val_loss: 3.6212e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0154e-04 - acc: 1.1282e-04 - val_loss: 1.5755e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.5086e-05 - acc: 1.1282e-04 - val_loss: 1.4332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.2627e-05 - acc: 1.1282e-04 - val_loss: 3.0847e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.9794e-05 - acc: 1.1282e-04 - val_loss: 1.3244e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.2506e-05 - acc: 1.1282e-04 - val_loss: 2.9250e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.5380e-05 - acc: 1.1282e-04 - val_loss: 2.1828e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.3567e-05 - acc: 1.1282e-04 - val_loss: 4.1058e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 9.3509e-05 - acc: 1.1282e-04 - val_loss: 2.7239e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.7049e-05 - acc: 1.1282e-04 - val_loss: 1.4126e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.8994e-05 - acc: 1.1282e-04 - val_loss: 6.0317e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0478e-04 - acc: 1.1282e-04 - val_loss: 3.6931e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 9.9696e-05 - acc: 1.1282e-04 - val_loss: 2.5138e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0365e-04 - acc: 1.1282e-04 - val_loss: 2.9332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.0893e-04 - acc: 1.1282e-04 - val_loss: 1.4657e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.0342e-05 - acc: 1.1282e-04 - val_loss: 1.3144e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.9265e-05 - acc: 1.1282e-04 - val_loss: 1.8556e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.2413e-05 - acc: 1.1282e-04 - val_loss: 1.6182e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.6578e-05 - acc: 1.1282e-04 - val_loss: 2.1417e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.2207e-05 - acc: 1.1282e-04 - val_loss: 1.4835e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0427e-04 - acc: 1.1282e-04 - val_loss: 2.0691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.0485e-05 - acc: 1.1282e-04 - val_loss: 1.3211e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.5090e-05 - acc: 1.1282e-04 - val_loss: 3.5998e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.5554e-05 - acc: 1.1282e-04 - val_loss: 1.3658e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.1528e-05 - acc: 1.1282e-04 - val_loss: 1.9503e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.6218e-05 - acc: 1.1282e-04 - val_loss: 1.9265e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.8317e-05 - acc: 1.1282e-04 - val_loss: 1.7320e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.5265e-05 - acc: 1.1282e-04 - val_loss: 1.7225e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.4311e-05 - acc: 1.1282e-04 - val_loss: 1.5091e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.6159e-05 - acc: 1.1282e-04 - val_loss: 3.0427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.4563e-05 - acc: 1.1282e-04 - val_loss: 1.3562e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.1450e-05 - acc: 1.1282e-04 - val_loss: 1.4261e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.4287e-05 - acc: 1.1282e-04 - val_loss: 1.3141e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.6557e-05 - acc: 1.1282e-04 - val_loss: 2.1758e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.6302e-05 - acc: 1.1282e-04 - val_loss: 1.3015e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.3092e-05 - acc: 1.1282e-04 - val_loss: 2.2501e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.3730e-05 - acc: 1.1282e-04 - val_loss: 1.6841e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.8914e-05 - acc: 1.1282e-04 - val_loss: 2.8076e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.4066e-05 - acc: 1.1282e-04 - val_loss: 1.2863e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.5501e-05 - acc: 1.1282e-04 - val_loss: 2.3172e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.0756e-05 - acc: 1.1282e-04 - val_loss: 1.3010e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.1931e-05 - acc: 1.1282e-04 - val_loss: 1.6476e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.1011e-05 - acc: 1.1282e-04 - val_loss: 1.6655e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.7938e-05 - acc: 1.1282e-04 - val_loss: 1.3949e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.0146e-05 - acc: 1.1282e-04 - val_loss: 1.5715e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.6113e-05 - acc: 1.1282e-04 - val_loss: 1.2814e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.1114e-05 - acc: 1.1282e-04 - val_loss: 1.2901e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.3001e-05 - acc: 1.1282e-04 - val_loss: 1.3585e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.8815e-05 - acc: 1.1282e-04 - val_loss: 1.2576e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.0849e-05 - acc: 1.1282e-04 - val_loss: 1.3149e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.6950e-05 - acc: 1.1282e-04 - val_loss: 1.5302e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 9.2074e-05 - acc: 1.1282e-04 - val_loss: 1.4430e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.4971e-05 - acc: 1.1282e-04 - val_loss: 2.8794e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.1628e-05 - acc: 1.1282e-04 - val_loss: 1.7385e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.5517e-05 - acc: 1.1282e-04 - val_loss: 1.7961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.3827e-05 - acc: 1.1282e-04 - val_loss: 1.7026e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1346e-05 - acc: 1.1282e-04 - val_loss: 1.3406e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.8436e-05 - acc: 1.1282e-04 - val_loss: 1.2437e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.7640e-05 - acc: 1.1282e-04 - val_loss: 1.7832e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1527e-05 - acc: 1.1282e-04 - val_loss: 1.3470e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.1591e-05 - acc: 1.1282e-04 - val_loss: 1.4790e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.1422e-05 - acc: 1.1282e-04 - val_loss: 3.2373e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6218e-05 - acc: 1.1282e-04 - val_loss: 1.6042e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.2671e-05 - acc: 1.1282e-04 - val_loss: 1.2433e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.2678e-05 - acc: 1.1282e-04 - val_loss: 1.2597e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 8.6675e-05 - acc: 1.1282e-04 - val_loss: 2.5732e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 8.7497e-05 - acc: 1.1282e-04 - val_loss: 1.3151e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.9406e-05 - acc: 1.1282e-04 - val_loss: 1.9860e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.1860e-05 - acc: 1.1282e-04 - val_loss: 1.2340e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.1084e-05 - acc: 1.1282e-04 - val_loss: 5.8632e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.0927e-05 - acc: 1.1282e-04 - val_loss: 1.7678e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.5967e-05 - acc: 1.1282e-04 - val_loss: 1.4058e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.9646e-05 - acc: 1.1282e-04 - val_loss: 1.3209e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.0885e-05 - acc: 1.1282e-04 - val_loss: 1.7604e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.9776e-05 - acc: 1.1282e-04 - val_loss: 1.6836e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.4659e-05 - acc: 1.1282e-04 - val_loss: 1.5780e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.2471e-05 - acc: 1.1282e-04 - val_loss: 1.3369e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.8744e-05 - acc: 1.1282e-04 - val_loss: 1.2017e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.0869e-05 - acc: 1.1282e-04 - val_loss: 2.3881e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.7481e-05 - acc: 1.1282e-04 - val_loss: 1.1877e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.2943e-05 - acc: 1.1282e-04 - val_loss: 1.4001e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.0158e-05 - acc: 1.1282e-04 - val_loss: 1.2527e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.9325e-05 - acc: 1.1282e-04 - val_loss: 1.9924e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.3392e-05 - acc: 1.1282e-04 - val_loss: 1.1749e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.0357e-05 - acc: 1.1282e-04 - val_loss: 1.3365e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.3175e-05 - acc: 1.1282e-04 - val_loss: 1.2200e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.4013e-05 - acc: 1.1282e-04 - val_loss: 1.3691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.2382e-05 - acc: 1.1282e-04 - val_loss: 1.3147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 6.6940e-05 - acc: 1.1282e-04 - val_loss: 1.3346e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.6085e-05 - acc: 1.1282e-04 - val_loss: 1.2985e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 7.0819e-05 - acc: 1.1282e-04 - val_loss: 1.5424e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.7202e-05 - acc: 1.1282e-04 - val_loss: 1.7806e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.5532e-05 - acc: 1.1282e-04 - val_loss: 1.2758e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.0126e-05 - acc: 1.1282e-04 - val_loss: 1.1471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.0523e-05 - acc: 1.1282e-04 - val_loss: 1.3329e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.1848e-05 - acc: 1.1282e-04 - val_loss: 1.4104e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.5932e-05 - acc: 1.1282e-04 - val_loss: 1.1502e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.3330e-05 - acc: 1.1282e-04 - val_loss: 1.4990e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.2533e-05 - acc: 1.1282e-04 - val_loss: 1.1986e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.0592e-05 - acc: 1.1282e-04 - val_loss: 1.2059e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.2593e-05 - acc: 1.1282e-04 - val_loss: 1.2279e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.3754e-05 - acc: 1.1282e-04 - val_loss: 1.8197e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.2777e-05 - acc: 1.1282e-04 - val_loss: 1.9719e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.5504e-05 - acc: 1.1282e-04 - val_loss: 1.1387e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.7142e-05 - acc: 1.1282e-04 - val_loss: 2.0029e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.4570e-05 - acc: 1.1282e-04 - val_loss: 1.3124e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.0985e-05 - acc: 1.1282e-04 - val_loss: 1.4289e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.0651e-05 - acc: 1.1282e-04 - val_loss: 1.2899e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.1749e-05 - acc: 1.1282e-04 - val_loss: 1.3145e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.9008e-05 - acc: 1.1282e-04 - val_loss: 1.7424e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.2582e-05 - acc: 1.1282e-04 - val_loss: 1.1725e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.6877e-05 - acc: 1.1282e-04 - val_loss: 1.1733e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.7688e-05 - acc: 1.1282e-04 - val_loss: 1.8039e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.0745e-05 - acc: 1.1282e-04 - val_loss: 1.1548e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.9174e-05 - acc: 1.1282e-04 - val_loss: 1.2110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.1428e-05 - acc: 1.1282e-04 - val_loss: 1.3036e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.6396e-05 - acc: 1.1282e-04 - val_loss: 1.2692e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.0961e-05 - acc: 1.1282e-04 - val_loss: 1.1652e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.8554e-05 - acc: 1.1282e-04 - val_loss: 1.2697e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.5144e-05 - acc: 1.1282e-04 - val_loss: 1.5190e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.0970e-05 - acc: 1.1282e-04 - val_loss: 1.1356e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.9775e-05 - acc: 1.1282e-04 - val_loss: 1.6326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.2643e-05 - acc: 1.1282e-04 - val_loss: 1.6603e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.2874e-05 - acc: 1.1282e-04 - val_loss: 1.1332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.6785e-05 - acc: 1.1282e-04 - val_loss: 1.2170e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.6803e-05 - acc: 1.1282e-04 - val_loss: 1.1715e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.0592e-05 - acc: 1.1282e-04 - val_loss: 1.3005e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.0417e-05 - acc: 1.1282e-04 - val_loss: 1.2075e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.5166e-05 - acc: 1.1282e-04 - val_loss: 1.9086e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.5288e-05 - acc: 1.1282e-04 - val_loss: 1.8347e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.8242e-05 - acc: 1.1282e-04 - val_loss: 1.1788e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.056\n",
            "TEMP MSE: 0.003\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 5s 570us/step - loss: 0.0179 - acc: 1.1282e-04 - val_loss: 0.0084 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.0726e-04 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.1949e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.1910e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.7859e-04 - acc: 1.1282e-04 - val_loss: 8.0042e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.4538e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.3998e-04 - acc: 1.1282e-04 - val_loss: 3.6731e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.0561e-04 - acc: 1.1282e-04 - val_loss: 3.0927e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.2618e-04 - acc: 1.1282e-04 - val_loss: 3.1896e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.7399e-04 - acc: 1.1282e-04 - val_loss: 2.6617e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.6689e-04 - acc: 1.1282e-04 - val_loss: 2.5628e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.7196e-04 - acc: 1.1282e-04 - val_loss: 5.7291e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.7508e-04 - acc: 1.1282e-04 - val_loss: 3.2705e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.7369e-04 - acc: 1.1282e-04 - val_loss: 3.7569e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.7297e-04 - acc: 1.1282e-04 - val_loss: 2.6255e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.6019e-04 - acc: 1.1282e-04 - val_loss: 4.7428e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 3.6530e-04 - acc: 1.1282e-04 - val_loss: 2.4896e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.4405e-04 - acc: 1.1282e-04 - val_loss: 2.9943e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 3.7180e-04 - acc: 1.1282e-04 - val_loss: 2.5850e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.9305e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.5906e-04 - acc: 1.1282e-04 - val_loss: 3.6497e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.3705e-04 - acc: 1.1282e-04 - val_loss: 5.8075e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.2385e-04 - acc: 1.1282e-04 - val_loss: 3.9642e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.3511e-04 - acc: 1.1282e-04 - val_loss: 4.2693e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.4255e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.4862e-04 - acc: 1.1282e-04 - val_loss: 2.7743e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.2269e-04 - acc: 1.1282e-04 - val_loss: 5.7913e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 3.2800e-04 - acc: 1.1282e-04 - val_loss: 4.8687e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.0948e-04 - acc: 1.1282e-04 - val_loss: 4.2892e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.3192e-04 - acc: 1.1282e-04 - val_loss: 2.2908e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.1010e-04 - acc: 1.1282e-04 - val_loss: 2.2867e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.2078e-04 - acc: 1.1282e-04 - val_loss: 2.8572e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.3915e-04 - acc: 1.1282e-04 - val_loss: 3.6240e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.1620e-04 - acc: 1.1282e-04 - val_loss: 2.8674e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.9476e-04 - acc: 1.1282e-04 - val_loss: 5.0007e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.0291e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.2197e-04 - acc: 1.1282e-04 - val_loss: 2.3357e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.7443e-04 - acc: 1.1282e-04 - val_loss: 5.6146e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.9746e-04 - acc: 1.1282e-04 - val_loss: 2.9308e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.6728e-04 - acc: 1.1282e-04 - val_loss: 2.8801e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.8923e-04 - acc: 1.1282e-04 - val_loss: 9.7437e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.5494e-04 - acc: 1.1282e-04 - val_loss: 2.5529e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 3.4261e-04 - acc: 1.1282e-04 - val_loss: 3.5040e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.1128e-04 - acc: 1.1282e-04 - val_loss: 3.8481e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.9680e-04 - acc: 1.1282e-04 - val_loss: 8.7110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.8433e-04 - acc: 1.1282e-04 - val_loss: 2.7377e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.6638e-04 - acc: 1.1282e-04 - val_loss: 2.1893e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.5734e-04 - acc: 1.1282e-04 - val_loss: 3.6994e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.7273e-04 - acc: 1.1282e-04 - val_loss: 6.2540e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.9519e-04 - acc: 1.1282e-04 - val_loss: 2.1469e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.7687e-04 - acc: 1.1282e-04 - val_loss: 4.5414e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.4548e-04 - acc: 1.1282e-04 - val_loss: 3.3958e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.4679e-04 - acc: 1.1282e-04 - val_loss: 3.2648e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3356e-04 - acc: 1.1282e-04 - val_loss: 4.2144e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.7800e-04 - acc: 1.1282e-04 - val_loss: 6.0932e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.4874e-04 - acc: 1.1282e-04 - val_loss: 2.5283e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.3773e-04 - acc: 1.1282e-04 - val_loss: 2.1142e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.4156e-04 - acc: 1.1282e-04 - val_loss: 6.5887e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.7176e-04 - acc: 1.1282e-04 - val_loss: 2.2085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.4441e-04 - acc: 1.1282e-04 - val_loss: 2.1494e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.3741e-04 - acc: 1.1282e-04 - val_loss: 1.9797e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.3603e-04 - acc: 1.1282e-04 - val_loss: 2.5489e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.4361e-04 - acc: 1.1282e-04 - val_loss: 4.4722e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.4311e-04 - acc: 1.1282e-04 - val_loss: 2.7422e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.5300e-04 - acc: 1.1282e-04 - val_loss: 2.6122e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.6423e-04 - acc: 1.1282e-04 - val_loss: 3.9535e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.3598e-04 - acc: 1.1282e-04 - val_loss: 2.3075e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.3811e-04 - acc: 1.1282e-04 - val_loss: 3.3947e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.5376e-04 - acc: 1.1282e-04 - val_loss: 3.3944e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.2021e-04 - acc: 1.1282e-04 - val_loss: 2.1129e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.2261e-04 - acc: 1.1282e-04 - val_loss: 1.9194e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.2116e-04 - acc: 1.1282e-04 - val_loss: 3.4839e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.1554e-04 - acc: 1.1282e-04 - val_loss: 2.5349e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.1451e-04 - acc: 1.1282e-04 - val_loss: 2.2594e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.1526e-04 - acc: 1.1282e-04 - val_loss: 3.5689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.1696e-04 - acc: 1.1282e-04 - val_loss: 2.0800e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.2125e-04 - acc: 1.1282e-04 - val_loss: 2.1056e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.1179e-04 - acc: 1.1282e-04 - val_loss: 3.4321e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.1349e-04 - acc: 1.1282e-04 - val_loss: 5.2641e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.1246e-04 - acc: 1.1282e-04 - val_loss: 4.7419e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.0766e-04 - acc: 1.1282e-04 - val_loss: 6.7862e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.1439e-04 - acc: 1.1282e-04 - val_loss: 1.6692e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.0064e-04 - acc: 1.1282e-04 - val_loss: 2.1440e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9869e-04 - acc: 1.1282e-04 - val_loss: 2.3789e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9695e-04 - acc: 1.1282e-04 - val_loss: 3.5149e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.0590e-04 - acc: 1.1282e-04 - val_loss: 3.2977e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9576e-04 - acc: 1.1282e-04 - val_loss: 4.1460e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9337e-04 - acc: 1.1282e-04 - val_loss: 4.1260e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.1999e-04 - acc: 1.1282e-04 - val_loss: 1.8555e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.9497e-04 - acc: 1.1282e-04 - val_loss: 1.5761e-04 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.9139e-04 - acc: 1.1282e-04 - val_loss: 1.6328e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.8597e-04 - acc: 1.1282e-04 - val_loss: 3.2989e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.7501e-04 - acc: 1.1282e-04 - val_loss: 3.1325e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.7241e-04 - acc: 1.1282e-04 - val_loss: 2.9012e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.7495e-04 - acc: 1.1282e-04 - val_loss: 2.1697e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.7890e-04 - acc: 1.1282e-04 - val_loss: 6.1110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.6386e-04 - acc: 1.1282e-04 - val_loss: 2.4921e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.6833e-04 - acc: 1.1282e-04 - val_loss: 2.3964e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.6154e-04 - acc: 1.1282e-04 - val_loss: 7.1959e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7521e-04 - acc: 1.1282e-04 - val_loss: 2.0487e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7766e-04 - acc: 1.1282e-04 - val_loss: 3.3835e-04 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.6204e-04 - acc: 1.1282e-04 - val_loss: 1.8299e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5564e-04 - acc: 1.1282e-04 - val_loss: 2.1825e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6685e-04 - acc: 1.1282e-04 - val_loss: 1.7664e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.6368e-04 - acc: 1.1282e-04 - val_loss: 2.5941e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6429e-04 - acc: 1.1282e-04 - val_loss: 4.7929e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.6329e-04 - acc: 1.1282e-04 - val_loss: 1.8747e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.5010e-04 - acc: 1.1282e-04 - val_loss: 1.9249e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4615e-04 - acc: 1.1282e-04 - val_loss: 2.0271e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.5471e-04 - acc: 1.1282e-04 - val_loss: 4.1799e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5124e-04 - acc: 1.1282e-04 - val_loss: 1.7981e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6315e-04 - acc: 1.1282e-04 - val_loss: 4.8284e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.8188e-04 - acc: 1.1282e-04 - val_loss: 5.3083e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.4094e-04 - acc: 1.1282e-04 - val_loss: 2.5886e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.5219e-04 - acc: 1.1282e-04 - val_loss: 4.0266e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4409e-04 - acc: 1.1282e-04 - val_loss: 1.4412e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3698e-04 - acc: 1.1282e-04 - val_loss: 1.6958e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.3774e-04 - acc: 1.1282e-04 - val_loss: 2.5019e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.3121e-04 - acc: 1.1282e-04 - val_loss: 1.8273e-04 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2841e-04 - acc: 1.1282e-04 - val_loss: 4.1389e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.6448e-04 - acc: 1.1282e-04 - val_loss: 1.6117e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.6208e-04 - acc: 1.1282e-04 - val_loss: 5.3030e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5406e-04 - acc: 1.1282e-04 - val_loss: 2.3911e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.4141e-04 - acc: 1.1282e-04 - val_loss: 1.8195e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3940e-04 - acc: 1.1282e-04 - val_loss: 1.5487e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2306e-04 - acc: 1.1282e-04 - val_loss: 2.9418e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2688e-04 - acc: 1.1282e-04 - val_loss: 1.7799e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3085e-04 - acc: 1.1282e-04 - val_loss: 2.7607e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2126e-04 - acc: 1.1282e-04 - val_loss: 2.9088e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2867e-04 - acc: 1.1282e-04 - val_loss: 3.1155e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1743e-04 - acc: 1.1282e-04 - val_loss: 1.5233e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2199e-04 - acc: 1.1282e-04 - val_loss: 1.4216e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3066e-04 - acc: 1.1282e-04 - val_loss: 1.4147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1104e-04 - acc: 1.1282e-04 - val_loss: 2.3846e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0936e-04 - acc: 1.1282e-04 - val_loss: 2.8039e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.1807e-04 - acc: 1.1282e-04 - val_loss: 3.6112e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1261e-04 - acc: 1.1282e-04 - val_loss: 1.4641e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.1676e-04 - acc: 1.1282e-04 - val_loss: 2.0519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 1.1194e-04 - acc: 1.1282e-04 - val_loss: 3.5287e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1432e-04 - acc: 1.1282e-04 - val_loss: 1.3512e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1200e-04 - acc: 1.1282e-04 - val_loss: 2.0876e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1775e-04 - acc: 1.1282e-04 - val_loss: 1.7655e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1161e-04 - acc: 1.1282e-04 - val_loss: 3.4973e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0689e-04 - acc: 1.1282e-04 - val_loss: 1.3978e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1118e-04 - acc: 1.1282e-04 - val_loss: 1.3427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2265e-04 - acc: 1.1282e-04 - val_loss: 2.5352e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1825e-04 - acc: 1.1282e-04 - val_loss: 3.9740e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1694e-04 - acc: 1.1282e-04 - val_loss: 1.9149e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.9827e-05 - acc: 1.1282e-04 - val_loss: 2.1110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0561e-04 - acc: 1.1282e-04 - val_loss: 1.3172e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.6439e-05 - acc: 1.1282e-04 - val_loss: 2.0961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.7743e-05 - acc: 1.1282e-04 - val_loss: 1.8006e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.8604e-05 - acc: 1.1282e-04 - val_loss: 2.5008e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0387e-04 - acc: 1.1282e-04 - val_loss: 1.3722e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.6219e-05 - acc: 1.1282e-04 - val_loss: 2.1747e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 1.0074e-04 - acc: 1.1282e-04 - val_loss: 1.3871e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0609e-04 - acc: 1.1282e-04 - val_loss: 3.2593e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0677e-04 - acc: 1.1282e-04 - val_loss: 1.9949e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0031e-04 - acc: 1.1282e-04 - val_loss: 2.7032e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.1299e-05 - acc: 1.1282e-04 - val_loss: 2.3381e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0474e-04 - acc: 1.1282e-04 - val_loss: 1.2769e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.2597e-05 - acc: 1.1282e-04 - val_loss: 1.4421e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.9933e-05 - acc: 1.1282e-04 - val_loss: 2.3183e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.2219e-05 - acc: 1.1282e-04 - val_loss: 1.2984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.6302e-05 - acc: 1.1282e-04 - val_loss: 2.0464e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.9282e-05 - acc: 1.1282e-04 - val_loss: 1.5107e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.4316e-05 - acc: 1.1282e-04 - val_loss: 1.5785e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.6210e-05 - acc: 1.1282e-04 - val_loss: 1.8711e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0449e-04 - acc: 1.1282e-04 - val_loss: 2.7943e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.7354e-05 - acc: 1.1282e-04 - val_loss: 1.3096e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.1237e-05 - acc: 1.1282e-04 - val_loss: 1.3660e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0084e-04 - acc: 1.1282e-04 - val_loss: 1.3341e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.4934e-05 - acc: 1.1282e-04 - val_loss: 1.4788e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0113e-04 - acc: 1.1282e-04 - val_loss: 3.1707e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0002e-04 - acc: 1.1282e-04 - val_loss: 1.3944e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.8026e-05 - acc: 1.1282e-04 - val_loss: 2.5517e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.5420e-05 - acc: 1.1282e-04 - val_loss: 1.2442e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.1047e-05 - acc: 1.1282e-04 - val_loss: 3.8558e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.5024e-05 - acc: 1.1282e-04 - val_loss: 2.6957e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1008e-04 - acc: 1.1282e-04 - val_loss: 2.6170e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0654e-04 - acc: 1.1282e-04 - val_loss: 3.9032e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.8414e-05 - acc: 1.1282e-04 - val_loss: 2.2838e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.4990e-05 - acc: 1.1282e-04 - val_loss: 2.1791e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.9991e-05 - acc: 1.1282e-04 - val_loss: 1.3566e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.0398e-04 - acc: 1.1282e-04 - val_loss: 1.5132e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.7111e-05 - acc: 1.1282e-04 - val_loss: 1.6064e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.9492e-05 - acc: 1.1282e-04 - val_loss: 3.1372e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0329e-04 - acc: 1.1282e-04 - val_loss: 2.1471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0263e-04 - acc: 1.1282e-04 - val_loss: 3.1531e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0347e-04 - acc: 1.1282e-04 - val_loss: 3.0869e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.7975e-05 - acc: 1.1282e-04 - val_loss: 1.2177e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.6796e-05 - acc: 1.1282e-04 - val_loss: 1.2548e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.9082e-05 - acc: 1.1282e-04 - val_loss: 3.4085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.9411e-05 - acc: 1.1282e-04 - val_loss: 1.2731e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.2113e-05 - acc: 1.1282e-04 - val_loss: 1.2411e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 8.2338e-05 - acc: 1.1282e-04 - val_loss: 2.0027e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.0776e-05 - acc: 1.1282e-04 - val_loss: 1.1744e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.5236e-05 - acc: 1.1282e-04 - val_loss: 1.7385e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.2214e-05 - acc: 1.1282e-04 - val_loss: 1.2762e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.4278e-05 - acc: 1.1282e-04 - val_loss: 1.3906e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.5890e-05 - acc: 1.1282e-04 - val_loss: 1.2111e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.4240e-05 - acc: 1.1282e-04 - val_loss: 1.3320e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.1511e-05 - acc: 1.1282e-04 - val_loss: 1.1834e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.4045e-05 - acc: 1.1282e-04 - val_loss: 1.1725e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.8140e-05 - acc: 1.1282e-04 - val_loss: 1.2045e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.1051e-05 - acc: 1.1282e-04 - val_loss: 1.1996e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 8.0247e-05 - acc: 1.1282e-04 - val_loss: 1.1856e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 8.9231e-05 - acc: 1.1282e-04 - val_loss: 3.3001e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.1165e-05 - acc: 1.1282e-04 - val_loss: 1.2232e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.6555e-05 - acc: 1.1282e-04 - val_loss: 2.9488e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.8214e-05 - acc: 1.1282e-04 - val_loss: 1.2968e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.2014e-05 - acc: 1.1282e-04 - val_loss: 1.2302e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.9213e-05 - acc: 1.1282e-04 - val_loss: 2.4705e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.1155e-05 - acc: 1.1282e-04 - val_loss: 1.1592e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.0196e-05 - acc: 1.1282e-04 - val_loss: 2.1023e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 9.3581e-05 - acc: 1.1282e-04 - val_loss: 1.7363e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.2665e-05 - acc: 1.1282e-04 - val_loss: 1.8909e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.3135e-05 - acc: 1.1282e-04 - val_loss: 1.6636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.9881e-05 - acc: 1.1282e-04 - val_loss: 1.1944e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 8.5758e-05 - acc: 1.1282e-04 - val_loss: 1.9191e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.0542e-05 - acc: 1.1282e-04 - val_loss: 1.2317e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.8366e-05 - acc: 1.1282e-04 - val_loss: 1.1394e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.3136e-05 - acc: 1.1282e-04 - val_loss: 1.5897e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.7608e-05 - acc: 1.1282e-04 - val_loss: 1.4007e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.8634e-05 - acc: 1.1282e-04 - val_loss: 1.6376e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.9722e-05 - acc: 1.1282e-04 - val_loss: 2.1615e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.7999e-05 - acc: 1.1282e-04 - val_loss: 1.1528e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.8605e-05 - acc: 1.1282e-04 - val_loss: 2.0270e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.2115e-05 - acc: 1.1282e-04 - val_loss: 1.2429e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.4999e-05 - acc: 1.1282e-04 - val_loss: 1.4128e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.2385e-05 - acc: 1.1282e-04 - val_loss: 1.4092e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.2214e-05 - acc: 1.1282e-04 - val_loss: 1.1550e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.8470e-05 - acc: 1.1282e-04 - val_loss: 1.9368e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.9091e-05 - acc: 1.1282e-04 - val_loss: 1.3714e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.6369e-05 - acc: 1.1282e-04 - val_loss: 1.8299e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.9114e-05 - acc: 1.1282e-04 - val_loss: 1.3777e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 8.1801e-05 - acc: 1.1282e-04 - val_loss: 1.3829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.6048e-05 - acc: 1.1282e-04 - val_loss: 1.8812e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.0542e-05 - acc: 1.1282e-04 - val_loss: 1.1701e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.6249e-05 - acc: 1.1282e-04 - val_loss: 1.1306e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.1532e-05 - acc: 1.1282e-04 - val_loss: 1.3615e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.8385e-05 - acc: 1.1282e-04 - val_loss: 1.1847e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.4619e-05 - acc: 1.1282e-04 - val_loss: 1.9332e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.9191e-05 - acc: 1.1282e-04 - val_loss: 3.2911e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 8.5636e-05 - acc: 1.1282e-04 - val_loss: 1.4994e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 8.2560e-05 - acc: 1.1282e-04 - val_loss: 2.3050e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.1474e-05 - acc: 1.1282e-04 - val_loss: 1.7815e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.0566e-05 - acc: 1.1282e-04 - val_loss: 1.9010e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 7.2210e-05 - acc: 1.1282e-04 - val_loss: 1.3647e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.6560e-05 - acc: 1.1282e-04 - val_loss: 1.2819e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.4097e-05 - acc: 1.1282e-04 - val_loss: 1.5016e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 7.1423e-05 - acc: 1.1282e-04 - val_loss: 1.5239e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.1847e-05 - acc: 1.1282e-04 - val_loss: 1.8044e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.4895e-05 - acc: 1.1282e-04 - val_loss: 1.1414e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.9036e-05 - acc: 1.1282e-04 - val_loss: 1.8881e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.6458e-05 - acc: 1.1282e-04 - val_loss: 1.2486e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.3244e-05 - acc: 1.1282e-04 - val_loss: 1.8368e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.5808e-05 - acc: 1.1282e-04 - val_loss: 2.9062e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.4481e-05 - acc: 1.1282e-04 - val_loss: 1.2474e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1287e-05 - acc: 1.1282e-04 - val_loss: 1.2086e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.0338e-05 - acc: 1.1282e-04 - val_loss: 1.3001e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.8857e-05 - acc: 1.1282e-04 - val_loss: 1.1140e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 8.0995e-05 - acc: 1.1282e-04 - val_loss: 1.6246e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.3365e-05 - acc: 1.1282e-04 - val_loss: 1.8426e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.2074e-05 - acc: 1.1282e-04 - val_loss: 1.3071e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.7515e-05 - acc: 1.1282e-04 - val_loss: 1.3643e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.3004e-05 - acc: 1.1282e-04 - val_loss: 1.3121e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.9733e-05 - acc: 1.1282e-04 - val_loss: 1.1427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.1983e-05 - acc: 1.1282e-04 - val_loss: 1.3858e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.1517e-05 - acc: 1.1282e-04 - val_loss: 1.1207e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.8726e-05 - acc: 1.1282e-04 - val_loss: 2.2834e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.8803e-05 - acc: 1.1282e-04 - val_loss: 2.2015e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.2638e-05 - acc: 1.1282e-04 - val_loss: 1.1230e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.0180e-05 - acc: 1.1282e-04 - val_loss: 1.1127e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.7032e-05 - acc: 1.1282e-04 - val_loss: 1.2409e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.0441e-05 - acc: 1.1282e-04 - val_loss: 1.1535e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.6291e-05 - acc: 1.1282e-04 - val_loss: 1.1671e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 7.0286e-05 - acc: 1.1282e-04 - val_loss: 1.0892e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 6.8071e-05 - acc: 1.1282e-04 - val_loss: 3.6071e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.4660e-05 - acc: 1.1282e-04 - val_loss: 1.4885e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.9270e-05 - acc: 1.1282e-04 - val_loss: 1.8112e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.8469e-05 - acc: 1.1282e-04 - val_loss: 1.4337e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.7930e-05 - acc: 1.1282e-04 - val_loss: 1.0819e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.0343e-05 - acc: 1.1282e-04 - val_loss: 1.0437e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.4590e-05 - acc: 1.1282e-04 - val_loss: 2.9046e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.8033e-05 - acc: 1.1282e-04 - val_loss: 1.0934e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.1513e-05 - acc: 1.1282e-04 - val_loss: 1.4244e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.6624e-05 - acc: 1.1282e-04 - val_loss: 2.3111e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.4687e-05 - acc: 1.1282e-04 - val_loss: 2.1656e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.2294e-05 - acc: 1.1282e-04 - val_loss: 1.6334e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.3707e-05 - acc: 1.1282e-04 - val_loss: 2.6879e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.1630e-05 - acc: 1.1282e-04 - val_loss: 1.1659e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 8.2956e-05 - acc: 1.1282e-04 - val_loss: 2.7026e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 7.5663e-05 - acc: 1.1282e-04 - val_loss: 2.3099e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.1765e-05 - acc: 1.1282e-04 - val_loss: 1.2096e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.5905e-05 - acc: 1.1282e-04 - val_loss: 1.1808e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.7350e-05 - acc: 1.1282e-04 - val_loss: 1.2351e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.5515e-05 - acc: 1.1282e-04 - val_loss: 1.6304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.5517e-05 - acc: 1.1282e-04 - val_loss: 1.1674e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.095\n",
            "TEMP MSE: 0.009\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_21 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/300\n",
            "8864/8864 [==============================] - 5s 594us/step - loss: 0.0167 - acc: 1.1282e-04 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
            "Epoch 2/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 0.0021 - acc: 1.1282e-04 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 3/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 4/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.2117e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 5/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.7381e-04 - acc: 1.1282e-04 - val_loss: 7.0961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 6/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.6906e-04 - acc: 1.1282e-04 - val_loss: 5.5599e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 6.6103e-04 - acc: 1.1282e-04 - val_loss: 3.8644e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.2465e-04 - acc: 1.1282e-04 - val_loss: 5.3638e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 6.4952e-04 - acc: 1.1282e-04 - val_loss: 5.0752e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.9992e-04 - acc: 1.1282e-04 - val_loss: 2.9817e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.9127e-04 - acc: 1.1282e-04 - val_loss: 2.8237e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.6045e-04 - acc: 1.1282e-04 - val_loss: 6.7588e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.4057e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 14/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.4812e-04 - acc: 1.1282e-04 - val_loss: 2.6280e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.7731e-04 - acc: 1.1282e-04 - val_loss: 9.6563e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.4275e-04 - acc: 1.1282e-04 - val_loss: 3.5694e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.6022e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 18/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.0156e-04 - acc: 1.1282e-04 - val_loss: 5.3575e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.0102e-04 - acc: 1.1282e-04 - val_loss: 4.9845e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.9745e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 21/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0846e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 22/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9788e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 23/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.7342e-04 - acc: 1.1282e-04 - val_loss: 2.8669e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.1782e-04 - acc: 1.1282e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 25/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8341e-04 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 26/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.8227e-04 - acc: 1.1282e-04 - val_loss: 8.8399e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.6958e-04 - acc: 1.1282e-04 - val_loss: 2.3807e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.9227e-04 - acc: 1.1282e-04 - val_loss: 8.1191e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.5598e-04 - acc: 1.1282e-04 - val_loss: 7.1945e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.8245e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 31/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.3555e-04 - acc: 1.1282e-04 - val_loss: 8.3685e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.2277e-04 - acc: 1.1282e-04 - val_loss: 4.3523e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.0812e-04 - acc: 1.1282e-04 - val_loss: 4.5146e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.9744e-04 - acc: 1.1282e-04 - val_loss: 2.9386e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.2768e-04 - acc: 1.1282e-04 - val_loss: 4.3693e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.0721e-04 - acc: 1.1282e-04 - val_loss: 2.9331e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.0914e-04 - acc: 1.1282e-04 - val_loss: 3.1349e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.9312e-04 - acc: 1.1282e-04 - val_loss: 5.4366e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.9389e-04 - acc: 1.1282e-04 - val_loss: 6.8838e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.2722e-04 - acc: 1.1282e-04 - val_loss: 6.4624e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.1441e-04 - acc: 1.1282e-04 - val_loss: 4.1693e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.6130e-04 - acc: 1.1282e-04 - val_loss: 2.9242e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.6467e-04 - acc: 1.1282e-04 - val_loss: 4.6636e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.8219e-04 - acc: 1.1282e-04 - val_loss: 2.3129e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 3.9394e-04 - acc: 1.1282e-04 - val_loss: 3.0791e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.9217e-04 - acc: 1.1282e-04 - val_loss: 3.1011e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.7321e-04 - acc: 1.1282e-04 - val_loss: 4.1740e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.5204e-04 - acc: 1.1282e-04 - val_loss: 9.1144e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.6134e-04 - acc: 1.1282e-04 - val_loss: 6.2734e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.4953e-04 - acc: 1.1282e-04 - val_loss: 2.0870e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.6959e-04 - acc: 1.1282e-04 - val_loss: 8.8569e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.8190e-04 - acc: 1.1282e-04 - val_loss: 4.3298e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 3.3547e-04 - acc: 1.1282e-04 - val_loss: 1.9674e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.6100e-04 - acc: 1.1282e-04 - val_loss: 2.8152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.1957e-04 - acc: 1.1282e-04 - val_loss: 3.5309e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.4142e-04 - acc: 1.1282e-04 - val_loss: 2.1678e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.0482e-04 - acc: 1.1282e-04 - val_loss: 3.0858e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.3070e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 59/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.0939e-04 - acc: 1.1282e-04 - val_loss: 3.9788e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.9703e-04 - acc: 1.1282e-04 - val_loss: 3.0156e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.8307e-04 - acc: 1.1282e-04 - val_loss: 5.2627e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.9021e-04 - acc: 1.1282e-04 - val_loss: 2.3782e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.8002e-04 - acc: 1.1282e-04 - val_loss: 2.8721e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.9190e-04 - acc: 1.1282e-04 - val_loss: 9.4459e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.7438e-04 - acc: 1.1282e-04 - val_loss: 5.4192e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.6409e-04 - acc: 1.1282e-04 - val_loss: 5.9519e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.6286e-04 - acc: 1.1282e-04 - val_loss: 2.3219e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.8122e-04 - acc: 1.1282e-04 - val_loss: 5.0365e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.4965e-04 - acc: 1.1282e-04 - val_loss: 3.3854e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.6639e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 71/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.5749e-04 - acc: 1.1282e-04 - val_loss: 5.2214e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.4612e-04 - acc: 1.1282e-04 - val_loss: 7.5857e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.3820e-04 - acc: 1.1282e-04 - val_loss: 3.1667e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.2318e-04 - acc: 1.1282e-04 - val_loss: 3.6882e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3537e-04 - acc: 1.1282e-04 - val_loss: 3.5102e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.3187e-04 - acc: 1.1282e-04 - val_loss: 7.9240e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.2843e-04 - acc: 1.1282e-04 - val_loss: 2.2928e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.2575e-04 - acc: 1.1282e-04 - val_loss: 4.3308e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.1420e-04 - acc: 1.1282e-04 - val_loss: 2.9163e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.3693e-04 - acc: 1.1282e-04 - val_loss: 3.9931e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.2010e-04 - acc: 1.1282e-04 - val_loss: 3.9590e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.1486e-04 - acc: 1.1282e-04 - val_loss: 7.0038e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2635e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 84/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.4325e-04 - acc: 1.1282e-04 - val_loss: 3.4430e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9190e-04 - acc: 1.1282e-04 - val_loss: 5.8141e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.0373e-04 - acc: 1.1282e-04 - val_loss: 8.9518e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.0990e-04 - acc: 1.1282e-04 - val_loss: 9.4207e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.3948e-04 - acc: 1.1282e-04 - val_loss: 1.9118e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.0342e-04 - acc: 1.1282e-04 - val_loss: 4.9803e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.2462e-04 - acc: 1.1282e-04 - val_loss: 4.9801e-04 - val_acc: 0.0000e+00\n",
            "Epoch 91/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.0241e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 92/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3715e-04 - acc: 1.1282e-04 - val_loss: 3.7707e-04 - val_acc: 0.0000e+00\n",
            "Epoch 93/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.8902e-04 - acc: 1.1282e-04 - val_loss: 2.1003e-04 - val_acc: 0.0000e+00\n",
            "Epoch 94/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.8082e-04 - acc: 1.1282e-04 - val_loss: 4.6834e-04 - val_acc: 0.0000e+00\n",
            "Epoch 95/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.7721e-04 - acc: 1.1282e-04 - val_loss: 2.9562e-04 - val_acc: 0.0000e+00\n",
            "Epoch 96/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.8562e-04 - acc: 1.1282e-04 - val_loss: 4.5733e-04 - val_acc: 0.0000e+00\n",
            "Epoch 97/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9822e-04 - acc: 1.1282e-04 - val_loss: 3.1541e-04 - val_acc: 0.0000e+00\n",
            "Epoch 98/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.8850e-04 - acc: 1.1282e-04 - val_loss: 4.0782e-04 - val_acc: 0.0000e+00\n",
            "Epoch 99/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6738e-04 - acc: 1.1282e-04 - val_loss: 4.1140e-04 - val_acc: 0.0000e+00\n",
            "Epoch 100/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.7335e-04 - acc: 1.1282e-04 - val_loss: 5.1110e-04 - val_acc: 0.0000e+00\n",
            "Epoch 101/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.0798e-04 - acc: 1.1282e-04 - val_loss: 5.9414e-04 - val_acc: 0.0000e+00\n",
            "Epoch 102/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.7397e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 103/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.8572e-04 - acc: 1.1282e-04 - val_loss: 6.3814e-04 - val_acc: 0.0000e+00\n",
            "Epoch 104/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.6122e-04 - acc: 1.1282e-04 - val_loss: 3.2427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 105/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6832e-04 - acc: 1.1282e-04 - val_loss: 3.7836e-04 - val_acc: 0.0000e+00\n",
            "Epoch 106/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.6103e-04 - acc: 1.1282e-04 - val_loss: 2.3951e-04 - val_acc: 0.0000e+00\n",
            "Epoch 107/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.6009e-04 - acc: 1.1282e-04 - val_loss: 3.1389e-04 - val_acc: 0.0000e+00\n",
            "Epoch 108/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.5541e-04 - acc: 1.1282e-04 - val_loss: 3.2857e-04 - val_acc: 0.0000e+00\n",
            "Epoch 109/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.5146e-04 - acc: 1.1282e-04 - val_loss: 4.8895e-04 - val_acc: 0.0000e+00\n",
            "Epoch 110/300\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 1.6095e-04 - acc: 1.1282e-04 - val_loss: 3.6240e-04 - val_acc: 0.0000e+00\n",
            "Epoch 111/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6405e-04 - acc: 1.1282e-04 - val_loss: 4.3297e-04 - val_acc: 0.0000e+00\n",
            "Epoch 112/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.6193e-04 - acc: 1.1282e-04 - val_loss: 5.2776e-04 - val_acc: 0.0000e+00\n",
            "Epoch 113/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.6442e-04 - acc: 1.1282e-04 - val_loss: 3.8281e-04 - val_acc: 0.0000e+00\n",
            "Epoch 114/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.5650e-04 - acc: 1.1282e-04 - val_loss: 2.8877e-04 - val_acc: 0.0000e+00\n",
            "Epoch 115/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.6415e-04 - acc: 1.1282e-04 - val_loss: 4.1423e-04 - val_acc: 0.0000e+00\n",
            "Epoch 116/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.6765e-04 - acc: 1.1282e-04 - val_loss: 2.5359e-04 - val_acc: 0.0000e+00\n",
            "Epoch 117/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.7933e-04 - acc: 1.1282e-04 - val_loss: 2.1698e-04 - val_acc: 0.0000e+00\n",
            "Epoch 118/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5455e-04 - acc: 1.1282e-04 - val_loss: 3.9195e-04 - val_acc: 0.0000e+00\n",
            "Epoch 119/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4710e-04 - acc: 1.1282e-04 - val_loss: 6.8400e-04 - val_acc: 0.0000e+00\n",
            "Epoch 120/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.6452e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 121/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.6007e-04 - acc: 1.1282e-04 - val_loss: 6.0045e-04 - val_acc: 0.0000e+00\n",
            "Epoch 122/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.4842e-04 - acc: 1.1282e-04 - val_loss: 3.1141e-04 - val_acc: 0.0000e+00\n",
            "Epoch 123/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.4943e-04 - acc: 1.1282e-04 - val_loss: 2.7239e-04 - val_acc: 0.0000e+00\n",
            "Epoch 124/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.5909e-04 - acc: 1.1282e-04 - val_loss: 5.1837e-04 - val_acc: 0.0000e+00\n",
            "Epoch 125/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.6308e-04 - acc: 1.1282e-04 - val_loss: 5.6022e-04 - val_acc: 0.0000e+00\n",
            "Epoch 126/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.6238e-04 - acc: 1.1282e-04 - val_loss: 5.6115e-04 - val_acc: 0.0000e+00\n",
            "Epoch 127/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.4722e-04 - acc: 1.1282e-04 - val_loss: 2.7010e-04 - val_acc: 0.0000e+00\n",
            "Epoch 128/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5275e-04 - acc: 1.1282e-04 - val_loss: 2.6936e-04 - val_acc: 0.0000e+00\n",
            "Epoch 129/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.4332e-04 - acc: 1.1282e-04 - val_loss: 2.6092e-04 - val_acc: 0.0000e+00\n",
            "Epoch 130/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.4403e-04 - acc: 1.1282e-04 - val_loss: 2.9670e-04 - val_acc: 0.0000e+00\n",
            "Epoch 131/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.6811e-04 - acc: 1.1282e-04 - val_loss: 5.4691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 132/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.5032e-04 - acc: 1.1282e-04 - val_loss: 4.3079e-04 - val_acc: 0.0000e+00\n",
            "Epoch 133/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.4003e-04 - acc: 1.1282e-04 - val_loss: 2.4829e-04 - val_acc: 0.0000e+00\n",
            "Epoch 134/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.6545e-04 - acc: 1.1282e-04 - val_loss: 2.3236e-04 - val_acc: 0.0000e+00\n",
            "Epoch 135/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.6306e-04 - acc: 1.1282e-04 - val_loss: 5.0761e-04 - val_acc: 0.0000e+00\n",
            "Epoch 136/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.4205e-04 - acc: 1.1282e-04 - val_loss: 2.3183e-04 - val_acc: 0.0000e+00\n",
            "Epoch 137/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.4026e-04 - acc: 1.1282e-04 - val_loss: 2.3192e-04 - val_acc: 0.0000e+00\n",
            "Epoch 138/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.3865e-04 - acc: 1.1282e-04 - val_loss: 3.7764e-04 - val_acc: 0.0000e+00\n",
            "Epoch 139/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.4104e-04 - acc: 1.1282e-04 - val_loss: 2.5268e-04 - val_acc: 0.0000e+00\n",
            "Epoch 140/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3116e-04 - acc: 1.1282e-04 - val_loss: 2.0385e-04 - val_acc: 0.0000e+00\n",
            "Epoch 141/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2913e-04 - acc: 1.1282e-04 - val_loss: 2.3410e-04 - val_acc: 0.0000e+00\n",
            "Epoch 142/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.3956e-04 - acc: 1.1282e-04 - val_loss: 4.2896e-04 - val_acc: 0.0000e+00\n",
            "Epoch 143/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.3736e-04 - acc: 1.1282e-04 - val_loss: 1.9447e-04 - val_acc: 0.0000e+00\n",
            "Epoch 144/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2751e-04 - acc: 1.1282e-04 - val_loss: 3.3578e-04 - val_acc: 0.0000e+00\n",
            "Epoch 145/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.2871e-04 - acc: 1.1282e-04 - val_loss: 4.4422e-04 - val_acc: 0.0000e+00\n",
            "Epoch 146/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3461e-04 - acc: 1.1282e-04 - val_loss: 1.8588e-04 - val_acc: 0.0000e+00\n",
            "Epoch 147/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.5657e-04 - acc: 1.1282e-04 - val_loss: 2.0471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 148/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.4283e-04 - acc: 1.1282e-04 - val_loss: 2.2626e-04 - val_acc: 0.0000e+00\n",
            "Epoch 149/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2934e-04 - acc: 1.1282e-04 - val_loss: 4.8354e-04 - val_acc: 0.0000e+00\n",
            "Epoch 150/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.3359e-04 - acc: 1.1282e-04 - val_loss: 2.9913e-04 - val_acc: 0.0000e+00\n",
            "Epoch 151/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3629e-04 - acc: 1.1282e-04 - val_loss: 1.9981e-04 - val_acc: 0.0000e+00\n",
            "Epoch 152/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.2564e-04 - acc: 1.1282e-04 - val_loss: 3.0338e-04 - val_acc: 0.0000e+00\n",
            "Epoch 153/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.4147e-04 - acc: 1.1282e-04 - val_loss: 3.8522e-04 - val_acc: 0.0000e+00\n",
            "Epoch 154/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3923e-04 - acc: 1.1282e-04 - val_loss: 1.8229e-04 - val_acc: 0.0000e+00\n",
            "Epoch 155/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.7684e-04 - acc: 1.1282e-04 - val_loss: 2.0520e-04 - val_acc: 0.0000e+00\n",
            "Epoch 156/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.3084e-04 - acc: 1.1282e-04 - val_loss: 5.5016e-04 - val_acc: 0.0000e+00\n",
            "Epoch 157/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.4000e-04 - acc: 1.1282e-04 - val_loss: 1.8100e-04 - val_acc: 0.0000e+00\n",
            "Epoch 158/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3209e-04 - acc: 1.1282e-04 - val_loss: 1.8589e-04 - val_acc: 0.0000e+00\n",
            "Epoch 159/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.2772e-04 - acc: 1.1282e-04 - val_loss: 1.7788e-04 - val_acc: 0.0000e+00\n",
            "Epoch 160/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.3288e-04 - acc: 1.1282e-04 - val_loss: 1.6226e-04 - val_acc: 0.0000e+00\n",
            "Epoch 161/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.3083e-04 - acc: 1.1282e-04 - val_loss: 2.3305e-04 - val_acc: 0.0000e+00\n",
            "Epoch 162/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1791e-04 - acc: 1.1282e-04 - val_loss: 2.0001e-04 - val_acc: 0.0000e+00\n",
            "Epoch 163/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2391e-04 - acc: 1.1282e-04 - val_loss: 2.6217e-04 - val_acc: 0.0000e+00\n",
            "Epoch 164/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2878e-04 - acc: 1.1282e-04 - val_loss: 2.4843e-04 - val_acc: 0.0000e+00\n",
            "Epoch 165/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2825e-04 - acc: 1.1282e-04 - val_loss: 1.8561e-04 - val_acc: 0.0000e+00\n",
            "Epoch 166/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.2386e-04 - acc: 1.1282e-04 - val_loss: 3.4014e-04 - val_acc: 0.0000e+00\n",
            "Epoch 167/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2356e-04 - acc: 1.1282e-04 - val_loss: 4.5685e-04 - val_acc: 0.0000e+00\n",
            "Epoch 168/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.3360e-04 - acc: 1.1282e-04 - val_loss: 3.4963e-04 - val_acc: 0.0000e+00\n",
            "Epoch 169/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.3230e-04 - acc: 1.1282e-04 - val_loss: 2.0293e-04 - val_acc: 0.0000e+00\n",
            "Epoch 170/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.2860e-04 - acc: 1.1282e-04 - val_loss: 2.6993e-04 - val_acc: 0.0000e+00\n",
            "Epoch 171/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1894e-04 - acc: 1.1282e-04 - val_loss: 1.6228e-04 - val_acc: 0.0000e+00\n",
            "Epoch 172/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2972e-04 - acc: 1.1282e-04 - val_loss: 2.0028e-04 - val_acc: 0.0000e+00\n",
            "Epoch 173/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2441e-04 - acc: 1.1282e-04 - val_loss: 3.3084e-04 - val_acc: 0.0000e+00\n",
            "Epoch 174/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2013e-04 - acc: 1.1282e-04 - val_loss: 1.4996e-04 - val_acc: 0.0000e+00\n",
            "Epoch 175/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1714e-04 - acc: 1.1282e-04 - val_loss: 2.9881e-04 - val_acc: 0.0000e+00\n",
            "Epoch 176/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.2210e-04 - acc: 1.1282e-04 - val_loss: 2.0692e-04 - val_acc: 0.0000e+00\n",
            "Epoch 177/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.2630e-04 - acc: 1.1282e-04 - val_loss: 2.1842e-04 - val_acc: 0.0000e+00\n",
            "Epoch 178/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2969e-04 - acc: 1.1282e-04 - val_loss: 2.0389e-04 - val_acc: 0.0000e+00\n",
            "Epoch 179/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2745e-04 - acc: 1.1282e-04 - val_loss: 3.3849e-04 - val_acc: 0.0000e+00\n",
            "Epoch 180/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.3698e-04 - acc: 1.1282e-04 - val_loss: 1.9726e-04 - val_acc: 0.0000e+00\n",
            "Epoch 181/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.2251e-04 - acc: 1.1282e-04 - val_loss: 2.4426e-04 - val_acc: 0.0000e+00\n",
            "Epoch 182/300\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.1447e-04 - acc: 1.1282e-04 - val_loss: 3.1463e-04 - val_acc: 0.0000e+00\n",
            "Epoch 183/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2213e-04 - acc: 1.1282e-04 - val_loss: 1.9215e-04 - val_acc: 0.0000e+00\n",
            "Epoch 184/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.1580e-04 - acc: 1.1282e-04 - val_loss: 1.6725e-04 - val_acc: 0.0000e+00\n",
            "Epoch 185/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2219e-04 - acc: 1.1282e-04 - val_loss: 1.7065e-04 - val_acc: 0.0000e+00\n",
            "Epoch 186/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2359e-04 - acc: 1.1282e-04 - val_loss: 1.9731e-04 - val_acc: 0.0000e+00\n",
            "Epoch 187/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3436e-04 - acc: 1.1282e-04 - val_loss: 2.6635e-04 - val_acc: 0.0000e+00\n",
            "Epoch 188/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.2317e-04 - acc: 1.1282e-04 - val_loss: 2.4145e-04 - val_acc: 0.0000e+00\n",
            "Epoch 189/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.4163e-04 - acc: 1.1282e-04 - val_loss: 1.7351e-04 - val_acc: 0.0000e+00\n",
            "Epoch 190/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2143e-04 - acc: 1.1282e-04 - val_loss: 2.3899e-04 - val_acc: 0.0000e+00\n",
            "Epoch 191/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1449e-04 - acc: 1.1282e-04 - val_loss: 1.9107e-04 - val_acc: 0.0000e+00\n",
            "Epoch 192/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2396e-04 - acc: 1.1282e-04 - val_loss: 1.4179e-04 - val_acc: 0.0000e+00\n",
            "Epoch 193/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.2387e-04 - acc: 1.1282e-04 - val_loss: 2.0695e-04 - val_acc: 0.0000e+00\n",
            "Epoch 194/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.2714e-04 - acc: 1.1282e-04 - val_loss: 3.5425e-04 - val_acc: 0.0000e+00\n",
            "Epoch 195/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.2059e-04 - acc: 1.1282e-04 - val_loss: 2.3904e-04 - val_acc: 0.0000e+00\n",
            "Epoch 196/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.2029e-04 - acc: 1.1282e-04 - val_loss: 1.5105e-04 - val_acc: 0.0000e+00\n",
            "Epoch 197/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1671e-04 - acc: 1.1282e-04 - val_loss: 1.7892e-04 - val_acc: 0.0000e+00\n",
            "Epoch 198/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1282e-04 - acc: 1.1282e-04 - val_loss: 2.8341e-04 - val_acc: 0.0000e+00\n",
            "Epoch 199/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1531e-04 - acc: 1.1282e-04 - val_loss: 1.8640e-04 - val_acc: 0.0000e+00\n",
            "Epoch 200/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1160e-04 - acc: 1.1282e-04 - val_loss: 1.5721e-04 - val_acc: 0.0000e+00\n",
            "Epoch 201/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1750e-04 - acc: 1.1282e-04 - val_loss: 1.7655e-04 - val_acc: 0.0000e+00\n",
            "Epoch 202/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1052e-04 - acc: 1.1282e-04 - val_loss: 1.6712e-04 - val_acc: 0.0000e+00\n",
            "Epoch 203/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0794e-04 - acc: 1.1282e-04 - val_loss: 2.2293e-04 - val_acc: 0.0000e+00\n",
            "Epoch 204/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1854e-04 - acc: 1.1282e-04 - val_loss: 2.6527e-04 - val_acc: 0.0000e+00\n",
            "Epoch 205/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.1973e-04 - acc: 1.1282e-04 - val_loss: 3.3307e-04 - val_acc: 0.0000e+00\n",
            "Epoch 206/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1880e-04 - acc: 1.1282e-04 - val_loss: 1.7571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 207/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.1154e-04 - acc: 1.1282e-04 - val_loss: 3.9229e-04 - val_acc: 0.0000e+00\n",
            "Epoch 208/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1649e-04 - acc: 1.1282e-04 - val_loss: 1.5521e-04 - val_acc: 0.0000e+00\n",
            "Epoch 209/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1200e-04 - acc: 1.1282e-04 - val_loss: 1.5076e-04 - val_acc: 0.0000e+00\n",
            "Epoch 210/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1851e-04 - acc: 1.1282e-04 - val_loss: 4.3043e-04 - val_acc: 0.0000e+00\n",
            "Epoch 211/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.3041e-04 - acc: 1.1282e-04 - val_loss: 1.9190e-04 - val_acc: 0.0000e+00\n",
            "Epoch 212/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.2390e-04 - acc: 1.1282e-04 - val_loss: 1.8259e-04 - val_acc: 0.0000e+00\n",
            "Epoch 213/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1469e-04 - acc: 1.1282e-04 - val_loss: 2.5009e-04 - val_acc: 0.0000e+00\n",
            "Epoch 214/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0503e-04 - acc: 1.1282e-04 - val_loss: 2.2797e-04 - val_acc: 0.0000e+00\n",
            "Epoch 215/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1045e-04 - acc: 1.1282e-04 - val_loss: 1.6893e-04 - val_acc: 0.0000e+00\n",
            "Epoch 216/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0632e-04 - acc: 1.1282e-04 - val_loss: 2.1522e-04 - val_acc: 0.0000e+00\n",
            "Epoch 217/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0909e-04 - acc: 1.1282e-04 - val_loss: 1.9981e-04 - val_acc: 0.0000e+00\n",
            "Epoch 218/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0502e-04 - acc: 1.1282e-04 - val_loss: 3.1354e-04 - val_acc: 0.0000e+00\n",
            "Epoch 219/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1981e-04 - acc: 1.1282e-04 - val_loss: 1.5689e-04 - val_acc: 0.0000e+00\n",
            "Epoch 220/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1550e-04 - acc: 1.1282e-04 - val_loss: 1.7353e-04 - val_acc: 0.0000e+00\n",
            "Epoch 221/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1134e-04 - acc: 1.1282e-04 - val_loss: 1.9405e-04 - val_acc: 0.0000e+00\n",
            "Epoch 222/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.2154e-04 - acc: 1.1282e-04 - val_loss: 3.1085e-04 - val_acc: 0.0000e+00\n",
            "Epoch 223/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0762e-04 - acc: 1.1282e-04 - val_loss: 1.4929e-04 - val_acc: 0.0000e+00\n",
            "Epoch 224/300\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 1.1145e-04 - acc: 1.1282e-04 - val_loss: 3.0701e-04 - val_acc: 0.0000e+00\n",
            "Epoch 225/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0949e-04 - acc: 1.1282e-04 - val_loss: 1.8041e-04 - val_acc: 0.0000e+00\n",
            "Epoch 226/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0541e-04 - acc: 1.1282e-04 - val_loss: 2.1291e-04 - val_acc: 0.0000e+00\n",
            "Epoch 227/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0395e-04 - acc: 1.1282e-04 - val_loss: 2.7782e-04 - val_acc: 0.0000e+00\n",
            "Epoch 228/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0627e-04 - acc: 1.1282e-04 - val_loss: 2.0152e-04 - val_acc: 0.0000e+00\n",
            "Epoch 229/300\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.0411e-04 - acc: 1.1282e-04 - val_loss: 2.3971e-04 - val_acc: 0.0000e+00\n",
            "Epoch 230/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0289e-04 - acc: 1.1282e-04 - val_loss: 2.6714e-04 - val_acc: 0.0000e+00\n",
            "Epoch 231/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0354e-04 - acc: 1.1282e-04 - val_loss: 2.3961e-04 - val_acc: 0.0000e+00\n",
            "Epoch 232/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1593e-04 - acc: 1.1282e-04 - val_loss: 3.1008e-04 - val_acc: 0.0000e+00\n",
            "Epoch 233/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0877e-04 - acc: 1.1282e-04 - val_loss: 2.3774e-04 - val_acc: 0.0000e+00\n",
            "Epoch 234/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2402e-04 - acc: 1.1282e-04 - val_loss: 4.1844e-04 - val_acc: 0.0000e+00\n",
            "Epoch 235/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.2307e-04 - acc: 1.1282e-04 - val_loss: 4.6587e-04 - val_acc: 0.0000e+00\n",
            "Epoch 236/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1493e-04 - acc: 1.1282e-04 - val_loss: 3.2860e-04 - val_acc: 0.0000e+00\n",
            "Epoch 237/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0471e-04 - acc: 1.1282e-04 - val_loss: 2.0582e-04 - val_acc: 0.0000e+00\n",
            "Epoch 238/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0953e-04 - acc: 1.1282e-04 - val_loss: 1.8084e-04 - val_acc: 0.0000e+00\n",
            "Epoch 239/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1909e-04 - acc: 1.1282e-04 - val_loss: 4.0461e-04 - val_acc: 0.0000e+00\n",
            "Epoch 240/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1132e-04 - acc: 1.1282e-04 - val_loss: 1.9545e-04 - val_acc: 0.0000e+00\n",
            "Epoch 241/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.1249e-04 - acc: 1.1282e-04 - val_loss: 2.1564e-04 - val_acc: 0.0000e+00\n",
            "Epoch 242/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.0723e-04 - acc: 1.1282e-04 - val_loss: 2.9518e-04 - val_acc: 0.0000e+00\n",
            "Epoch 243/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0820e-04 - acc: 1.1282e-04 - val_loss: 1.9816e-04 - val_acc: 0.0000e+00\n",
            "Epoch 244/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.2028e-04 - acc: 1.1282e-04 - val_loss: 2.9512e-04 - val_acc: 0.0000e+00\n",
            "Epoch 245/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1715e-04 - acc: 1.1282e-04 - val_loss: 2.2460e-04 - val_acc: 0.0000e+00\n",
            "Epoch 246/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.1165e-04 - acc: 1.1282e-04 - val_loss: 2.0034e-04 - val_acc: 0.0000e+00\n",
            "Epoch 247/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.1291e-04 - acc: 1.1282e-04 - val_loss: 1.8053e-04 - val_acc: 0.0000e+00\n",
            "Epoch 248/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.0378e-04 - acc: 1.1282e-04 - val_loss: 2.0062e-04 - val_acc: 0.0000e+00\n",
            "Epoch 249/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.1735e-04 - acc: 1.1282e-04 - val_loss: 2.4544e-04 - val_acc: 0.0000e+00\n",
            "Epoch 250/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.2454e-04 - acc: 1.1282e-04 - val_loss: 1.6068e-04 - val_acc: 0.0000e+00\n",
            "Epoch 251/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0451e-04 - acc: 1.1282e-04 - val_loss: 2.5600e-04 - val_acc: 0.0000e+00\n",
            "Epoch 252/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0009e-04 - acc: 1.1282e-04 - val_loss: 2.0976e-04 - val_acc: 0.0000e+00\n",
            "Epoch 253/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.0421e-04 - acc: 1.1282e-04 - val_loss: 1.6153e-04 - val_acc: 0.0000e+00\n",
            "Epoch 254/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.8277e-05 - acc: 1.1282e-04 - val_loss: 1.8665e-04 - val_acc: 0.0000e+00\n",
            "Epoch 255/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1175e-04 - acc: 1.1282e-04 - val_loss: 2.9926e-04 - val_acc: 0.0000e+00\n",
            "Epoch 256/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1586e-04 - acc: 1.1282e-04 - val_loss: 2.4333e-04 - val_acc: 0.0000e+00\n",
            "Epoch 257/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1232e-04 - acc: 1.1282e-04 - val_loss: 2.4970e-04 - val_acc: 0.0000e+00\n",
            "Epoch 258/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0127e-04 - acc: 1.1282e-04 - val_loss: 1.6019e-04 - val_acc: 0.0000e+00\n",
            "Epoch 259/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.8284e-05 - acc: 1.1282e-04 - val_loss: 1.9351e-04 - val_acc: 0.0000e+00\n",
            "Epoch 260/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.5048e-05 - acc: 1.1282e-04 - val_loss: 2.3981e-04 - val_acc: 0.0000e+00\n",
            "Epoch 261/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.1197e-04 - acc: 1.1282e-04 - val_loss: 2.1396e-04 - val_acc: 0.0000e+00\n",
            "Epoch 262/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.0627e-04 - acc: 1.1282e-04 - val_loss: 4.0510e-04 - val_acc: 0.0000e+00\n",
            "Epoch 263/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.3565e-04 - acc: 1.1282e-04 - val_loss: 1.8632e-04 - val_acc: 0.0000e+00\n",
            "Epoch 264/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 1.0638e-04 - acc: 1.1282e-04 - val_loss: 4.2618e-04 - val_acc: 0.0000e+00\n",
            "Epoch 265/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.2016e-04 - acc: 1.1282e-04 - val_loss: 2.0743e-04 - val_acc: 0.0000e+00\n",
            "Epoch 266/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0688e-04 - acc: 1.1282e-04 - val_loss: 1.6878e-04 - val_acc: 0.0000e+00\n",
            "Epoch 267/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 9.6210e-05 - acc: 1.1282e-04 - val_loss: 2.3301e-04 - val_acc: 0.0000e+00\n",
            "Epoch 268/300\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 9.5116e-05 - acc: 1.1282e-04 - val_loss: 2.0050e-04 - val_acc: 0.0000e+00\n",
            "Epoch 269/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.5672e-05 - acc: 1.1282e-04 - val_loss: 2.1344e-04 - val_acc: 0.0000e+00\n",
            "Epoch 270/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.8433e-05 - acc: 1.1282e-04 - val_loss: 1.6677e-04 - val_acc: 0.0000e+00\n",
            "Epoch 271/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.9894e-05 - acc: 1.1282e-04 - val_loss: 2.0481e-04 - val_acc: 0.0000e+00\n",
            "Epoch 272/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.7790e-05 - acc: 1.1282e-04 - val_loss: 1.9204e-04 - val_acc: 0.0000e+00\n",
            "Epoch 273/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 9.6620e-05 - acc: 1.1282e-04 - val_loss: 1.7423e-04 - val_acc: 0.0000e+00\n",
            "Epoch 274/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0608e-04 - acc: 1.1282e-04 - val_loss: 2.7839e-04 - val_acc: 0.0000e+00\n",
            "Epoch 275/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 1.0025e-04 - acc: 1.1282e-04 - val_loss: 1.8044e-04 - val_acc: 0.0000e+00\n",
            "Epoch 276/300\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.0200e-04 - acc: 1.1282e-04 - val_loss: 1.7856e-04 - val_acc: 0.0000e+00\n",
            "Epoch 277/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.0786e-05 - acc: 1.1282e-04 - val_loss: 1.7214e-04 - val_acc: 0.0000e+00\n",
            "Epoch 278/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.7058e-05 - acc: 1.1282e-04 - val_loss: 1.6238e-04 - val_acc: 0.0000e+00\n",
            "Epoch 279/300\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.6640e-05 - acc: 1.1282e-04 - val_loss: 1.8925e-04 - val_acc: 0.0000e+00\n",
            "Epoch 280/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.7190e-05 - acc: 1.1282e-04 - val_loss: 2.3099e-04 - val_acc: 0.0000e+00\n",
            "Epoch 281/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0362e-04 - acc: 1.1282e-04 - val_loss: 1.8837e-04 - val_acc: 0.0000e+00\n",
            "Epoch 282/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1911e-04 - acc: 1.1282e-04 - val_loss: 1.7953e-04 - val_acc: 0.0000e+00\n",
            "Epoch 283/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0100e-04 - acc: 1.1282e-04 - val_loss: 2.4393e-04 - val_acc: 0.0000e+00\n",
            "Epoch 284/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.0410e-04 - acc: 1.1282e-04 - val_loss: 1.9288e-04 - val_acc: 0.0000e+00\n",
            "Epoch 285/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.6395e-05 - acc: 1.1282e-04 - val_loss: 1.7908e-04 - val_acc: 0.0000e+00\n",
            "Epoch 286/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.9134e-05 - acc: 1.1282e-04 - val_loss: 1.8645e-04 - val_acc: 0.0000e+00\n",
            "Epoch 287/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0118e-04 - acc: 1.1282e-04 - val_loss: 1.7878e-04 - val_acc: 0.0000e+00\n",
            "Epoch 288/300\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.1015e-04 - acc: 1.1282e-04 - val_loss: 2.1964e-04 - val_acc: 0.0000e+00\n",
            "Epoch 289/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.1493e-04 - acc: 1.1282e-04 - val_loss: 3.0923e-04 - val_acc: 0.0000e+00\n",
            "Epoch 290/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.0196e-04 - acc: 1.1282e-04 - val_loss: 2.0604e-04 - val_acc: 0.0000e+00\n",
            "Epoch 291/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.4526e-05 - acc: 1.1282e-04 - val_loss: 1.8120e-04 - val_acc: 0.0000e+00\n",
            "Epoch 292/300\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.9584e-05 - acc: 1.1282e-04 - val_loss: 1.8319e-04 - val_acc: 0.0000e+00\n",
            "Epoch 293/300\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.6893e-05 - acc: 1.1282e-04 - val_loss: 1.9129e-04 - val_acc: 0.0000e+00\n",
            "Epoch 294/300\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.7027e-05 - acc: 1.1282e-04 - val_loss: 2.4852e-04 - val_acc: 0.0000e+00\n",
            "Epoch 295/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.1447e-04 - acc: 1.1282e-04 - val_loss: 2.1958e-04 - val_acc: 0.0000e+00\n",
            "Epoch 296/300\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.9716e-05 - acc: 1.1282e-04 - val_loss: 2.1799e-04 - val_acc: 0.0000e+00\n",
            "Epoch 297/300\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 9.5342e-05 - acc: 1.1282e-04 - val_loss: 1.9147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 298/300\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 9.7533e-05 - acc: 1.1282e-04 - val_loss: 3.1036e-04 - val_acc: 0.0000e+00\n",
            "Epoch 299/300\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.0211e-04 - acc: 1.1282e-04 - val_loss: 1.6501e-04 - val_acc: 0.0000e+00\n",
            "Epoch 300/300\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 9.9432e-05 - acc: 1.1282e-04 - val_loss: 1.9484e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.160\n",
            "TEMP MSE: 0.026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kl1i1XCDgP1",
        "colab_type": "code",
        "outputId": "4a464b65-c073-4f41-e3c9-e69e2db669f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print (dropout_result)\n",
        "print (min_val_key)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0.2: 0.001286035325368157, 0.3: 0.002027867798531647, 0.4: 0.0006707537255025533, 0.5: 0.00245526851124072, 0.6: 0.0031540509690867937, 0.7: 0.009109958880244176, 0.8: 0.02553420945291733}\n",
            "[0.4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvMf0bDdEYAo",
        "colab_type": "code",
        "outputId": "ae898d55-43a0-406b-c1ca-d385d161ddfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "lists = sorted(dropout_result.items())\n",
        "x,y = zip(*lists)\n",
        "plt.plot(x,y)\n",
        "plt.title('Finding the best hyperparameter')\n",
        "plt.xlabel('Dropout')\n",
        "plt.ylabel('Mean Square Error')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtMk1YFhEauL",
        "colab_type": "code",
        "outputId": "dec0e097-87f3-4684-e96e-92a4f9a0fe66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stock_name = '^GSPC'\n",
        "seq_len = 22\n",
        "shape = [4, seq_len, 1] # feature, window, output\n",
        "epochs = 90\n",
        "dropout = 0.2\n",
        "neuronlist1 = [32, 64, 128, 256, 512]\n",
        "neuronlist2 = [16, 32, 64]\n",
        "neurons_result = {}\n",
        " \n",
        "for neuron_lstm in neuronlist1:\n",
        "    neurons = [neuron_lstm, neuron_lstm]\n",
        "    for activation in neuronlist2:\n",
        "        neurons.append(activation)\n",
        "        neurons.append(1)\n",
        "        trainScore, testScore = quick_measure(stock_name, seq_len, d, shape, neurons, epochs, decay)\n",
        "        neurons_result[str(neurons)] = testScore\n",
        "        neurons = neurons[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_23 (LSTM)               (None, 22, 32)            4736      \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 22, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 13,601\n",
            "Trainable params: 13,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 6s 644us/step - loss: 0.0302 - acc: 1.1282e-04 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0110 - acc: 1.1282e-04 - val_loss: 0.0097 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0047 - acc: 1.1282e-04 - val_loss: 6.1530e-04 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0039 - acc: 1.1282e-04 - val_loss: 9.9427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0035 - acc: 1.1282e-04 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0033 - acc: 1.1282e-04 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0032 - acc: 1.1282e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 0.0030 - acc: 1.1282e-04 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 0.0029 - acc: 1.1282e-04 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 0.0027 - acc: 1.1282e-04 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0025 - acc: 1.1282e-04 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0023 - acc: 1.1282e-04 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0021 - acc: 1.1282e-04 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0020 - acc: 1.1282e-04 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 0.0099 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0094 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0116 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0136 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0127 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0154 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0148 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0146 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0155 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0159 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0166 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 9.5614e-04 - acc: 1.1282e-04 - val_loss: 0.0170 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 9.1766e-04 - acc: 1.1282e-04 - val_loss: 0.0195 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 8.7378e-04 - acc: 1.1282e-04 - val_loss: 0.0207 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 8.8333e-04 - acc: 1.1282e-04 - val_loss: 0.0204 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 8.7140e-04 - acc: 1.1282e-04 - val_loss: 0.0222 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.2476e-04 - acc: 1.1282e-04 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 8.0383e-04 - acc: 1.1282e-04 - val_loss: 0.0254 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.8171e-04 - acc: 1.1282e-04 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 7.1525e-04 - acc: 1.1282e-04 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.9209e-04 - acc: 1.1282e-04 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.7380e-04 - acc: 1.1282e-04 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.3569e-04 - acc: 1.1282e-04 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.2378e-04 - acc: 1.1282e-04 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.0599e-04 - acc: 1.1282e-04 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.3967e-04 - acc: 1.1282e-04 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.9973e-04 - acc: 1.1282e-04 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.0455e-04 - acc: 1.1282e-04 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.6718e-04 - acc: 1.1282e-04 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.4350e-04 - acc: 1.1282e-04 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 5.6227e-04 - acc: 1.1282e-04 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 5.0512e-04 - acc: 1.1282e-04 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 5.0663e-04 - acc: 1.1282e-04 - val_loss: 0.0423 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9682e-04 - acc: 1.1282e-04 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.3835e-04 - acc: 1.1282e-04 - val_loss: 0.0416 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 5.1414e-04 - acc: 1.1282e-04 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.1920e-04 - acc: 1.1282e-04 - val_loss: 0.0441 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.2390e-04 - acc: 1.1282e-04 - val_loss: 0.0433 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.9970e-04 - acc: 1.1282e-04 - val_loss: 0.0410 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.8501e-04 - acc: 1.1282e-04 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.3218e-04 - acc: 1.1282e-04 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.9500e-04 - acc: 1.1282e-04 - val_loss: 0.0453 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 4.7136e-04 - acc: 1.1282e-04 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 4.5773e-04 - acc: 1.1282e-04 - val_loss: 0.0420 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.3566e-04 - acc: 1.1282e-04 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.7211e-04 - acc: 1.1282e-04 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.7134e-04 - acc: 1.1282e-04 - val_loss: 0.0458 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.2375e-04 - acc: 1.1282e-04 - val_loss: 0.0434 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 4.6842e-04 - acc: 1.1282e-04 - val_loss: 0.0468 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.8233e-04 - acc: 1.1282e-04 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.4646e-04 - acc: 1.1282e-04 - val_loss: 0.0453 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.4243e-04 - acc: 1.1282e-04 - val_loss: 0.0444 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 4.4778e-04 - acc: 1.1282e-04 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.5537e-04 - acc: 1.1282e-04 - val_loss: 0.0463 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.1607e-04 - acc: 1.1282e-04 - val_loss: 0.0447 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 4.4207e-04 - acc: 1.1282e-04 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.0628e-04 - acc: 1.1282e-04 - val_loss: 0.0433 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.4996e-04 - acc: 1.1282e-04 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.5754e-04 - acc: 1.1282e-04 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.0732e-04 - acc: 1.1282e-04 - val_loss: 0.0455 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.1484e-04 - acc: 1.1282e-04 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.3566e-04 - acc: 1.1282e-04 - val_loss: 0.0483 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.5013e-04 - acc: 1.1282e-04 - val_loss: 0.0450 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.1640e-04 - acc: 1.1282e-04 - val_loss: 0.0431 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.0199e-04 - acc: 1.1282e-04 - val_loss: 0.0446 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.4626e-04 - acc: 1.1282e-04 - val_loss: 0.0442 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.6721e-04 - acc: 1.1282e-04 - val_loss: 0.0479 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.9812e-04 - acc: 1.1282e-04 - val_loss: 0.0458 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.0765e-04 - acc: 1.1282e-04 - val_loss: 0.0460 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.4610e-04 - acc: 1.1282e-04 - val_loss: 0.0457 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.9753e-04 - acc: 1.1282e-04 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.0001e-04 - acc: 1.1282e-04 - val_loss: 0.0469 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.478\n",
            "TEMP MSE: 0.228\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_25 (LSTM)               (None, 22, 32)            4736      \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 22, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_26 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 14,145\n",
            "Trainable params: 14,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 6s 686us/step - loss: 0.0302 - acc: 1.1282e-04 - val_loss: 0.0601 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0109 - acc: 1.1282e-04 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0042 - acc: 1.1282e-04 - val_loss: 0.0062 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0035 - acc: 1.1282e-04 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0034 - acc: 1.1282e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0031 - acc: 1.1282e-04 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0028 - acc: 1.1282e-04 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0024 - acc: 1.1282e-04 - val_loss: 0.0071 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0022 - acc: 1.1282e-04 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0020 - acc: 1.1282e-04 - val_loss: 0.0143 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0225 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0262 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0424 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0465 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.3736e-04 - acc: 1.1282e-04 - val_loss: 0.0486 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.4788e-04 - acc: 1.1282e-04 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 8.1692e-04 - acc: 1.1282e-04 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 8.0326e-04 - acc: 1.1282e-04 - val_loss: 0.0496 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.6305e-04 - acc: 1.1282e-04 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 7.1746e-04 - acc: 1.1282e-04 - val_loss: 0.0545 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.0141e-04 - acc: 1.1282e-04 - val_loss: 0.0539 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.4175e-04 - acc: 1.1282e-04 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.8215e-04 - acc: 1.1282e-04 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.8418e-04 - acc: 1.1282e-04 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 5.7356e-04 - acc: 1.1282e-04 - val_loss: 0.0556 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.5548e-04 - acc: 1.1282e-04 - val_loss: 0.0563 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 5.4432e-04 - acc: 1.1282e-04 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.5200e-04 - acc: 1.1282e-04 - val_loss: 0.0573 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.8265e-04 - acc: 1.1282e-04 - val_loss: 0.0588 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.9191e-04 - acc: 1.1282e-04 - val_loss: 0.0594 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.7559e-04 - acc: 1.1282e-04 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.8484e-04 - acc: 1.1282e-04 - val_loss: 0.0603 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.0939e-04 - acc: 1.1282e-04 - val_loss: 0.0621 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.9090e-04 - acc: 1.1282e-04 - val_loss: 0.0623 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.7422e-04 - acc: 1.1282e-04 - val_loss: 0.0608 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.1219e-04 - acc: 1.1282e-04 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.3282e-04 - acc: 1.1282e-04 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.5177e-04 - acc: 1.1282e-04 - val_loss: 0.0637 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.0527e-04 - acc: 1.1282e-04 - val_loss: 0.0636 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.1161e-04 - acc: 1.1282e-04 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.4127e-04 - acc: 1.1282e-04 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.2352e-04 - acc: 1.1282e-04 - val_loss: 0.0647 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.8445e-04 - acc: 1.1282e-04 - val_loss: 0.0616 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.0797e-04 - acc: 1.1282e-04 - val_loss: 0.0618 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.1688e-04 - acc: 1.1282e-04 - val_loss: 0.0613 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.0184e-04 - acc: 1.1282e-04 - val_loss: 0.0619 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.0707e-04 - acc: 1.1282e-04 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.4571e-04 - acc: 1.1282e-04 - val_loss: 0.0611 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.8941e-04 - acc: 1.1282e-04 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.6012e-04 - acc: 1.1282e-04 - val_loss: 0.0625 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.3600e-04 - acc: 1.1282e-04 - val_loss: 0.0624 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 3.4858e-04 - acc: 1.1282e-04 - val_loss: 0.0614 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.7345e-04 - acc: 1.1282e-04 - val_loss: 0.0638 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.8220e-04 - acc: 1.1282e-04 - val_loss: 0.0615 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.5426e-04 - acc: 1.1282e-04 - val_loss: 0.0640 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.4694e-04 - acc: 1.1282e-04 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.6600e-04 - acc: 1.1282e-04 - val_loss: 0.0593 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.4005e-04 - acc: 1.1282e-04 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.1793e-04 - acc: 1.1282e-04 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.3502e-04 - acc: 1.1282e-04 - val_loss: 0.0577 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.1866e-04 - acc: 1.1282e-04 - val_loss: 0.0559 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.2852e-04 - acc: 1.1282e-04 - val_loss: 0.0589 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.2650e-04 - acc: 1.1282e-04 - val_loss: 0.0575 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.1617e-04 - acc: 1.1282e-04 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.5756e-04 - acc: 1.1282e-04 - val_loss: 0.0553 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.1769e-04 - acc: 1.1282e-04 - val_loss: 0.0576 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.3461e-04 - acc: 1.1282e-04 - val_loss: 0.0564 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.1660e-04 - acc: 1.1282e-04 - val_loss: 0.0586 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.1257e-04 - acc: 1.1282e-04 - val_loss: 0.0584 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.1693e-04 - acc: 1.1282e-04 - val_loss: 0.0599 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.9768e-04 - acc: 1.1282e-04 - val_loss: 0.0582 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.3720e-04 - acc: 1.1282e-04 - val_loss: 0.0567 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.8673e-04 - acc: 1.1282e-04 - val_loss: 0.0565 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.1197e-04 - acc: 1.1282e-04 - val_loss: 0.0569 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.9209e-04 - acc: 1.1282e-04 - val_loss: 0.0575 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.0413e-04 - acc: 1.1282e-04 - val_loss: 0.0580 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.7783e-04 - acc: 1.1282e-04 - val_loss: 0.0565 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.9550e-04 - acc: 1.1282e-04 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.9930e-04 - acc: 1.1282e-04 - val_loss: 0.0593 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.3634e-04 - acc: 1.1282e-04 - val_loss: 0.0595 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.1883e-04 - acc: 1.1282e-04 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.0002e-04 - acc: 1.1282e-04 - val_loss: 0.0594 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.8362e-04 - acc: 1.1282e-04 - val_loss: 0.0589 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.0885e-04 - acc: 1.1282e-04 - val_loss: 0.0604 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.1173e-04 - acc: 1.1282e-04 - val_loss: 0.0579 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.0413e-04 - acc: 1.1282e-04 - val_loss: 0.0592 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.506\n",
            "TEMP MSE: 0.256\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_27 (LSTM)               (None, 22, 32)            4736      \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 22, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_28 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 15,233\n",
            "Trainable params: 15,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 7s 737us/step - loss: 0.0297 - acc: 1.1282e-04 - val_loss: 0.0471 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0093 - acc: 1.1282e-04 - val_loss: 0.0120 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0041 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 0.0034 - acc: 1.1282e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0031 - acc: 1.1282e-04 - val_loss: 0.0068 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0028 - acc: 1.1282e-04 - val_loss: 0.0107 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0024 - acc: 1.1282e-04 - val_loss: 0.0133 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0020 - acc: 1.1282e-04 - val_loss: 0.0202 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0476 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.5405e-04 - acc: 1.1282e-04 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.3847e-04 - acc: 1.1282e-04 - val_loss: 0.0598 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.2595e-04 - acc: 1.1282e-04 - val_loss: 0.0635 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.8898e-04 - acc: 1.1282e-04 - val_loss: 0.0685 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.6473e-04 - acc: 1.1282e-04 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.4600e-04 - acc: 1.1282e-04 - val_loss: 0.0729 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 6.0839e-04 - acc: 1.1282e-04 - val_loss: 0.0744 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.3164e-04 - acc: 1.1282e-04 - val_loss: 0.0758 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.6663e-04 - acc: 1.1282e-04 - val_loss: 0.0773 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 5.2479e-04 - acc: 1.1282e-04 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.2610e-04 - acc: 1.1282e-04 - val_loss: 0.0824 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.5132e-04 - acc: 1.1282e-04 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.5411e-04 - acc: 1.1282e-04 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.1969e-04 - acc: 1.1282e-04 - val_loss: 0.0800 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.2746e-04 - acc: 1.1282e-04 - val_loss: 0.0803 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.0245e-04 - acc: 1.1282e-04 - val_loss: 0.0807 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.4433e-04 - acc: 1.1282e-04 - val_loss: 0.0796 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.3443e-04 - acc: 1.1282e-04 - val_loss: 0.0796 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.4125e-04 - acc: 1.1282e-04 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 4.0603e-04 - acc: 1.1282e-04 - val_loss: 0.0783 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.3443e-04 - acc: 1.1282e-04 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.8773e-04 - acc: 1.1282e-04 - val_loss: 0.0790 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.6920e-04 - acc: 1.1282e-04 - val_loss: 0.0786 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.9625e-04 - acc: 1.1282e-04 - val_loss: 0.0766 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.5635e-04 - acc: 1.1282e-04 - val_loss: 0.0764 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.8557e-04 - acc: 1.1282e-04 - val_loss: 0.0800 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.7079e-04 - acc: 1.1282e-04 - val_loss: 0.0759 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.6961e-04 - acc: 1.1282e-04 - val_loss: 0.0761 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.3721e-04 - acc: 1.1282e-04 - val_loss: 0.0771 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.4261e-04 - acc: 1.1282e-04 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.1320e-04 - acc: 1.1282e-04 - val_loss: 0.0753 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.4117e-04 - acc: 1.1282e-04 - val_loss: 0.0777 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 3.5141e-04 - acc: 1.1282e-04 - val_loss: 0.0763 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.4098e-04 - acc: 1.1282e-04 - val_loss: 0.0750 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.2684e-04 - acc: 1.1282e-04 - val_loss: 0.0746 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.2449e-04 - acc: 1.1282e-04 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.1460e-04 - acc: 1.1282e-04 - val_loss: 0.0740 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.1879e-04 - acc: 1.1282e-04 - val_loss: 0.0740 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.1031e-04 - acc: 1.1282e-04 - val_loss: 0.0773 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.0997e-04 - acc: 1.1282e-04 - val_loss: 0.0755 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.1385e-04 - acc: 1.1282e-04 - val_loss: 0.0765 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.4893e-04 - acc: 1.1282e-04 - val_loss: 0.0754 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.3092e-04 - acc: 1.1282e-04 - val_loss: 0.0760 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.2189e-04 - acc: 1.1282e-04 - val_loss: 0.0770 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.9226e-04 - acc: 1.1282e-04 - val_loss: 0.0753 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.9564e-04 - acc: 1.1282e-04 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.7444e-04 - acc: 1.1282e-04 - val_loss: 0.0735 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.7841e-04 - acc: 1.1282e-04 - val_loss: 0.0746 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.7660e-04 - acc: 1.1282e-04 - val_loss: 0.0722 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.6997e-04 - acc: 1.1282e-04 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.9762e-04 - acc: 1.1282e-04 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.8595e-04 - acc: 1.1282e-04 - val_loss: 0.0719 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.9645e-04 - acc: 1.1282e-04 - val_loss: 0.0718 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.6755e-04 - acc: 1.1282e-04 - val_loss: 0.0735 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.6518e-04 - acc: 1.1282e-04 - val_loss: 0.0736 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.0638e-04 - acc: 1.1282e-04 - val_loss: 0.0720 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.8601e-04 - acc: 1.1282e-04 - val_loss: 0.0763 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.8996e-04 - acc: 1.1282e-04 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.8133e-04 - acc: 1.1282e-04 - val_loss: 0.0741 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.6376e-04 - acc: 1.1282e-04 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.7511e-04 - acc: 1.1282e-04 - val_loss: 0.0719 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.7595e-04 - acc: 1.1282e-04 - val_loss: 0.0732 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.0422e-04 - acc: 1.1282e-04 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.7880e-04 - acc: 1.1282e-04 - val_loss: 0.0719 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.6418e-04 - acc: 1.1282e-04 - val_loss: 0.0695 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.9688e-04 - acc: 1.1282e-04 - val_loss: 0.0706 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.8178e-04 - acc: 1.1282e-04 - val_loss: 0.0686 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.5561e-04 - acc: 1.1282e-04 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.8639e-04 - acc: 1.1282e-04 - val_loss: 0.0693 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.6724e-04 - acc: 1.1282e-04 - val_loss: 0.0689 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.5487e-04 - acc: 1.1282e-04 - val_loss: 0.0694 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.4385e-04 - acc: 1.1282e-04 - val_loss: 0.0699 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.9430e-04 - acc: 1.1282e-04 - val_loss: 0.0688 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.4521e-04 - acc: 1.1282e-04 - val_loss: 0.0705 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.6085e-04 - acc: 1.1282e-04 - val_loss: 0.0699 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.7884e-04 - acc: 1.1282e-04 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.9463e-04 - acc: 1.1282e-04 - val_loss: 0.0703 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.5574e-04 - acc: 1.1282e-04 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.518\n",
            "TEMP MSE: 0.268\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_29 (LSTM)               (None, 22, 64)            17664     \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 22, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 51,745\n",
            "Trainable params: 51,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 7s 782us/step - loss: 0.0272 - acc: 1.1282e-04 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0066 - acc: 1.1282e-04 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 0.0028 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0022 - acc: 1.1282e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0021 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0020 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0020 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 9.1952e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 8.3512e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 6.8520e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 9.6759e-04 - acc: 1.1282e-04 - val_loss: 8.2497e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 9.4277e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 8.7008e-04 - acc: 1.1282e-04 - val_loss: 5.9960e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 8.2949e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.0162e-04 - acc: 1.1282e-04 - val_loss: 9.6401e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.8349e-04 - acc: 1.1282e-04 - val_loss: 9.3371e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.6863e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 7.1493e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.3798e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 6.7499e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 6.6438e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.8564e-04 - acc: 1.1282e-04 - val_loss: 6.3951e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 6.7006e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.4408e-04 - acc: 1.1282e-04 - val_loss: 7.5557e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.1537e-04 - acc: 1.1282e-04 - val_loss: 9.3855e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 6.4029e-04 - acc: 1.1282e-04 - val_loss: 6.8591e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 5.8268e-04 - acc: 1.1282e-04 - val_loss: 8.0347e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.7380e-04 - acc: 1.1282e-04 - val_loss: 6.5941e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.3606e-04 - acc: 1.1282e-04 - val_loss: 4.1108e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 4.8181e-04 - acc: 1.1282e-04 - val_loss: 3.1666e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.1436e-04 - acc: 1.1282e-04 - val_loss: 3.7045e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.7443e-04 - acc: 1.1282e-04 - val_loss: 5.6748e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.0137e-04 - acc: 1.1282e-04 - val_loss: 3.9678e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.7233e-04 - acc: 1.1282e-04 - val_loss: 7.7867e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.3658e-04 - acc: 1.1282e-04 - val_loss: 3.6311e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 4.5011e-04 - acc: 1.1282e-04 - val_loss: 4.2448e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.0235e-04 - acc: 1.1282e-04 - val_loss: 5.9321e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.9660e-04 - acc: 1.1282e-04 - val_loss: 5.8571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.9172e-04 - acc: 1.1282e-04 - val_loss: 6.1825e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.7151e-04 - acc: 1.1282e-04 - val_loss: 6.3683e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.6873e-04 - acc: 1.1282e-04 - val_loss: 5.7014e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.5878e-04 - acc: 1.1282e-04 - val_loss: 4.5387e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.6313e-04 - acc: 1.1282e-04 - val_loss: 7.9564e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.5661e-04 - acc: 1.1282e-04 - val_loss: 6.9409e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.5102e-04 - acc: 1.1282e-04 - val_loss: 8.3941e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.4548e-04 - acc: 1.1282e-04 - val_loss: 6.7731e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.2610e-04 - acc: 1.1282e-04 - val_loss: 5.5091e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.3259e-04 - acc: 1.1282e-04 - val_loss: 5.2442e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.3826e-04 - acc: 1.1282e-04 - val_loss: 7.2146e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 3.2600e-04 - acc: 1.1282e-04 - val_loss: 7.1848e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.0938e-04 - acc: 1.1282e-04 - val_loss: 7.5898e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.2376e-04 - acc: 1.1282e-04 - val_loss: 8.6507e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.0861e-04 - acc: 1.1282e-04 - val_loss: 9.2304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.0908e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.2660e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.2439e-04 - acc: 1.1282e-04 - val_loss: 9.1063e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 2.8793e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.1265e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.9484e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.9490e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.9120e-04 - acc: 1.1282e-04 - val_loss: 9.7082e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.0394e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.9645e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.9392e-04 - acc: 1.1282e-04 - val_loss: 8.8966e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.9561e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.9086e-04 - acc: 1.1282e-04 - val_loss: 8.3691e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 2.9296e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.8523e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.8696e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.8155e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.9162e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.8271e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.7120e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.7690e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.7688e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.6578e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.8379e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.6685e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.7757e-04 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.287\n",
            "TEMP MSE: 0.083\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_31 (LSTM)               (None, 22, 64)            17664     \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 22, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_32 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 52,801\n",
            "Trainable params: 52,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 8s 850us/step - loss: 0.0270 - acc: 1.1282e-04 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0059 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0026 - acc: 1.1282e-04 - val_loss: 9.9991e-04 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0021 - acc: 1.1282e-04 - val_loss: 9.5208e-04 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 0.0020 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0085 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0075 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.8345e-04 - acc: 1.1282e-04 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.4613e-04 - acc: 1.1282e-04 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.6954e-04 - acc: 1.1282e-04 - val_loss: 0.0090 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.9314e-04 - acc: 1.1282e-04 - val_loss: 0.0089 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 7.2135e-04 - acc: 1.1282e-04 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 7.1558e-04 - acc: 1.1282e-04 - val_loss: 0.0083 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.4362e-04 - acc: 1.1282e-04 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.2626e-04 - acc: 1.1282e-04 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 5.7750e-04 - acc: 1.1282e-04 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.3899e-04 - acc: 1.1282e-04 - val_loss: 0.0128 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0462e-04 - acc: 1.1282e-04 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.2658e-04 - acc: 1.1282e-04 - val_loss: 0.0164 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.9958e-04 - acc: 1.1282e-04 - val_loss: 0.0152 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.6946e-04 - acc: 1.1282e-04 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.4071e-04 - acc: 1.1282e-04 - val_loss: 0.0158 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.3165e-04 - acc: 1.1282e-04 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 4.1288e-04 - acc: 1.1282e-04 - val_loss: 0.0172 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.8443e-04 - acc: 1.1282e-04 - val_loss: 0.0173 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.8200e-04 - acc: 1.1282e-04 - val_loss: 0.0174 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.7591e-04 - acc: 1.1282e-04 - val_loss: 0.0194 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.6295e-04 - acc: 1.1282e-04 - val_loss: 0.0163 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.7115e-04 - acc: 1.1282e-04 - val_loss: 0.0185 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.3271e-04 - acc: 1.1282e-04 - val_loss: 0.0203 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.1882e-04 - acc: 1.1282e-04 - val_loss: 0.0176 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.1212e-04 - acc: 1.1282e-04 - val_loss: 0.0214 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.2567e-04 - acc: 1.1282e-04 - val_loss: 0.0182 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.2055e-04 - acc: 1.1282e-04 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.1078e-04 - acc: 1.1282e-04 - val_loss: 0.0184 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.8759e-04 - acc: 1.1282e-04 - val_loss: 0.0219 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.9561e-04 - acc: 1.1282e-04 - val_loss: 0.0218 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.8283e-04 - acc: 1.1282e-04 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.8577e-04 - acc: 1.1282e-04 - val_loss: 0.0215 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.8191e-04 - acc: 1.1282e-04 - val_loss: 0.0210 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.6888e-04 - acc: 1.1282e-04 - val_loss: 0.0217 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.5795e-04 - acc: 1.1282e-04 - val_loss: 0.0223 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.5179e-04 - acc: 1.1282e-04 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.5387e-04 - acc: 1.1282e-04 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.5962e-04 - acc: 1.1282e-04 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.5138e-04 - acc: 1.1282e-04 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.3878e-04 - acc: 1.1282e-04 - val_loss: 0.0220 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.5138e-04 - acc: 1.1282e-04 - val_loss: 0.0237 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.3018e-04 - acc: 1.1282e-04 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.4505e-04 - acc: 1.1282e-04 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.5622e-04 - acc: 1.1282e-04 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.4254e-04 - acc: 1.1282e-04 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 2.3607e-04 - acc: 1.1282e-04 - val_loss: 0.0240 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.3010e-04 - acc: 1.1282e-04 - val_loss: 0.0246 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.2986e-04 - acc: 1.1282e-04 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3104e-04 - acc: 1.1282e-04 - val_loss: 0.0234 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.2756e-04 - acc: 1.1282e-04 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.2242e-04 - acc: 1.1282e-04 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.2596e-04 - acc: 1.1282e-04 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3392e-04 - acc: 1.1282e-04 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.2234e-04 - acc: 1.1282e-04 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.3122e-04 - acc: 1.1282e-04 - val_loss: 0.0265 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.2796e-04 - acc: 1.1282e-04 - val_loss: 0.0245 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.1577e-04 - acc: 1.1282e-04 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2161e-04 - acc: 1.1282e-04 - val_loss: 0.0239 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.2582e-04 - acc: 1.1282e-04 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.2157e-04 - acc: 1.1282e-04 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.1099e-04 - acc: 1.1282e-04 - val_loss: 0.0259 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.0177e-04 - acc: 1.1282e-04 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.0914e-04 - acc: 1.1282e-04 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2174e-04 - acc: 1.1282e-04 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.1887e-04 - acc: 1.1282e-04 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0394e-04 - acc: 1.1282e-04 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9621e-04 - acc: 1.1282e-04 - val_loss: 0.0263 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.0800e-04 - acc: 1.1282e-04 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0712e-04 - acc: 1.1282e-04 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.0933e-04 - acc: 1.1282e-04 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0055e-04 - acc: 1.1282e-04 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.422\n",
            "TEMP MSE: 0.178\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_33 (LSTM)               (None, 22, 64)            17664     \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 22, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_34 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 54,913\n",
            "Trainable params: 54,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 8s 894us/step - loss: 0.0213 - acc: 1.1282e-04 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0044 - acc: 1.1282e-04 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0024 - acc: 1.1282e-04 - val_loss: 4.9074e-04 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0019 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0017 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0189 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.1218e-04 - acc: 1.1282e-04 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 8.3583e-04 - acc: 1.1282e-04 - val_loss: 0.0453 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.5417e-04 - acc: 1.1282e-04 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.1338e-04 - acc: 1.1282e-04 - val_loss: 0.0549 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.6166e-04 - acc: 1.1282e-04 - val_loss: 0.0570 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 5.9059e-04 - acc: 1.1282e-04 - val_loss: 0.0606 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.5047e-04 - acc: 1.1282e-04 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 5.0972e-04 - acc: 1.1282e-04 - val_loss: 0.0752 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.0099e-04 - acc: 1.1282e-04 - val_loss: 0.0772 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 4.6064e-04 - acc: 1.1282e-04 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.2983e-04 - acc: 1.1282e-04 - val_loss: 0.0826 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.3585e-04 - acc: 1.1282e-04 - val_loss: 0.0856 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.1306e-04 - acc: 1.1282e-04 - val_loss: 0.0893 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.9237e-04 - acc: 1.1282e-04 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.4980e-04 - acc: 1.1282e-04 - val_loss: 0.0924 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.8612e-04 - acc: 1.1282e-04 - val_loss: 0.0919 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.4892e-04 - acc: 1.1282e-04 - val_loss: 0.0943 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.2809e-04 - acc: 1.1282e-04 - val_loss: 0.0938 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.3881e-04 - acc: 1.1282e-04 - val_loss: 0.0931 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 3.2176e-04 - acc: 1.1282e-04 - val_loss: 0.0925 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.1072e-04 - acc: 1.1282e-04 - val_loss: 0.0949 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.9822e-04 - acc: 1.1282e-04 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.0279e-04 - acc: 1.1282e-04 - val_loss: 0.0942 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.8056e-04 - acc: 1.1282e-04 - val_loss: 0.0910 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.8709e-04 - acc: 1.1282e-04 - val_loss: 0.0941 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.7523e-04 - acc: 1.1282e-04 - val_loss: 0.0894 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.7544e-04 - acc: 1.1282e-04 - val_loss: 0.0902 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.8421e-04 - acc: 1.1282e-04 - val_loss: 0.0892 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.6053e-04 - acc: 1.1282e-04 - val_loss: 0.0881 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.6988e-04 - acc: 1.1282e-04 - val_loss: 0.0883 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.5862e-04 - acc: 1.1282e-04 - val_loss: 0.0855 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.4857e-04 - acc: 1.1282e-04 - val_loss: 0.0874 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.5590e-04 - acc: 1.1282e-04 - val_loss: 0.0848 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.4083e-04 - acc: 1.1282e-04 - val_loss: 0.0843 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.4746e-04 - acc: 1.1282e-04 - val_loss: 0.0868 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.4604e-04 - acc: 1.1282e-04 - val_loss: 0.0837 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.4148e-04 - acc: 1.1282e-04 - val_loss: 0.0846 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.4909e-04 - acc: 1.1282e-04 - val_loss: 0.0812 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.5525e-04 - acc: 1.1282e-04 - val_loss: 0.0844 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.4543e-04 - acc: 1.1282e-04 - val_loss: 0.0820 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2270e-04 - acc: 1.1282e-04 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.2655e-04 - acc: 1.1282e-04 - val_loss: 0.0809 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1629e-04 - acc: 1.1282e-04 - val_loss: 0.0793 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.1648e-04 - acc: 1.1282e-04 - val_loss: 0.0779 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.2234e-04 - acc: 1.1282e-04 - val_loss: 0.0809 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.2267e-04 - acc: 1.1282e-04 - val_loss: 0.0797 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1763e-04 - acc: 1.1282e-04 - val_loss: 0.0776 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.0584e-04 - acc: 1.1282e-04 - val_loss: 0.0819 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.1310e-04 - acc: 1.1282e-04 - val_loss: 0.0798 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.1555e-04 - acc: 1.1282e-04 - val_loss: 0.0788 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.0410e-04 - acc: 1.1282e-04 - val_loss: 0.0795 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.1380e-04 - acc: 1.1282e-04 - val_loss: 0.0801 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.0976e-04 - acc: 1.1282e-04 - val_loss: 0.0804 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.0127e-04 - acc: 1.1282e-04 - val_loss: 0.0786 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 1.9425e-04 - acc: 1.1282e-04 - val_loss: 0.0765 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.0549e-04 - acc: 1.1282e-04 - val_loss: 0.0751 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.0672e-04 - acc: 1.1282e-04 - val_loss: 0.0757 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.0453e-04 - acc: 1.1282e-04 - val_loss: 0.0755 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.0450e-04 - acc: 1.1282e-04 - val_loss: 0.0739 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9731e-04 - acc: 1.1282e-04 - val_loss: 0.0722 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 1.9380e-04 - acc: 1.1282e-04 - val_loss: 0.0732 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.0232e-04 - acc: 1.1282e-04 - val_loss: 0.0724 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.0480e-04 - acc: 1.1282e-04 - val_loss: 0.0721 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.9291e-04 - acc: 1.1282e-04 - val_loss: 0.0745 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.9949e-04 - acc: 1.1282e-04 - val_loss: 0.0734 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.9894e-04 - acc: 1.1282e-04 - val_loss: 0.0723 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9824e-04 - acc: 1.1282e-04 - val_loss: 0.0730 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.0185e-04 - acc: 1.1282e-04 - val_loss: 0.0712 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 1.9474e-04 - acc: 1.1282e-04 - val_loss: 0.0713 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.9041e-04 - acc: 1.1282e-04 - val_loss: 0.0708 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 1.8895e-04 - acc: 1.1282e-04 - val_loss: 0.0715 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.8030e-04 - acc: 1.1282e-04 - val_loss: 0.0726 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.8591e-04 - acc: 1.1282e-04 - val_loss: 0.0725 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.8916e-04 - acc: 1.1282e-04 - val_loss: 0.0710 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 1.9649e-04 - acc: 1.1282e-04 - val_loss: 0.0698 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.0153e-04 - acc: 1.1282e-04 - val_loss: 0.0696 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9061e-04 - acc: 1.1282e-04 - val_loss: 0.0714 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.8600e-04 - acc: 1.1282e-04 - val_loss: 0.0687 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.7848e-04 - acc: 1.1282e-04 - val_loss: 0.0657 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.525\n",
            "TEMP MSE: 0.275\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_35 (LSTM)               (None, 22, 128)           68096     \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 22, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_36 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 201,761\n",
            "Trainable params: 201,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 8s 938us/step - loss: 0.0234 - acc: 1.1282e-04 - val_loss: 0.0199 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0030 - acc: 1.1282e-04 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0014 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 5.9415e-04 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 9.9255e-04 - acc: 1.1282e-04 - val_loss: 4.7698e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 9.4391e-04 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 9.1300e-04 - acc: 1.1282e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.2026e-04 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 8.6422e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.2022e-04 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 9.1041e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 8.4511e-04 - acc: 1.1282e-04 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 7.6791e-04 - acc: 1.1282e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.6362e-04 - acc: 1.1282e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 7.6408e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 7.7933e-04 - acc: 1.1282e-04 - val_loss: 7.5357e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 8.2654e-04 - acc: 1.1282e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 7.1726e-04 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 6.7366e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 6.7724e-04 - acc: 1.1282e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 6.6438e-04 - acc: 1.1282e-04 - val_loss: 9.9866e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.5980e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.4052e-04 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.0948e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 5.8471e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.7146e-04 - acc: 1.1282e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.2112e-04 - acc: 1.1282e-04 - val_loss: 6.3230e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 5.0693e-04 - acc: 1.1282e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 5.0511e-04 - acc: 1.1282e-04 - val_loss: 8.3840e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.1076e-04 - acc: 1.1282e-04 - val_loss: 4.1593e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.0802e-04 - acc: 1.1282e-04 - val_loss: 9.6515e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.6275e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 4.5838e-04 - acc: 1.1282e-04 - val_loss: 9.3755e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.3886e-04 - acc: 1.1282e-04 - val_loss: 4.3432e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.3062e-04 - acc: 1.1282e-04 - val_loss: 7.2052e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.1376e-04 - acc: 1.1282e-04 - val_loss: 5.4304e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.8782e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.9129e-04 - acc: 1.1282e-04 - val_loss: 9.1550e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.9288e-04 - acc: 1.1282e-04 - val_loss: 7.4914e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.0260e-04 - acc: 1.1282e-04 - val_loss: 6.7206e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 3.7914e-04 - acc: 1.1282e-04 - val_loss: 8.6330e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.7893e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.5287e-04 - acc: 1.1282e-04 - val_loss: 5.9557e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.4871e-04 - acc: 1.1282e-04 - val_loss: 6.2969e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.4567e-04 - acc: 1.1282e-04 - val_loss: 6.6623e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 3.4032e-04 - acc: 1.1282e-04 - val_loss: 4.0179e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.3331e-04 - acc: 1.1282e-04 - val_loss: 8.9369e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.3502e-04 - acc: 1.1282e-04 - val_loss: 6.0886e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 3.1464e-04 - acc: 1.1282e-04 - val_loss: 4.0447e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.9917e-04 - acc: 1.1282e-04 - val_loss: 4.7048e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.9894e-04 - acc: 1.1282e-04 - val_loss: 4.6216e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.9237e-04 - acc: 1.1282e-04 - val_loss: 9.0404e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.3375e-04 - acc: 1.1282e-04 - val_loss: 7.3147e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.7649e-04 - acc: 1.1282e-04 - val_loss: 3.0373e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.7715e-04 - acc: 1.1282e-04 - val_loss: 3.4393e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.6539e-04 - acc: 1.1282e-04 - val_loss: 6.3036e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.7207e-04 - acc: 1.1282e-04 - val_loss: 3.5248e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.7109e-04 - acc: 1.1282e-04 - val_loss: 5.4642e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.6388e-04 - acc: 1.1282e-04 - val_loss: 4.9000e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.5144e-04 - acc: 1.1282e-04 - val_loss: 8.3669e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.6068e-04 - acc: 1.1282e-04 - val_loss: 7.0131e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.4516e-04 - acc: 1.1282e-04 - val_loss: 4.0408e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.3146e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.4952e-04 - acc: 1.1282e-04 - val_loss: 6.7428e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.3261e-04 - acc: 1.1282e-04 - val_loss: 6.3739e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.2798e-04 - acc: 1.1282e-04 - val_loss: 5.5328e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.3071e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.5484e-04 - acc: 1.1282e-04 - val_loss: 6.2429e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.2537e-04 - acc: 1.1282e-04 - val_loss: 4.7655e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 2.2747e-04 - acc: 1.1282e-04 - val_loss: 7.3230e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1288e-04 - acc: 1.1282e-04 - val_loss: 5.3699e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.1316e-04 - acc: 1.1282e-04 - val_loss: 6.6789e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.3386e-04 - acc: 1.1282e-04 - val_loss: 4.7805e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1589e-04 - acc: 1.1282e-04 - val_loss: 9.7326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.1848e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.2791e-04 - acc: 1.1282e-04 - val_loss: 5.6598e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9268e-04 - acc: 1.1282e-04 - val_loss: 8.0202e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.9840e-04 - acc: 1.1282e-04 - val_loss: 4.4593e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.0899e-04 - acc: 1.1282e-04 - val_loss: 4.1516e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.9735e-04 - acc: 1.1282e-04 - val_loss: 4.8870e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.9452e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.1569e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.0412e-04 - acc: 1.1282e-04 - val_loss: 5.2372e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9365e-04 - acc: 1.1282e-04 - val_loss: 7.1477e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.9978e-04 - acc: 1.1282e-04 - val_loss: 9.1545e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.209\n",
            "TEMP MSE: 0.044\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_37 (LSTM)               (None, 22, 128)           68096     \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 22, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 203,841\n",
            "Trainable params: 203,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 9s 976us/step - loss: 0.0202 - acc: 1.1282e-04 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0032 - acc: 1.1282e-04 - val_loss: 0.0073 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 0.0016 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0013 - acc: 1.1282e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 8.6241e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 9.4560e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 9.0756e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 9.1723e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 8.0774e-04 - acc: 1.1282e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 8.1619e-04 - acc: 1.1282e-04 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 7.9816e-04 - acc: 1.1282e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.4364e-04 - acc: 1.1282e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.4948e-04 - acc: 1.1282e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 7.3888e-04 - acc: 1.1282e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 7.1281e-04 - acc: 1.1282e-04 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.8008e-04 - acc: 1.1282e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.7389e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.5061e-04 - acc: 1.1282e-04 - val_loss: 0.0034 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.3638e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 6.2116e-04 - acc: 1.1282e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 5.6508e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.4940e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.4711e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 5.2985e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 5.3111e-04 - acc: 1.1282e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 5.1182e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.7492e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.7243e-04 - acc: 1.1282e-04 - val_loss: 0.0020 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 4.4722e-04 - acc: 1.1282e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 4.4352e-04 - acc: 1.1282e-04 - val_loss: 8.3456e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 4.5160e-04 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 4.4725e-04 - acc: 1.1282e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.0682e-04 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.6734e-04 - acc: 1.1282e-04 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.6993e-04 - acc: 1.1282e-04 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 3.6186e-04 - acc: 1.1282e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.4854e-04 - acc: 1.1282e-04 - val_loss: 0.0031 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 3.4103e-04 - acc: 1.1282e-04 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 3.2922e-04 - acc: 1.1282e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.1649e-04 - acc: 1.1282e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 3.0698e-04 - acc: 1.1282e-04 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.0211e-04 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 3.1278e-04 - acc: 1.1282e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 2.9189e-04 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.7870e-04 - acc: 1.1282e-04 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.7132e-04 - acc: 1.1282e-04 - val_loss: 0.0032 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.6485e-04 - acc: 1.1282e-04 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.4731e-04 - acc: 1.1282e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.5694e-04 - acc: 1.1282e-04 - val_loss: 0.0025 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.5278e-04 - acc: 1.1282e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.6091e-04 - acc: 1.1282e-04 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.9084e-04 - acc: 1.1282e-04 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.5137e-04 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.4959e-04 - acc: 1.1282e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.2304e-04 - acc: 1.1282e-04 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 2.1910e-04 - acc: 1.1282e-04 - val_loss: 0.0039 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.2037e-04 - acc: 1.1282e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 2.1388e-04 - acc: 1.1282e-04 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.1277e-04 - acc: 1.1282e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.2602e-04 - acc: 1.1282e-04 - val_loss: 0.0056 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.0635e-04 - acc: 1.1282e-04 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.9340e-04 - acc: 1.1282e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.0537e-04 - acc: 1.1282e-04 - val_loss: 0.0051 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 1.9076e-04 - acc: 1.1282e-04 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 2.0010e-04 - acc: 1.1282e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9740e-04 - acc: 1.1282e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.3273e-04 - acc: 1.1282e-04 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.9352e-04 - acc: 1.1282e-04 - val_loss: 0.0038 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 1.9883e-04 - acc: 1.1282e-04 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.8993e-04 - acc: 1.1282e-04 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.8160e-04 - acc: 1.1282e-04 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.8506e-04 - acc: 1.1282e-04 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 133us/step - loss: 1.8248e-04 - acc: 1.1282e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.8409e-04 - acc: 1.1282e-04 - val_loss: 0.0045 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.7373e-04 - acc: 1.1282e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.6961e-04 - acc: 1.1282e-04 - val_loss: 0.0044 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.8790e-04 - acc: 1.1282e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 134us/step - loss: 1.7594e-04 - acc: 1.1282e-04 - val_loss: 0.0058 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.8348e-04 - acc: 1.1282e-04 - val_loss: 0.0057 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.7936e-04 - acc: 1.1282e-04 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.6732e-04 - acc: 1.1282e-04 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.7628e-04 - acc: 1.1282e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 1.7917e-04 - acc: 1.1282e-04 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.7392e-04 - acc: 1.1282e-04 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6710e-04 - acc: 1.1282e-04 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.7039e-04 - acc: 1.1282e-04 - val_loss: 0.0042 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.7125e-04 - acc: 1.1282e-04 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.271\n",
            "TEMP MSE: 0.073\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_39 (LSTM)               (None, 22, 128)           68096     \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 22, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_40 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 208,001\n",
            "Trainable params: 208,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 9s 1ms/step - loss: 0.0155 - acc: 1.1282e-04 - val_loss: 0.0087 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 0.0023 - acc: 1.1282e-04 - val_loss: 0.0054 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0015 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0012 - acc: 1.1282e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 0.0010 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 9.8122e-04 - acc: 1.1282e-04 - val_loss: 7.6823e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 9.3530e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 8.7667e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 7.7376e-04 - acc: 1.1282e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 7.6695e-04 - acc: 1.1282e-04 - val_loss: 0.0049 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 8.0044e-04 - acc: 1.1282e-04 - val_loss: 0.0046 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 7.2036e-04 - acc: 1.1282e-04 - val_loss: 0.0104 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 7.0840e-04 - acc: 1.1282e-04 - val_loss: 0.0092 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 6.7304e-04 - acc: 1.1282e-04 - val_loss: 0.0095 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 6.4676e-04 - acc: 1.1282e-04 - val_loss: 0.0102 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 6.2106e-04 - acc: 1.1282e-04 - val_loss: 0.0145 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 6.0135e-04 - acc: 1.1282e-04 - val_loss: 0.0149 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 135us/step - loss: 5.6784e-04 - acc: 1.1282e-04 - val_loss: 0.0147 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 5.8425e-04 - acc: 1.1282e-04 - val_loss: 0.0176 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 6.0362e-04 - acc: 1.1282e-04 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 4.9685e-04 - acc: 1.1282e-04 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.1653e-04 - acc: 1.1282e-04 - val_loss: 0.0230 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 5.0399e-04 - acc: 1.1282e-04 - val_loss: 0.0217 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.6095e-04 - acc: 1.1282e-04 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.5534e-04 - acc: 1.1282e-04 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 4.2818e-04 - acc: 1.1282e-04 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 4.0826e-04 - acc: 1.1282e-04 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.8550e-04 - acc: 1.1282e-04 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.7822e-04 - acc: 1.1282e-04 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 3.6198e-04 - acc: 1.1282e-04 - val_loss: 0.0418 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 3.3488e-04 - acc: 1.1282e-04 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 3.3085e-04 - acc: 1.1282e-04 - val_loss: 0.0398 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 3.0037e-04 - acc: 1.1282e-04 - val_loss: 0.0409 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 3.0777e-04 - acc: 1.1282e-04 - val_loss: 0.0451 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 2.9463e-04 - acc: 1.1282e-04 - val_loss: 0.0471 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 2.8796e-04 - acc: 1.1282e-04 - val_loss: 0.0511 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.8198e-04 - acc: 1.1282e-04 - val_loss: 0.0526 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.7642e-04 - acc: 1.1282e-04 - val_loss: 0.0509 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.7773e-04 - acc: 1.1282e-04 - val_loss: 0.0520 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 2.5534e-04 - acc: 1.1282e-04 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.6641e-04 - acc: 1.1282e-04 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 2.3188e-04 - acc: 1.1282e-04 - val_loss: 0.0534 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.3082e-04 - acc: 1.1282e-04 - val_loss: 0.0540 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 2.3126e-04 - acc: 1.1282e-04 - val_loss: 0.0487 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 2.3083e-04 - acc: 1.1282e-04 - val_loss: 0.0529 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 2.0899e-04 - acc: 1.1282e-04 - val_loss: 0.0536 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.2633e-04 - acc: 1.1282e-04 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 2.2101e-04 - acc: 1.1282e-04 - val_loss: 0.0530 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.1240e-04 - acc: 1.1282e-04 - val_loss: 0.0538 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 2.0530e-04 - acc: 1.1282e-04 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.9858e-04 - acc: 1.1282e-04 - val_loss: 0.0522 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.9031e-04 - acc: 1.1282e-04 - val_loss: 0.0542 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.9430e-04 - acc: 1.1282e-04 - val_loss: 0.0537 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 1.9027e-04 - acc: 1.1282e-04 - val_loss: 0.0531 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.7973e-04 - acc: 1.1282e-04 - val_loss: 0.0510 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.9549e-04 - acc: 1.1282e-04 - val_loss: 0.0524 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.8723e-04 - acc: 1.1282e-04 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.8112e-04 - acc: 1.1282e-04 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.9334e-04 - acc: 1.1282e-04 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 2.0952e-04 - acc: 1.1282e-04 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.7847e-04 - acc: 1.1282e-04 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.7198e-04 - acc: 1.1282e-04 - val_loss: 0.0519 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.6502e-04 - acc: 1.1282e-04 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.6484e-04 - acc: 1.1282e-04 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.6507e-04 - acc: 1.1282e-04 - val_loss: 0.0514 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.6671e-04 - acc: 1.1282e-04 - val_loss: 0.0501 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.5842e-04 - acc: 1.1282e-04 - val_loss: 0.0512 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 1.6771e-04 - acc: 1.1282e-04 - val_loss: 0.0506 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.7164e-04 - acc: 1.1282e-04 - val_loss: 0.0502 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 1.5844e-04 - acc: 1.1282e-04 - val_loss: 0.0503 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.5415e-04 - acc: 1.1282e-04 - val_loss: 0.0504 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.5304e-04 - acc: 1.1282e-04 - val_loss: 0.0508 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 144us/step - loss: 1.6229e-04 - acc: 1.1282e-04 - val_loss: 0.0486 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.5835e-04 - acc: 1.1282e-04 - val_loss: 0.0494 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.4533e-04 - acc: 1.1282e-04 - val_loss: 0.0497 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 136us/step - loss: 1.5971e-04 - acc: 1.1282e-04 - val_loss: 0.0525 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.5577e-04 - acc: 1.1282e-04 - val_loss: 0.0501 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.4166e-04 - acc: 1.1282e-04 - val_loss: 0.0490 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 1.4915e-04 - acc: 1.1282e-04 - val_loss: 0.0499 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.4576e-04 - acc: 1.1282e-04 - val_loss: 0.0477 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 140us/step - loss: 1.6154e-04 - acc: 1.1282e-04 - val_loss: 0.0473 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 137us/step - loss: 1.5096e-04 - acc: 1.1282e-04 - val_loss: 0.0517 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.4956e-04 - acc: 1.1282e-04 - val_loss: 0.0460 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.5796e-04 - acc: 1.1282e-04 - val_loss: 0.0481 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 1.4379e-04 - acc: 1.1282e-04 - val_loss: 0.0484 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.3542e-04 - acc: 1.1282e-04 - val_loss: 0.0479 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 139us/step - loss: 1.4210e-04 - acc: 1.1282e-04 - val_loss: 0.0478 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 138us/step - loss: 1.4685e-04 - acc: 1.1282e-04 - val_loss: 0.0470 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 141us/step - loss: 1.4938e-04 - acc: 1.1282e-04 - val_loss: 0.0475 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.383\n",
            "TEMP MSE: 0.146\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_41 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_42 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 16)                4112      \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 796,705\n",
            "Trainable params: 796,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 10s 1ms/step - loss: 0.0151 - acc: 1.1282e-04 - val_loss: 0.0112 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 0.0018 - acc: 1.1282e-04 - val_loss: 0.0029 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 142us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 8.1383e-04 - acc: 1.1282e-04 - val_loss: 8.8043e-04 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.3790e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 7.7067e-04 - acc: 1.1282e-04 - val_loss: 9.9007e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.2615e-04 - acc: 1.1282e-04 - val_loss: 3.9514e-04 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 6.4114e-04 - acc: 1.1282e-04 - val_loss: 7.5570e-04 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.8519e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.9396e-04 - acc: 1.1282e-04 - val_loss: 4.2330e-04 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "8864/8864 [==============================] - 1s 143us/step - loss: 6.0098e-04 - acc: 1.1282e-04 - val_loss: 3.8708e-04 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.7608e-04 - acc: 1.1282e-04 - val_loss: 5.7390e-04 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 5.7795e-04 - acc: 1.1282e-04 - val_loss: 4.0726e-04 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.7241e-04 - acc: 1.1282e-04 - val_loss: 8.9282e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.6756e-04 - acc: 1.1282e-04 - val_loss: 5.0852e-04 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "8864/8864 [==============================] - 1s 145us/step - loss: 5.7720e-04 - acc: 1.1282e-04 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.3714e-04 - acc: 1.1282e-04 - val_loss: 6.2546e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.0936e-04 - acc: 1.1282e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 5.1402e-04 - acc: 1.1282e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 5.0800e-04 - acc: 1.1282e-04 - val_loss: 8.6563e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.1313e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 5.0477e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "8864/8864 [==============================] - 2s 180us/step - loss: 5.0305e-04 - acc: 1.1282e-04 - val_loss: 7.2151e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "8864/8864 [==============================] - 3s 318us/step - loss: 4.6889e-04 - acc: 1.1282e-04 - val_loss: 8.4296e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 5.2005e-04 - acc: 1.1282e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.8355e-04 - acc: 1.1282e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "8864/8864 [==============================] - 1s 161us/step - loss: 4.5366e-04 - acc: 1.1282e-04 - val_loss: 9.7133e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 4.4754e-04 - acc: 1.1282e-04 - val_loss: 5.3571e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 4.3901e-04 - acc: 1.1282e-04 - val_loss: 6.0777e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.4043e-04 - acc: 1.1282e-04 - val_loss: 3.8257e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 4.3708e-04 - acc: 1.1282e-04 - val_loss: 8.3620e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 4.2602e-04 - acc: 1.1282e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 4.3073e-04 - acc: 1.1282e-04 - val_loss: 3.0022e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.4095e-04 - acc: 1.1282e-04 - val_loss: 7.2188e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.2916e-04 - acc: 1.1282e-04 - val_loss: 6.7383e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 3.9386e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 4.4945e-04 - acc: 1.1282e-04 - val_loss: 2.6667e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.3446e-04 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 5.0952e-04 - acc: 1.1282e-04 - val_loss: 8.6713e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 4.0131e-04 - acc: 1.1282e-04 - val_loss: 6.6978e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 3.9138e-04 - acc: 1.1282e-04 - val_loss: 8.6451e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.7719e-04 - acc: 1.1282e-04 - val_loss: 9.6240e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 4.0797e-04 - acc: 1.1282e-04 - val_loss: 2.9157e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.8410e-04 - acc: 1.1282e-04 - val_loss: 6.0866e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 3.5029e-04 - acc: 1.1282e-04 - val_loss: 4.2773e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 3.6409e-04 - acc: 1.1282e-04 - val_loss: 6.0956e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 3.5573e-04 - acc: 1.1282e-04 - val_loss: 2.2950e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 3.5139e-04 - acc: 1.1282e-04 - val_loss: 2.6015e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 3.5172e-04 - acc: 1.1282e-04 - val_loss: 5.1062e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 3.4468e-04 - acc: 1.1282e-04 - val_loss: 2.5381e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "8864/8864 [==============================] - 1s 157us/step - loss: 3.3830e-04 - acc: 1.1282e-04 - val_loss: 2.3384e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "8864/8864 [==============================] - 1s 159us/step - loss: 3.5926e-04 - acc: 1.1282e-04 - val_loss: 6.3099e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 3.3884e-04 - acc: 1.1282e-04 - val_loss: 2.2963e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.9652e-04 - acc: 1.1282e-04 - val_loss: 2.0990e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 3.4401e-04 - acc: 1.1282e-04 - val_loss: 2.1156e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "8864/8864 [==============================] - 1s 146us/step - loss: 3.2424e-04 - acc: 1.1282e-04 - val_loss: 3.4102e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 3.1881e-04 - acc: 1.1282e-04 - val_loss: 1.8638e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "8864/8864 [==============================] - 1s 157us/step - loss: 2.9505e-04 - acc: 1.1282e-04 - val_loss: 3.6621e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.8485e-04 - acc: 1.1282e-04 - val_loss: 3.8704e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.9960e-04 - acc: 1.1282e-04 - val_loss: 2.4563e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.9153e-04 - acc: 1.1282e-04 - val_loss: 3.9326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "8864/8864 [==============================] - 1s 156us/step - loss: 2.6408e-04 - acc: 1.1282e-04 - val_loss: 2.1128e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.8033e-04 - acc: 1.1282e-04 - val_loss: 2.6249e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 2.4314e-04 - acc: 1.1282e-04 - val_loss: 6.8042e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 2.6805e-04 - acc: 1.1282e-04 - val_loss: 1.9938e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.9236e-04 - acc: 1.1282e-04 - val_loss: 2.8395e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.5060e-04 - acc: 1.1282e-04 - val_loss: 1.9172e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.3476e-04 - acc: 1.1282e-04 - val_loss: 3.8705e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 2.5184e-04 - acc: 1.1282e-04 - val_loss: 3.7486e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.2821e-04 - acc: 1.1282e-04 - val_loss: 5.3923e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.2283e-04 - acc: 1.1282e-04 - val_loss: 5.3123e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "8864/8864 [==============================] - 1s 156us/step - loss: 2.2487e-04 - acc: 1.1282e-04 - val_loss: 3.4603e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "8864/8864 [==============================] - 1s 152us/step - loss: 2.4081e-04 - acc: 1.1282e-04 - val_loss: 5.0287e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "8864/8864 [==============================] - 1s 162us/step - loss: 2.4666e-04 - acc: 1.1282e-04 - val_loss: 9.9654e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.3633e-04 - acc: 1.1282e-04 - val_loss: 7.1563e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.2852e-04 - acc: 1.1282e-04 - val_loss: 2.5751e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 2.3304e-04 - acc: 1.1282e-04 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.3143e-04 - acc: 1.1282e-04 - val_loss: 2.1757e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "8864/8864 [==============================] - 1s 147us/step - loss: 2.0307e-04 - acc: 1.1282e-04 - val_loss: 5.7984e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.1684e-04 - acc: 1.1282e-04 - val_loss: 6.0741e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "8864/8864 [==============================] - 1s 156us/step - loss: 2.0076e-04 - acc: 1.1282e-04 - val_loss: 3.2757e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "8864/8864 [==============================] - 1s 157us/step - loss: 2.0030e-04 - acc: 1.1282e-04 - val_loss: 5.1121e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 2.2852e-04 - acc: 1.1282e-04 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 2.1571e-04 - acc: 1.1282e-04 - val_loss: 2.5789e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 2.0492e-04 - acc: 1.1282e-04 - val_loss: 3.8786e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "8864/8864 [==============================] - 1s 151us/step - loss: 1.9367e-04 - acc: 1.1282e-04 - val_loss: 3.8987e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.9095e-04 - acc: 1.1282e-04 - val_loss: 4.3842e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "8864/8864 [==============================] - 1s 153us/step - loss: 1.8025e-04 - acc: 1.1282e-04 - val_loss: 1.8955e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "8864/8864 [==============================] - 1s 148us/step - loss: 1.9509e-04 - acc: 1.1282e-04 - val_loss: 3.4405e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 1.7676e-04 - acc: 1.1282e-04 - val_loss: 4.2511e-04 - val_acc: 0.0000e+00\n",
            "TEMP RMSE: 0.108\n",
            "TEMP MSE: 0.012\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_43 (LSTM)               (None, 22, 256)           267264    \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 22, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_44 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 800,833\n",
            "Trainable params: 800,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 8864 samples, validate on 985 samples\n",
            "Epoch 1/90\n",
            "8864/8864 [==============================] - 10s 1ms/step - loss: 0.0153 - acc: 1.1282e-04 - val_loss: 0.0066 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "8864/8864 [==============================] - 1s 150us/step - loss: 0.0021 - acc: 1.1282e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "8864/8864 [==============================] - 1s 155us/step - loss: 0.0011 - acc: 1.1282e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 7.8284e-04 - acc: 1.1282e-04 - val_loss: 0.0023 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "8864/8864 [==============================] - 1s 154us/step - loss: 7.8720e-04 - acc: 1.1282e-04 - val_loss: 9.0599e-04 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "8864/8864 [==============================] - 1s 149us/step - loss: 6.7416e-04 - acc: 1.1282e-04 - val_loss: 6.9680e-04 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "6656/8864 [=====================>........] - ETA: 0s - loss: 6.6339e-04 - acc: 1.5024e-04"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efm3oUSuL-TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lists = sorted(neurons_result.items())\n",
        "x,y = zip(*lists)\n",
        " \n",
        "plt.title('Finding the best hyperparameter')\n",
        "plt.xlabel('neurons')\n",
        "plt.ylabel('Mean Square Error')\n",
        " \n",
        "plt.bar(range(len(lists)), y, align='center')\n",
        "plt.xticks(range(len(lists)), x)\n",
        "plt.xticks(rotation=90)\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2DMI_GMMARL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF0Io4mcMCUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}